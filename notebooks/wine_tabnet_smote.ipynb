{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:44:09.260652Z",
     "start_time": "2025-05-20T12:44:09.247789Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:44:09.317202Z",
     "start_time": "2025-05-20T12:44:09.271912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load datasets\n",
    "red = pd.read_csv(\"../data/wine+quality/winequality-red.csv\", sep=';')\n",
    "white = pd.read_csv(\"../data/wine+quality/winequality-white.csv\", sep=';')\n",
    "\n",
    "# Add 'type' feature\n",
    "red['type'] = 'red'\n",
    "white['type'] = 'white'\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([red, white], ignore_index=True)\n",
    "\n",
    "# One-hot encode 'type'\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']"
   ],
   "id": "eaa87da57b291efe",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:44:09.463628Z",
     "start_time": "2025-05-20T12:44:09.358556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize distribution.\n",
    "\n",
    "# Count and ratio\n",
    "counts = y.value_counts().sort_index()\n",
    "ratios = counts / counts.sum()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(counts.index, counts.values, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ratio = ratios.iloc[i]\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 30,\n",
    "        f\"{ratio:.1%}\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "        color='black'  # Force pure white\n",
    "    )\n",
    "\n",
    "\n",
    "# Titles and axes\n",
    "plt.title(\"Wine Data Distribution\")\n",
    "plt.xlabel(\"Quality\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(counts.index)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "2016fea8b49fc4e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:44:09.540243Z",
     "start_time": "2025-05-20T12:44:09.485971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load datasets\n",
    "red = pd.read_csv(\"../data/wine+quality/winequality-red.csv\", sep=';')\n",
    "white = pd.read_csv(\"../data/wine+quality/winequality-white.csv\", sep=';')\n",
    "\n",
    "# Add 'type' feature\n",
    "red['type'] = 'red'\n",
    "white['type'] = 'white'\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([red, white], ignore_index=True)\n",
    "\n",
    "# One-hot encode 'type'\n",
    "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_all = le.fit_transform(df['quality'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "\n",
    "# 1. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_all, test_size=0.2, stratify=y_all, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Separate rare classes (e.g., <10 samples)\n",
    "y_series = pd.Series(y_train).reset_index(drop=True)\n",
    "X_df = pd.DataFrame(X_train_scaled).reset_index(drop=True)\n",
    "\n",
    "class_counts = y_series.value_counts()\n",
    "rare_classes = class_counts[class_counts < 1000].index.tolist()\n",
    "\n",
    "# 4. Split training data: SMOTE-safe vs rare\n",
    "mask = ~y_series.isin(rare_classes)\n",
    "X_safe = X_df[mask].values\n",
    "y_safe = y_series[mask].values\n",
    "\n",
    "X_rare = X_df[~mask].values\n",
    "y_rare = y_series[~mask].values\n",
    "\n",
    "# 5. Apply SMOTE on SMOTE-safe subset only\n",
    "sm = SMOTE(random_state=42)\n",
    "X_smote, y_smote = sm.fit_resample(X_safe, y_safe)\n",
    "\n",
    "# 6. Combine all: original + resampled\n",
    "X_train_final = np.vstack([X_train_scaled, X_smote])\n",
    "y_train_final = np.hstack([y_train, y_smote])\n"
   ],
   "id": "4d81e60973601bba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:44:16.458189Z",
     "start_time": "2025-05-20T12:44:09.562848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize TabNet classifier\n",
    "clf = TabNetClassifier()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(\n",
    "    X_train=X_train_final, y_train=y_train_final,\n",
    "    eval_set=[(X_test_scaled, y_test)],\n",
    "    eval_name=['test'],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=256*2,\n",
    "    virtual_batch_size=128*2,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ],
   "id": "6ea274a33927b0ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.43517 | test_accuracy: 0.46538 |  0:00:00s\n",
      "epoch 1  | loss: 1.04292 | test_accuracy: 0.50769 |  0:00:00s\n",
      "epoch 2  | loss: 0.98452 | test_accuracy: 0.53077 |  0:00:00s\n",
      "epoch 3  | loss: 0.97266 | test_accuracy: 0.51462 |  0:00:01s\n",
      "epoch 4  | loss: 0.95135 | test_accuracy: 0.53077 |  0:00:01s\n",
      "epoch 5  | loss: 0.94819 | test_accuracy: 0.52538 |  0:00:01s\n",
      "epoch 6  | loss: 0.93681 | test_accuracy: 0.53308 |  0:00:02s\n",
      "epoch 7  | loss: 0.92687 | test_accuracy: 0.52923 |  0:00:02s\n",
      "epoch 8  | loss: 0.92044 | test_accuracy: 0.52692 |  0:00:02s\n",
      "epoch 9  | loss: 0.91475 | test_accuracy: 0.53923 |  0:00:02s\n",
      "epoch 10 | loss: 0.91327 | test_accuracy: 0.52615 |  0:00:03s\n",
      "epoch 11 | loss: 0.91277 | test_accuracy: 0.53769 |  0:00:03s\n",
      "epoch 12 | loss: 0.90813 | test_accuracy: 0.55077 |  0:00:03s\n",
      "epoch 13 | loss: 0.91067 | test_accuracy: 0.53923 |  0:00:04s\n",
      "epoch 14 | loss: 0.91701 | test_accuracy: 0.53077 |  0:00:04s\n",
      "epoch 15 | loss: 0.90267 | test_accuracy: 0.53846 |  0:00:04s\n",
      "epoch 16 | loss: 0.89855 | test_accuracy: 0.52769 |  0:00:04s\n",
      "epoch 17 | loss: 0.89806 | test_accuracy: 0.53385 |  0:00:05s\n",
      "epoch 18 | loss: 0.8938  | test_accuracy: 0.52308 |  0:00:05s\n",
      "epoch 19 | loss: 0.89702 | test_accuracy: 0.52615 |  0:00:05s\n",
      "epoch 20 | loss: 0.89667 | test_accuracy: 0.54077 |  0:00:06s\n",
      "epoch 21 | loss: 0.89467 | test_accuracy: 0.53462 |  0:00:06s\n",
      "epoch 22 | loss: 0.89036 | test_accuracy: 0.53615 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_test_accuracy = 0.55077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:04:45.154549Z",
     "start_time": "2025-05-20T12:44:16.479526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sympy.printing.pytorch import torch\n",
    "import optuna\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_final, y_train_final,\n",
    "    test_size=0.2, stratify=y_train_final, random_state=42\n",
    ")\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_d\": trial.suggest_categorical(\"n_d\", [8, 16, 32]),\n",
    "        \"n_a\": trial.suggest_categorical(\"n_a\", [8, 16, 32]),\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
    "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 1e-5, 1e-2, log=True),\n",
    "        \"optimizer_params\": dict(lr=trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)),\n",
    "        \"mask_type\": trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"]),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [512, 1024]),\n",
    "        \"virtual_batch_size\": trial.suggest_categorical(\"virtual_batch_size\", [128, 256]),\n",
    "    }\n",
    "\n",
    "\n",
    "    clf = TabNetClassifier(\n",
    "        n_d=params[\"n_d\"],\n",
    "        n_a=params[\"n_a\"],\n",
    "        n_steps=params[\"n_steps\"],\n",
    "        gamma=params[\"gamma\"],\n",
    "        lambda_sparse=params[\"lambda_sparse\"],\n",
    "        optimizer_params=params[\"optimizer_params\"],\n",
    "        mask_type=params[\"mask_type\"],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    clf.fit(\n",
    "        X_train=X_train_final, y_train=y_train_final,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        num_workers=0,\n",
    "        eval_name=[\"test\"],\n",
    "        eval_metric=[\"accuracy\"],\n",
    "        max_epochs=100,\n",
    "        patience=10,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        virtual_batch_size=params[\"virtual_batch_size\"],\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    preds = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    return acc\n",
    "\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Best results\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n"
   ],
   "id": "5282447cbe51b59c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-20 15:44:16,488] A new study created in memory with name: no-name-be0a94c2-6f27-4ae6-897d-7f7534b61208\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.41613 | test_accuracy: 0.03441 |  0:00:00s\n",
      "epoch 1  | loss: 4.30095 | test_accuracy: 0.1397  |  0:00:01s\n",
      "epoch 2  | loss: 3.1018  | test_accuracy: 0.33436 |  0:00:02s\n",
      "epoch 3  | loss: 2.22736 | test_accuracy: 0.48536 |  0:00:03s\n",
      "epoch 4  | loss: 1.8027  | test_accuracy: 0.51823 |  0:00:04s\n",
      "epoch 5  | loss: 1.56233 | test_accuracy: 0.50385 |  0:00:05s\n",
      "epoch 6  | loss: 1.38404 | test_accuracy: 0.51464 |  0:00:05s\n",
      "epoch 7  | loss: 1.29547 | test_accuracy: 0.52645 |  0:00:06s\n",
      "epoch 8  | loss: 1.27105 | test_accuracy: 0.52234 |  0:00:08s\n",
      "epoch 9  | loss: 1.21104 | test_accuracy: 0.5244  |  0:00:09s\n",
      "epoch 10 | loss: 1.19415 | test_accuracy: 0.53416 |  0:00:10s\n",
      "epoch 11 | loss: 1.15461 | test_accuracy: 0.54854 |  0:00:11s\n",
      "epoch 12 | loss: 1.14604 | test_accuracy: 0.52953 |  0:00:12s\n",
      "epoch 13 | loss: 1.1248  | test_accuracy: 0.5434  |  0:00:13s\n",
      "epoch 14 | loss: 1.09207 | test_accuracy: 0.55573 |  0:00:14s\n",
      "epoch 15 | loss: 1.08169 | test_accuracy: 0.55573 |  0:00:16s\n",
      "epoch 16 | loss: 1.0836  | test_accuracy: 0.55521 |  0:00:17s\n",
      "epoch 17 | loss: 1.05932 | test_accuracy: 0.56343 |  0:00:18s\n",
      "epoch 18 | loss: 1.04661 | test_accuracy: 0.57062 |  0:00:19s\n",
      "epoch 19 | loss: 1.05318 | test_accuracy: 0.57268 |  0:00:20s\n",
      "epoch 20 | loss: 1.03189 | test_accuracy: 0.5773  |  0:00:21s\n",
      "epoch 21 | loss: 1.02816 | test_accuracy: 0.5773  |  0:00:22s\n",
      "epoch 22 | loss: 1.01753 | test_accuracy: 0.57935 |  0:00:24s\n",
      "epoch 23 | loss: 1.01861 | test_accuracy: 0.57422 |  0:00:25s\n",
      "epoch 24 | loss: 1.00049 | test_accuracy: 0.5624  |  0:00:25s\n",
      "epoch 25 | loss: 1.00667 | test_accuracy: 0.58449 |  0:00:27s\n",
      "epoch 26 | loss: 0.99921 | test_accuracy: 0.57216 |  0:00:28s\n",
      "epoch 27 | loss: 0.99213 | test_accuracy: 0.58808 |  0:00:29s\n",
      "epoch 28 | loss: 0.98799 | test_accuracy: 0.58911 |  0:00:30s\n",
      "epoch 29 | loss: 0.9749  | test_accuracy: 0.59887 |  0:00:31s\n",
      "epoch 30 | loss: 0.97289 | test_accuracy: 0.59476 |  0:00:31s\n",
      "epoch 31 | loss: 0.9844  | test_accuracy: 0.57987 |  0:00:32s\n",
      "epoch 32 | loss: 0.98122 | test_accuracy: 0.5963  |  0:00:33s\n",
      "epoch 33 | loss: 0.97263 | test_accuracy: 0.58911 |  0:00:34s\n",
      "epoch 34 | loss: 0.9793  | test_accuracy: 0.58192 |  0:00:35s\n",
      "epoch 35 | loss: 0.97026 | test_accuracy: 0.59373 |  0:00:36s\n",
      "epoch 36 | loss: 0.96503 | test_accuracy: 0.59836 |  0:00:37s\n",
      "epoch 37 | loss: 0.97051 | test_accuracy: 0.60195 |  0:00:38s\n",
      "epoch 38 | loss: 0.97348 | test_accuracy: 0.60503 |  0:00:39s\n",
      "epoch 39 | loss: 0.97158 | test_accuracy: 0.6076  |  0:00:41s\n",
      "epoch 40 | loss: 0.96699 | test_accuracy: 0.59887 |  0:00:42s\n",
      "epoch 41 | loss: 0.96139 | test_accuracy: 0.60092 |  0:00:43s\n",
      "epoch 42 | loss: 0.96218 | test_accuracy: 0.60555 |  0:00:44s\n",
      "epoch 43 | loss: 0.95719 | test_accuracy: 0.61274 |  0:00:45s\n",
      "epoch 44 | loss: 0.96176 | test_accuracy: 0.6076  |  0:00:46s\n",
      "epoch 45 | loss: 0.9576  | test_accuracy: 0.5963  |  0:00:48s\n",
      "epoch 46 | loss: 0.95016 | test_accuracy: 0.59938 |  0:00:49s\n",
      "epoch 47 | loss: 0.95556 | test_accuracy: 0.59065 |  0:00:50s\n",
      "epoch 48 | loss: 0.95441 | test_accuracy: 0.59784 |  0:00:51s\n",
      "epoch 49 | loss: 0.94721 | test_accuracy: 0.58295 |  0:00:51s\n",
      "epoch 50 | loss: 0.95268 | test_accuracy: 0.60041 |  0:00:52s\n",
      "epoch 51 | loss: 0.95052 | test_accuracy: 0.61325 |  0:00:53s\n",
      "epoch 52 | loss: 0.94903 | test_accuracy: 0.59938 |  0:00:54s\n",
      "epoch 53 | loss: 0.94897 | test_accuracy: 0.59527 |  0:00:55s\n",
      "epoch 54 | loss: 0.94844 | test_accuracy: 0.60606 |  0:00:56s\n",
      "epoch 55 | loss: 0.95882 | test_accuracy: 0.60144 |  0:00:57s\n",
      "epoch 56 | loss: 0.94887 | test_accuracy: 0.58757 |  0:00:58s\n",
      "epoch 57 | loss: 0.94974 | test_accuracy: 0.58552 |  0:00:59s\n",
      "epoch 58 | loss: 0.95209 | test_accuracy: 0.59168 |  0:01:00s\n",
      "epoch 59 | loss: 0.95261 | test_accuracy: 0.59476 |  0:01:01s\n",
      "epoch 60 | loss: 0.93884 | test_accuracy: 0.57987 |  0:01:02s\n",
      "epoch 61 | loss: 0.93921 | test_accuracy: 0.59014 |  0:01:03s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_test_accuracy = 0.61325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:45:19,910] Trial 0 finished with value: 0.613251155624037 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 9, 'gamma': 1.3429979017016884, 'lambda_sparse': 0.003182144273075528, 'lr': 0.003975430742925044, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.613251155624037.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.1052  | test_accuracy: 0.42167 |  0:00:00s\n",
      "epoch 1  | loss: 1.39028 | test_accuracy: 0.51618 |  0:00:01s\n",
      "epoch 2  | loss: 1.22504 | test_accuracy: 0.51464 |  0:00:02s\n",
      "epoch 3  | loss: 1.12147 | test_accuracy: 0.5511  |  0:00:03s\n",
      "epoch 4  | loss: 1.08375 | test_accuracy: 0.55984 |  0:00:03s\n",
      "epoch 5  | loss: 1.05008 | test_accuracy: 0.54854 |  0:00:04s\n",
      "epoch 6  | loss: 1.04313 | test_accuracy: 0.55778 |  0:00:05s\n",
      "epoch 7  | loss: 1.0373  | test_accuracy: 0.5773  |  0:00:05s\n",
      "epoch 8  | loss: 1.00806 | test_accuracy: 0.55008 |  0:00:06s\n",
      "epoch 9  | loss: 1.00719 | test_accuracy: 0.57524 |  0:00:07s\n",
      "epoch 10 | loss: 0.98452 | test_accuracy: 0.54289 |  0:00:08s\n",
      "epoch 11 | loss: 0.99153 | test_accuracy: 0.5773  |  0:00:09s\n",
      "epoch 12 | loss: 0.96128 | test_accuracy: 0.60555 |  0:00:09s\n",
      "epoch 13 | loss: 0.95446 | test_accuracy: 0.58603 |  0:00:10s\n",
      "epoch 14 | loss: 0.94248 | test_accuracy: 0.58243 |  0:00:11s\n",
      "epoch 15 | loss: 0.93558 | test_accuracy: 0.585   |  0:00:12s\n",
      "epoch 16 | loss: 0.94812 | test_accuracy: 0.58757 |  0:00:12s\n",
      "epoch 17 | loss: 0.93343 | test_accuracy: 0.57576 |  0:00:13s\n",
      "epoch 18 | loss: 0.94013 | test_accuracy: 0.58243 |  0:00:14s\n",
      "epoch 19 | loss: 0.92664 | test_accuracy: 0.58295 |  0:00:15s\n",
      "epoch 20 | loss: 0.92909 | test_accuracy: 0.58963 |  0:00:16s\n",
      "epoch 21 | loss: 0.91481 | test_accuracy: 0.59219 |  0:00:17s\n",
      "epoch 22 | loss: 0.91911 | test_accuracy: 0.59784 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_test_accuracy = 0.60555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:45:38,137] Trial 1 finished with value: 0.6055469953775039 and parameters: {'n_d': 32, 'n_a': 16, 'n_steps': 7, 'gamma': 1.568276734932656, 'lambda_sparse': 7.59318141904412e-05, 'lr': 0.00927748477385235, 'mask_type': 'entmax', 'batch_size': 1024, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.613251155624037.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.02842 | test_accuracy: 0.38932 |  0:00:01s\n",
      "epoch 1  | loss: 1.6563  | test_accuracy: 0.44325 |  0:00:02s\n",
      "epoch 2  | loss: 1.45365 | test_accuracy: 0.46944 |  0:00:03s\n",
      "epoch 3  | loss: 1.34573 | test_accuracy: 0.47252 |  0:00:03s\n",
      "epoch 4  | loss: 1.27511 | test_accuracy: 0.49872 |  0:00:04s\n",
      "epoch 5  | loss: 1.23211 | test_accuracy: 0.51669 |  0:00:05s\n",
      "epoch 6  | loss: 1.19262 | test_accuracy: 0.5131  |  0:00:06s\n",
      "epoch 7  | loss: 1.15741 | test_accuracy: 0.52799 |  0:00:07s\n",
      "epoch 8  | loss: 1.13778 | test_accuracy: 0.52748 |  0:00:08s\n",
      "epoch 9  | loss: 1.11919 | test_accuracy: 0.52902 |  0:00:09s\n",
      "epoch 10 | loss: 1.09047 | test_accuracy: 0.52131 |  0:00:10s\n",
      "epoch 11 | loss: 1.07922 | test_accuracy: 0.54083 |  0:00:10s\n",
      "epoch 12 | loss: 1.07395 | test_accuracy: 0.55419 |  0:00:11s\n",
      "epoch 13 | loss: 1.06578 | test_accuracy: 0.53929 |  0:00:12s\n",
      "epoch 14 | loss: 1.06069 | test_accuracy: 0.54597 |  0:00:13s\n",
      "epoch 15 | loss: 1.05795 | test_accuracy: 0.55316 |  0:00:14s\n",
      "epoch 16 | loss: 1.04835 | test_accuracy: 0.56138 |  0:00:15s\n",
      "epoch 17 | loss: 1.03586 | test_accuracy: 0.57114 |  0:00:15s\n",
      "epoch 18 | loss: 1.02525 | test_accuracy: 0.5773  |  0:00:16s\n",
      "epoch 19 | loss: 1.01799 | test_accuracy: 0.57524 |  0:00:17s\n",
      "epoch 20 | loss: 1.02046 | test_accuracy: 0.57473 |  0:00:18s\n",
      "epoch 21 | loss: 1.01885 | test_accuracy: 0.56805 |  0:00:19s\n",
      "epoch 22 | loss: 1.01046 | test_accuracy: 0.56959 |  0:00:20s\n",
      "epoch 23 | loss: 1.00863 | test_accuracy: 0.58757 |  0:00:20s\n",
      "epoch 24 | loss: 1.00557 | test_accuracy: 0.58552 |  0:00:21s\n",
      "epoch 25 | loss: 0.99178 | test_accuracy: 0.57833 |  0:00:22s\n",
      "epoch 26 | loss: 0.99307 | test_accuracy: 0.57987 |  0:00:23s\n",
      "epoch 27 | loss: 0.98606 | test_accuracy: 0.58141 |  0:00:24s\n",
      "epoch 28 | loss: 0.9875  | test_accuracy: 0.57833 |  0:00:25s\n",
      "epoch 29 | loss: 0.99507 | test_accuracy: 0.59373 |  0:00:26s\n",
      "epoch 30 | loss: 0.99072 | test_accuracy: 0.59065 |  0:00:26s\n",
      "epoch 31 | loss: 0.99081 | test_accuracy: 0.58552 |  0:00:27s\n",
      "epoch 32 | loss: 0.98434 | test_accuracy: 0.5963  |  0:00:28s\n",
      "epoch 33 | loss: 0.97657 | test_accuracy: 0.59938 |  0:00:29s\n",
      "epoch 34 | loss: 0.97356 | test_accuracy: 0.58603 |  0:00:30s\n",
      "epoch 35 | loss: 0.97306 | test_accuracy: 0.58808 |  0:00:31s\n",
      "epoch 36 | loss: 0.96497 | test_accuracy: 0.59476 |  0:00:32s\n",
      "epoch 37 | loss: 0.95652 | test_accuracy: 0.59065 |  0:00:33s\n",
      "epoch 38 | loss: 0.95358 | test_accuracy: 0.60092 |  0:00:33s\n",
      "epoch 39 | loss: 0.95592 | test_accuracy: 0.59476 |  0:00:34s\n",
      "epoch 40 | loss: 0.95062 | test_accuracy: 0.60401 |  0:00:35s\n",
      "epoch 41 | loss: 0.95793 | test_accuracy: 0.60195 |  0:00:36s\n",
      "epoch 42 | loss: 0.95488 | test_accuracy: 0.5999  |  0:00:37s\n",
      "epoch 43 | loss: 0.95094 | test_accuracy: 0.59784 |  0:00:38s\n",
      "epoch 44 | loss: 0.95607 | test_accuracy: 0.59887 |  0:00:39s\n",
      "epoch 45 | loss: 0.95936 | test_accuracy: 0.59219 |  0:00:40s\n",
      "epoch 46 | loss: 0.95845 | test_accuracy: 0.58346 |  0:00:41s\n",
      "epoch 47 | loss: 0.96063 | test_accuracy: 0.59682 |  0:00:42s\n",
      "epoch 48 | loss: 0.96603 | test_accuracy: 0.5963  |  0:00:43s\n",
      "epoch 49 | loss: 0.96281 | test_accuracy: 0.59271 |  0:00:44s\n",
      "epoch 50 | loss: 0.9556  | test_accuracy: 0.58757 |  0:00:45s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_test_accuracy = 0.60401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:46:23,922] Trial 2 finished with value: 0.6040061633281972 and parameters: {'n_d': 8, 'n_a': 32, 'n_steps': 7, 'gamma': 1.8607772487290903, 'lambda_sparse': 0.0025792299828894206, 'lr': 0.002192154705788445, 'mask_type': 'sparsemax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.613251155624037.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 7.25808 | test_accuracy: 0.01952 |  0:00:00s\n",
      "epoch 1  | loss: 7.09081 | test_accuracy: 0.01952 |  0:00:01s\n",
      "epoch 2  | loss: 6.99961 | test_accuracy: 0.01798 |  0:00:02s\n",
      "epoch 3  | loss: 6.86561 | test_accuracy: 0.02054 |  0:00:02s\n",
      "epoch 4  | loss: 6.75396 | test_accuracy: 0.02054 |  0:00:03s\n",
      "epoch 5  | loss: 6.62566 | test_accuracy: 0.0226  |  0:00:04s\n",
      "epoch 6  | loss: 6.54022 | test_accuracy: 0.02363 |  0:00:05s\n",
      "epoch 7  | loss: 6.3799  | test_accuracy: 0.02517 |  0:00:05s\n",
      "epoch 8  | loss: 6.29695 | test_accuracy: 0.02619 |  0:00:06s\n",
      "epoch 9  | loss: 6.2361  | test_accuracy: 0.02414 |  0:00:07s\n",
      "epoch 10 | loss: 6.07023 | test_accuracy: 0.02876 |  0:00:08s\n",
      "epoch 11 | loss: 5.98608 | test_accuracy: 0.02979 |  0:00:09s\n",
      "epoch 12 | loss: 5.93855 | test_accuracy: 0.0303  |  0:00:09s\n",
      "epoch 13 | loss: 5.84523 | test_accuracy: 0.03236 |  0:00:10s\n",
      "epoch 14 | loss: 5.79349 | test_accuracy: 0.03236 |  0:00:11s\n",
      "epoch 15 | loss: 5.74214 | test_accuracy: 0.03749 |  0:00:11s\n",
      "epoch 16 | loss: 5.62119 | test_accuracy: 0.0416  |  0:00:12s\n",
      "epoch 17 | loss: 5.57896 | test_accuracy: 0.04006 |  0:00:13s\n",
      "epoch 18 | loss: 5.52047 | test_accuracy: 0.04109 |  0:00:14s\n",
      "epoch 19 | loss: 5.45419 | test_accuracy: 0.04468 |  0:00:14s\n",
      "epoch 20 | loss: 5.38288 | test_accuracy: 0.05033 |  0:00:15s\n",
      "epoch 21 | loss: 5.28731 | test_accuracy: 0.0565  |  0:00:16s\n",
      "epoch 22 | loss: 5.22133 | test_accuracy: 0.06061 |  0:00:17s\n",
      "epoch 23 | loss: 5.18768 | test_accuracy: 0.05752 |  0:00:18s\n",
      "epoch 24 | loss: 5.08951 | test_accuracy: 0.05958 |  0:00:18s\n",
      "epoch 25 | loss: 5.05415 | test_accuracy: 0.06163 |  0:00:19s\n",
      "epoch 26 | loss: 4.94424 | test_accuracy: 0.07242 |  0:00:21s\n",
      "epoch 27 | loss: 4.91024 | test_accuracy: 0.08372 |  0:00:22s\n",
      "epoch 28 | loss: 4.81805 | test_accuracy: 0.08526 |  0:00:23s\n",
      "epoch 29 | loss: 4.76457 | test_accuracy: 0.09296 |  0:00:24s\n",
      "epoch 30 | loss: 4.67012 | test_accuracy: 0.10067 |  0:00:25s\n",
      "epoch 31 | loss: 4.59284 | test_accuracy: 0.11094 |  0:00:25s\n",
      "epoch 32 | loss: 4.53655 | test_accuracy: 0.12789 |  0:00:26s\n",
      "epoch 33 | loss: 4.45194 | test_accuracy: 0.13405 |  0:00:27s\n",
      "epoch 34 | loss: 4.40112 | test_accuracy: 0.13097 |  0:00:28s\n",
      "epoch 35 | loss: 4.35851 | test_accuracy: 0.14535 |  0:00:28s\n",
      "epoch 36 | loss: 4.3184  | test_accuracy: 0.1546  |  0:00:29s\n",
      "epoch 37 | loss: 4.24257 | test_accuracy: 0.16487 |  0:00:30s\n",
      "epoch 38 | loss: 4.1978  | test_accuracy: 0.17514 |  0:00:30s\n",
      "epoch 39 | loss: 4.13534 | test_accuracy: 0.18028 |  0:00:31s\n",
      "epoch 40 | loss: 4.06652 | test_accuracy: 0.18028 |  0:00:32s\n",
      "epoch 41 | loss: 4.04081 | test_accuracy: 0.19004 |  0:00:32s\n",
      "epoch 42 | loss: 3.99994 | test_accuracy: 0.19414 |  0:00:33s\n",
      "epoch 43 | loss: 3.95219 | test_accuracy: 0.20288 |  0:00:34s\n",
      "epoch 44 | loss: 3.86026 | test_accuracy: 0.2075  |  0:00:34s\n",
      "epoch 45 | loss: 3.83706 | test_accuracy: 0.20955 |  0:00:35s\n",
      "epoch 46 | loss: 3.75288 | test_accuracy: 0.22188 |  0:00:36s\n",
      "epoch 47 | loss: 3.69903 | test_accuracy: 0.23112 |  0:00:36s\n",
      "epoch 48 | loss: 3.64725 | test_accuracy: 0.2301  |  0:00:37s\n",
      "epoch 49 | loss: 3.58458 | test_accuracy: 0.23832 |  0:00:38s\n",
      "epoch 50 | loss: 3.52221 | test_accuracy: 0.25989 |  0:00:39s\n",
      "epoch 51 | loss: 3.47909 | test_accuracy: 0.25475 |  0:00:39s\n",
      "epoch 52 | loss: 3.425   | test_accuracy: 0.2604  |  0:00:40s\n",
      "epoch 53 | loss: 3.41117 | test_accuracy: 0.26451 |  0:00:41s\n",
      "epoch 54 | loss: 3.37213 | test_accuracy: 0.27221 |  0:00:41s\n",
      "epoch 55 | loss: 3.35813 | test_accuracy: 0.27324 |  0:00:42s\n",
      "epoch 56 | loss: 3.30624 | test_accuracy: 0.28043 |  0:00:43s\n",
      "epoch 57 | loss: 3.27503 | test_accuracy: 0.28249 |  0:00:43s\n",
      "epoch 58 | loss: 3.22249 | test_accuracy: 0.27119 |  0:00:44s\n",
      "epoch 59 | loss: 3.20467 | test_accuracy: 0.28659 |  0:00:45s\n",
      "epoch 60 | loss: 3.16065 | test_accuracy: 0.28608 |  0:00:45s\n",
      "epoch 61 | loss: 3.12248 | test_accuracy: 0.28711 |  0:00:46s\n",
      "epoch 62 | loss: 3.06596 | test_accuracy: 0.2943  |  0:00:47s\n",
      "epoch 63 | loss: 3.02698 | test_accuracy: 0.29635 |  0:00:47s\n",
      "epoch 64 | loss: 2.98158 | test_accuracy: 0.29687 |  0:00:48s\n",
      "epoch 65 | loss: 2.95317 | test_accuracy: 0.30252 |  0:00:49s\n",
      "epoch 66 | loss: 2.89607 | test_accuracy: 0.32101 |  0:00:49s\n",
      "epoch 67 | loss: 2.85105 | test_accuracy: 0.30252 |  0:00:50s\n",
      "epoch 68 | loss: 2.85184 | test_accuracy: 0.30765 |  0:00:51s\n",
      "epoch 69 | loss: 2.81801 | test_accuracy: 0.31587 |  0:00:51s\n",
      "epoch 70 | loss: 2.78035 | test_accuracy: 0.31073 |  0:00:52s\n",
      "epoch 71 | loss: 2.75543 | test_accuracy: 0.3169  |  0:00:53s\n",
      "epoch 72 | loss: 2.72135 | test_accuracy: 0.31587 |  0:00:53s\n",
      "epoch 73 | loss: 2.68141 | test_accuracy: 0.31844 |  0:00:54s\n",
      "epoch 74 | loss: 2.63258 | test_accuracy: 0.3246  |  0:00:55s\n",
      "epoch 75 | loss: 2.60489 | test_accuracy: 0.32563 |  0:00:56s\n",
      "epoch 76 | loss: 2.55455 | test_accuracy: 0.33077 |  0:00:57s\n",
      "epoch 77 | loss: 2.54118 | test_accuracy: 0.33744 |  0:00:57s\n",
      "epoch 78 | loss: 2.48509 | test_accuracy: 0.34463 |  0:00:58s\n",
      "epoch 79 | loss: 2.47053 | test_accuracy: 0.34977 |  0:00:59s\n",
      "epoch 80 | loss: 2.46313 | test_accuracy: 0.34258 |  0:00:59s\n",
      "epoch 81 | loss: 2.40724 | test_accuracy: 0.34155 |  0:01:00s\n",
      "epoch 82 | loss: 2.4009  | test_accuracy: 0.34566 |  0:01:01s\n",
      "epoch 83 | loss: 2.37825 | test_accuracy: 0.35285 |  0:01:01s\n",
      "epoch 84 | loss: 2.33558 | test_accuracy: 0.3549  |  0:01:02s\n",
      "epoch 85 | loss: 2.29752 | test_accuracy: 0.35285 |  0:01:03s\n",
      "epoch 86 | loss: 2.26938 | test_accuracy: 0.35747 |  0:01:03s\n",
      "epoch 87 | loss: 2.25141 | test_accuracy: 0.36107 |  0:01:04s\n",
      "epoch 88 | loss: 2.23551 | test_accuracy: 0.36261 |  0:01:05s\n",
      "epoch 89 | loss: 2.19304 | test_accuracy: 0.36723 |  0:01:06s\n",
      "epoch 90 | loss: 2.16465 | test_accuracy: 0.36877 |  0:01:06s\n",
      "epoch 91 | loss: 2.13517 | test_accuracy: 0.36415 |  0:01:07s\n",
      "epoch 92 | loss: 2.12338 | test_accuracy: 0.36518 |  0:01:08s\n",
      "epoch 93 | loss: 2.09156 | test_accuracy: 0.37339 |  0:01:08s\n",
      "epoch 94 | loss: 2.07692 | test_accuracy: 0.37237 |  0:01:09s\n",
      "epoch 95 | loss: 2.08862 | test_accuracy: 0.38213 |  0:01:10s\n",
      "epoch 96 | loss: 2.02479 | test_accuracy: 0.39137 |  0:01:10s\n",
      "epoch 97 | loss: 2.0065  | test_accuracy: 0.37853 |  0:01:11s\n",
      "epoch 98 | loss: 1.98747 | test_accuracy: 0.39034 |  0:01:12s\n",
      "epoch 99 | loss: 1.98319 | test_accuracy: 0.38161 |  0:01:12s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_test_accuracy = 0.39137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:47:37,077] Trial 3 finished with value: 0.3913713405238829 and parameters: {'n_d': 16, 'n_a': 8, 'n_steps': 7, 'gamma': 1.8069531470309854, 'lambda_sparse': 0.004415262522089323, 'lr': 0.00020682207554267921, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.613251155624037.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.57054 | test_accuracy: 0.18182 |  0:00:00s\n",
      "epoch 1  | loss: 3.54874 | test_accuracy: 0.17565 |  0:00:01s\n",
      "epoch 2  | loss: 3.48809 | test_accuracy: 0.18644 |  0:00:02s\n",
      "epoch 3  | loss: 3.42989 | test_accuracy: 0.17668 |  0:00:03s\n",
      "epoch 4  | loss: 3.45117 | test_accuracy: 0.17925 |  0:00:03s\n",
      "epoch 5  | loss: 3.37065 | test_accuracy: 0.18593 |  0:00:04s\n",
      "epoch 6  | loss: 3.34989 | test_accuracy: 0.18644 |  0:00:05s\n",
      "epoch 7  | loss: 3.31013 | test_accuracy: 0.1926  |  0:00:06s\n",
      "epoch 8  | loss: 3.29985 | test_accuracy: 0.1962  |  0:00:06s\n",
      "epoch 9  | loss: 3.25704 | test_accuracy: 0.19979 |  0:00:07s\n",
      "epoch 10 | loss: 3.20538 | test_accuracy: 0.20185 |  0:00:08s\n",
      "epoch 11 | loss: 3.15413 | test_accuracy: 0.20339 |  0:00:09s\n",
      "epoch 12 | loss: 3.14258 | test_accuracy: 0.20647 |  0:00:10s\n",
      "epoch 13 | loss: 3.10514 | test_accuracy: 0.21726 |  0:00:10s\n",
      "epoch 14 | loss: 3.07129 | test_accuracy: 0.21777 |  0:00:11s\n",
      "epoch 15 | loss: 3.02763 | test_accuracy: 0.22239 |  0:00:12s\n",
      "epoch 16 | loss: 3.03641 | test_accuracy: 0.22188 |  0:00:13s\n",
      "epoch 17 | loss: 2.97605 | test_accuracy: 0.22085 |  0:00:13s\n",
      "epoch 18 | loss: 2.95715 | test_accuracy: 0.22445 |  0:00:14s\n",
      "epoch 19 | loss: 2.9287  | test_accuracy: 0.23164 |  0:00:15s\n",
      "epoch 20 | loss: 2.95061 | test_accuracy: 0.23729 |  0:00:16s\n",
      "epoch 21 | loss: 2.88791 | test_accuracy: 0.23677 |  0:00:16s\n",
      "epoch 22 | loss: 2.85785 | test_accuracy: 0.24294 |  0:00:17s\n",
      "epoch 23 | loss: 2.82843 | test_accuracy: 0.23986 |  0:00:18s\n",
      "epoch 24 | loss: 2.79883 | test_accuracy: 0.25372 |  0:00:19s\n",
      "epoch 25 | loss: 2.78103 | test_accuracy: 0.26143 |  0:00:20s\n",
      "epoch 26 | loss: 2.77297 | test_accuracy: 0.25681 |  0:00:20s\n",
      "epoch 27 | loss: 2.69737 | test_accuracy: 0.26502 |  0:00:21s\n",
      "epoch 28 | loss: 2.70124 | test_accuracy: 0.2681  |  0:00:22s\n",
      "epoch 29 | loss: 2.65607 | test_accuracy: 0.27324 |  0:00:23s\n",
      "epoch 30 | loss: 2.62604 | test_accuracy: 0.27992 |  0:00:23s\n",
      "epoch 31 | loss: 2.61708 | test_accuracy: 0.27632 |  0:00:24s\n",
      "epoch 32 | loss: 2.59232 | test_accuracy: 0.28711 |  0:00:25s\n",
      "epoch 33 | loss: 2.55611 | test_accuracy: 0.28659 |  0:00:26s\n",
      "epoch 34 | loss: 2.5284  | test_accuracy: 0.29327 |  0:00:26s\n",
      "epoch 35 | loss: 2.47774 | test_accuracy: 0.29584 |  0:00:27s\n",
      "epoch 36 | loss: 2.47602 | test_accuracy: 0.29841 |  0:00:28s\n",
      "epoch 37 | loss: 2.43171 | test_accuracy: 0.29892 |  0:00:29s\n",
      "epoch 38 | loss: 2.4306  | test_accuracy: 0.31433 |  0:00:30s\n",
      "epoch 39 | loss: 2.39424 | test_accuracy: 0.31587 |  0:00:30s\n",
      "epoch 40 | loss: 2.35268 | test_accuracy: 0.31998 |  0:00:31s\n",
      "epoch 41 | loss: 2.33695 | test_accuracy: 0.32203 |  0:00:32s\n",
      "epoch 42 | loss: 2.33254 | test_accuracy: 0.32563 |  0:00:33s\n",
      "epoch 43 | loss: 2.28457 | test_accuracy: 0.33025 |  0:00:33s\n",
      "epoch 44 | loss: 2.29384 | test_accuracy: 0.34052 |  0:00:34s\n",
      "epoch 45 | loss: 2.22786 | test_accuracy: 0.34155 |  0:00:35s\n",
      "epoch 46 | loss: 2.24339 | test_accuracy: 0.34052 |  0:00:36s\n",
      "epoch 47 | loss: 2.20258 | test_accuracy: 0.35028 |  0:00:36s\n",
      "epoch 48 | loss: 2.14874 | test_accuracy: 0.35182 |  0:00:37s\n",
      "epoch 49 | loss: 2.1632  | test_accuracy: 0.35799 |  0:00:38s\n",
      "epoch 50 | loss: 2.13751 | test_accuracy: 0.36518 |  0:00:39s\n",
      "epoch 51 | loss: 2.11368 | test_accuracy: 0.37083 |  0:00:40s\n",
      "epoch 52 | loss: 2.09154 | test_accuracy: 0.37237 |  0:00:40s\n",
      "epoch 53 | loss: 2.10789 | test_accuracy: 0.37802 |  0:00:41s\n",
      "epoch 54 | loss: 2.06524 | test_accuracy: 0.37442 |  0:00:42s\n",
      "epoch 55 | loss: 2.05215 | test_accuracy: 0.38624 |  0:00:43s\n",
      "epoch 56 | loss: 2.06111 | test_accuracy: 0.38572 |  0:00:43s\n",
      "epoch 57 | loss: 2.02999 | test_accuracy: 0.39599 |  0:00:44s\n",
      "epoch 58 | loss: 2.02336 | test_accuracy: 0.39343 |  0:00:45s\n",
      "epoch 59 | loss: 1.97348 | test_accuracy: 0.39034 |  0:00:46s\n",
      "epoch 60 | loss: 1.98196 | test_accuracy: 0.39805 |  0:00:47s\n",
      "epoch 61 | loss: 1.96115 | test_accuracy: 0.40575 |  0:00:47s\n",
      "epoch 62 | loss: 1.97061 | test_accuracy: 0.40832 |  0:00:48s\n",
      "epoch 63 | loss: 1.93989 | test_accuracy: 0.415   |  0:00:49s\n",
      "epoch 64 | loss: 1.92674 | test_accuracy: 0.40935 |  0:00:50s\n",
      "epoch 65 | loss: 1.91597 | test_accuracy: 0.4227  |  0:00:50s\n",
      "epoch 66 | loss: 1.90283 | test_accuracy: 0.42732 |  0:00:51s\n",
      "epoch 67 | loss: 1.87883 | test_accuracy: 0.42732 |  0:00:52s\n",
      "epoch 68 | loss: 1.85784 | test_accuracy: 0.43451 |  0:00:53s\n",
      "epoch 69 | loss: 1.84224 | test_accuracy: 0.43092 |  0:00:54s\n",
      "epoch 70 | loss: 1.83984 | test_accuracy: 0.4376  |  0:00:54s\n",
      "epoch 71 | loss: 1.83473 | test_accuracy: 0.44119 |  0:00:55s\n",
      "epoch 72 | loss: 1.82266 | test_accuracy: 0.44119 |  0:00:56s\n",
      "epoch 73 | loss: 1.79604 | test_accuracy: 0.44992 |  0:00:57s\n",
      "epoch 74 | loss: 1.8024  | test_accuracy: 0.45455 |  0:00:58s\n",
      "epoch 75 | loss: 1.79287 | test_accuracy: 0.44633 |  0:00:58s\n",
      "epoch 76 | loss: 1.78687 | test_accuracy: 0.44273 |  0:00:59s\n",
      "epoch 77 | loss: 1.78109 | test_accuracy: 0.45352 |  0:01:00s\n",
      "epoch 78 | loss: 1.76317 | test_accuracy: 0.45044 |  0:01:01s\n",
      "epoch 79 | loss: 1.77118 | test_accuracy: 0.45146 |  0:01:01s\n",
      "epoch 80 | loss: 1.74721 | test_accuracy: 0.46687 |  0:01:02s\n",
      "epoch 81 | loss: 1.74206 | test_accuracy: 0.45146 |  0:01:03s\n",
      "epoch 82 | loss: 1.72859 | test_accuracy: 0.4602  |  0:01:04s\n",
      "epoch 83 | loss: 1.71364 | test_accuracy: 0.45814 |  0:01:04s\n",
      "epoch 84 | loss: 1.70567 | test_accuracy: 0.46276 |  0:01:05s\n",
      "epoch 85 | loss: 1.70679 | test_accuracy: 0.45403 |  0:01:06s\n",
      "epoch 86 | loss: 1.67107 | test_accuracy: 0.45352 |  0:01:07s\n",
      "epoch 87 | loss: 1.6747  | test_accuracy: 0.4453  |  0:01:08s\n",
      "epoch 88 | loss: 1.68739 | test_accuracy: 0.4643  |  0:01:08s\n",
      "epoch 89 | loss: 1.64813 | test_accuracy: 0.453   |  0:01:09s\n",
      "epoch 90 | loss: 1.65378 | test_accuracy: 0.46328 |  0:01:10s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 80 and best_test_accuracy = 0.46687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:48:47,766] Trial 4 finished with value: 0.46687211093990755 and parameters: {'n_d': 8, 'n_a': 32, 'n_steps': 8, 'gamma': 1.273613665191232, 'lambda_sparse': 0.00409002309699419, 'lr': 0.00012516748074582954, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.613251155624037.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.60911 | test_accuracy: 0.19055 |  0:00:00s\n",
      "epoch 1  | loss: 3.52392 | test_accuracy: 0.19004 |  0:00:00s\n",
      "epoch 2  | loss: 3.46058 | test_accuracy: 0.20955 |  0:00:01s\n",
      "epoch 3  | loss: 3.39284 | test_accuracy: 0.21983 |  0:00:02s\n",
      "epoch 4  | loss: 3.32767 | test_accuracy: 0.2265  |  0:00:02s\n",
      "epoch 5  | loss: 3.28721 | test_accuracy: 0.22445 |  0:00:02s\n",
      "epoch 6  | loss: 3.21613 | test_accuracy: 0.21983 |  0:00:03s\n",
      "epoch 7  | loss: 3.13447 | test_accuracy: 0.22137 |  0:00:03s\n",
      "epoch 8  | loss: 3.05155 | test_accuracy: 0.2301  |  0:00:04s\n",
      "epoch 9  | loss: 3.0049  | test_accuracy: 0.23677 |  0:00:04s\n",
      "epoch 10 | loss: 2.94751 | test_accuracy: 0.23729 |  0:00:05s\n",
      "epoch 11 | loss: 2.86821 | test_accuracy: 0.24345 |  0:00:05s\n",
      "epoch 12 | loss: 2.78009 | test_accuracy: 0.24807 |  0:00:06s\n",
      "epoch 13 | loss: 2.74905 | test_accuracy: 0.25424 |  0:00:06s\n",
      "epoch 14 | loss: 2.70195 | test_accuracy: 0.25989 |  0:00:07s\n",
      "epoch 15 | loss: 2.64822 | test_accuracy: 0.25937 |  0:00:07s\n",
      "epoch 16 | loss: 2.58754 | test_accuracy: 0.26297 |  0:00:08s\n",
      "epoch 17 | loss: 2.52063 | test_accuracy: 0.27016 |  0:00:08s\n",
      "epoch 18 | loss: 2.45796 | test_accuracy: 0.28249 |  0:00:09s\n",
      "epoch 19 | loss: 2.39209 | test_accuracy: 0.29327 |  0:00:09s\n",
      "epoch 20 | loss: 2.35641 | test_accuracy: 0.29379 |  0:00:09s\n",
      "epoch 21 | loss: 2.31086 | test_accuracy: 0.30252 |  0:00:10s\n",
      "epoch 22 | loss: 2.26497 | test_accuracy: 0.30508 |  0:00:10s\n",
      "epoch 23 | loss: 2.20323 | test_accuracy: 0.32152 |  0:00:11s\n",
      "epoch 24 | loss: 2.1596  | test_accuracy: 0.33025 |  0:00:11s\n",
      "epoch 25 | loss: 2.12681 | test_accuracy: 0.33333 |  0:00:12s\n",
      "epoch 26 | loss: 2.06665 | test_accuracy: 0.33898 |  0:00:12s\n",
      "epoch 27 | loss: 2.03034 | test_accuracy: 0.35285 |  0:00:13s\n",
      "epoch 28 | loss: 2.00002 | test_accuracy: 0.36364 |  0:00:13s\n",
      "epoch 29 | loss: 1.96593 | test_accuracy: 0.37545 |  0:00:14s\n",
      "epoch 30 | loss: 1.94068 | test_accuracy: 0.37339 |  0:00:14s\n",
      "epoch 31 | loss: 1.88597 | test_accuracy: 0.38778 |  0:00:15s\n",
      "epoch 32 | loss: 1.84318 | test_accuracy: 0.39908 |  0:00:15s\n",
      "epoch 33 | loss: 1.80349 | test_accuracy: 0.40473 |  0:00:15s\n",
      "epoch 34 | loss: 1.76917 | test_accuracy: 0.41602 |  0:00:16s\n",
      "epoch 35 | loss: 1.73808 | test_accuracy: 0.41448 |  0:00:16s\n",
      "epoch 36 | loss: 1.72545 | test_accuracy: 0.41448 |  0:00:17s\n",
      "epoch 37 | loss: 1.68811 | test_accuracy: 0.42527 |  0:00:17s\n",
      "epoch 38 | loss: 1.66496 | test_accuracy: 0.43862 |  0:00:18s\n",
      "epoch 39 | loss: 1.63581 | test_accuracy: 0.44735 |  0:00:18s\n",
      "epoch 40 | loss: 1.59978 | test_accuracy: 0.4566  |  0:00:19s\n",
      "epoch 41 | loss: 1.57006 | test_accuracy: 0.45968 |  0:00:19s\n",
      "epoch 42 | loss: 1.5688  | test_accuracy: 0.47304 |  0:00:20s\n",
      "epoch 43 | loss: 1.54057 | test_accuracy: 0.47817 |  0:00:20s\n",
      "epoch 44 | loss: 1.52382 | test_accuracy: 0.48485 |  0:00:20s\n",
      "epoch 45 | loss: 1.50748 | test_accuracy: 0.48896 |  0:00:21s\n",
      "epoch 46 | loss: 1.4921  | test_accuracy: 0.49204 |  0:00:21s\n",
      "epoch 47 | loss: 1.47635 | test_accuracy: 0.49409 |  0:00:22s\n",
      "epoch 48 | loss: 1.46143 | test_accuracy: 0.5018  |  0:00:22s\n",
      "epoch 49 | loss: 1.43306 | test_accuracy: 0.50282 |  0:00:23s\n",
      "epoch 50 | loss: 1.42917 | test_accuracy: 0.5095  |  0:00:23s\n",
      "epoch 51 | loss: 1.41751 | test_accuracy: 0.51875 |  0:00:24s\n",
      "epoch 52 | loss: 1.39857 | test_accuracy: 0.52286 |  0:00:24s\n",
      "epoch 53 | loss: 1.38746 | test_accuracy: 0.52029 |  0:00:25s\n",
      "epoch 54 | loss: 1.36062 | test_accuracy: 0.53364 |  0:00:25s\n",
      "epoch 55 | loss: 1.35126 | test_accuracy: 0.53416 |  0:00:26s\n",
      "epoch 56 | loss: 1.34943 | test_accuracy: 0.53775 |  0:00:26s\n",
      "epoch 57 | loss: 1.33549 | test_accuracy: 0.53826 |  0:00:26s\n",
      "epoch 58 | loss: 1.31296 | test_accuracy: 0.54083 |  0:00:27s\n",
      "epoch 59 | loss: 1.31335 | test_accuracy: 0.5398  |  0:00:27s\n",
      "epoch 60 | loss: 1.30622 | test_accuracy: 0.54545 |  0:00:28s\n",
      "epoch 61 | loss: 1.29719 | test_accuracy: 0.55162 |  0:00:28s\n",
      "epoch 62 | loss: 1.29423 | test_accuracy: 0.54648 |  0:00:29s\n",
      "epoch 63 | loss: 1.27681 | test_accuracy: 0.54135 |  0:00:29s\n",
      "epoch 64 | loss: 1.26093 | test_accuracy: 0.53929 |  0:00:30s\n",
      "epoch 65 | loss: 1.26    | test_accuracy: 0.53775 |  0:00:30s\n",
      "epoch 66 | loss: 1.25169 | test_accuracy: 0.54597 |  0:00:31s\n",
      "epoch 67 | loss: 1.23776 | test_accuracy: 0.54443 |  0:00:31s\n",
      "epoch 68 | loss: 1.24295 | test_accuracy: 0.54289 |  0:00:31s\n",
      "epoch 69 | loss: 1.22109 | test_accuracy: 0.55213 |  0:00:32s\n",
      "epoch 70 | loss: 1.22953 | test_accuracy: 0.54597 |  0:00:32s\n",
      "epoch 71 | loss: 1.23005 | test_accuracy: 0.54751 |  0:00:33s\n",
      "epoch 72 | loss: 1.2089  | test_accuracy: 0.54494 |  0:00:33s\n",
      "epoch 73 | loss: 1.20014 | test_accuracy: 0.54391 |  0:00:34s\n",
      "epoch 74 | loss: 1.20188 | test_accuracy: 0.55059 |  0:00:34s\n",
      "epoch 75 | loss: 1.18577 | test_accuracy: 0.55008 |  0:00:35s\n",
      "epoch 76 | loss: 1.17712 | test_accuracy: 0.54597 |  0:00:35s\n",
      "epoch 77 | loss: 1.16993 | test_accuracy: 0.55213 |  0:00:35s\n",
      "epoch 78 | loss: 1.16326 | test_accuracy: 0.55008 |  0:00:36s\n",
      "epoch 79 | loss: 1.16756 | test_accuracy: 0.55573 |  0:00:36s\n",
      "epoch 80 | loss: 1.16097 | test_accuracy: 0.55727 |  0:00:37s\n",
      "epoch 81 | loss: 1.15708 | test_accuracy: 0.55778 |  0:00:37s\n",
      "epoch 82 | loss: 1.15138 | test_accuracy: 0.55778 |  0:00:38s\n",
      "epoch 83 | loss: 1.1472  | test_accuracy: 0.55881 |  0:00:38s\n",
      "epoch 84 | loss: 1.15615 | test_accuracy: 0.55881 |  0:00:39s\n",
      "epoch 85 | loss: 1.1348  | test_accuracy: 0.55984 |  0:00:39s\n",
      "epoch 86 | loss: 1.13535 | test_accuracy: 0.55932 |  0:00:39s\n",
      "epoch 87 | loss: 1.12665 | test_accuracy: 0.54854 |  0:00:40s\n",
      "epoch 88 | loss: 1.13558 | test_accuracy: 0.54854 |  0:00:40s\n",
      "epoch 89 | loss: 1.11948 | test_accuracy: 0.55932 |  0:00:41s\n",
      "epoch 90 | loss: 1.11534 | test_accuracy: 0.56497 |  0:00:41s\n",
      "epoch 91 | loss: 1.11686 | test_accuracy: 0.55265 |  0:00:42s\n",
      "epoch 92 | loss: 1.11436 | test_accuracy: 0.55624 |  0:00:42s\n",
      "epoch 93 | loss: 1.10436 | test_accuracy: 0.5547  |  0:00:43s\n",
      "epoch 94 | loss: 1.1161  | test_accuracy: 0.5547  |  0:00:43s\n",
      "epoch 95 | loss: 1.10051 | test_accuracy: 0.55829 |  0:00:44s\n",
      "epoch 96 | loss: 1.09562 | test_accuracy: 0.56086 |  0:00:44s\n",
      "epoch 97 | loss: 1.09401 | test_accuracy: 0.56446 |  0:00:45s\n",
      "epoch 98 | loss: 1.09001 | test_accuracy: 0.56446 |  0:00:45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:49:33,916] Trial 5 finished with value: 0.5649717514124294 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 5, 'gamma': 1.2133520798758486, 'lambda_sparse': 2.0679273420140793e-05, 'lr': 0.0001317624758562132, 'mask_type': 'sparsemax', 'batch_size': 512, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.613251155624037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99 | loss: 1.09481 | test_accuracy: 0.56446 |  0:00:45s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_test_accuracy = 0.56497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.67489 | test_accuracy: 0.18439 |  0:00:00s\n",
      "epoch 1  | loss: 3.5714  | test_accuracy: 0.19877 |  0:00:01s\n",
      "epoch 2  | loss: 3.52163 | test_accuracy: 0.20236 |  0:00:01s\n",
      "epoch 3  | loss: 3.44132 | test_accuracy: 0.19979 |  0:00:02s\n",
      "epoch 4  | loss: 3.35354 | test_accuracy: 0.20699 |  0:00:02s\n",
      "epoch 5  | loss: 3.32968 | test_accuracy: 0.20236 |  0:00:03s\n",
      "epoch 6  | loss: 3.25676 | test_accuracy: 0.20236 |  0:00:04s\n",
      "epoch 7  | loss: 3.22326 | test_accuracy: 0.21777 |  0:00:04s\n",
      "epoch 8  | loss: 3.1307  | test_accuracy: 0.22445 |  0:00:05s\n",
      "epoch 9  | loss: 3.06221 | test_accuracy: 0.2265  |  0:00:05s\n",
      "epoch 10 | loss: 3.00155 | test_accuracy: 0.23523 |  0:00:06s\n",
      "epoch 11 | loss: 2.91516 | test_accuracy: 0.23164 |  0:00:06s\n",
      "epoch 12 | loss: 2.87454 | test_accuracy: 0.24551 |  0:00:07s\n",
      "epoch 13 | loss: 2.81091 | test_accuracy: 0.24859 |  0:00:08s\n",
      "epoch 14 | loss: 2.74421 | test_accuracy: 0.25372 |  0:00:08s\n",
      "epoch 15 | loss: 2.68322 | test_accuracy: 0.25578 |  0:00:09s\n",
      "epoch 16 | loss: 2.58477 | test_accuracy: 0.26708 |  0:00:09s\n",
      "epoch 17 | loss: 2.54273 | test_accuracy: 0.27324 |  0:00:10s\n",
      "epoch 18 | loss: 2.48531 | test_accuracy: 0.27581 |  0:00:10s\n",
      "epoch 19 | loss: 2.43766 | test_accuracy: 0.28249 |  0:00:11s\n",
      "epoch 20 | loss: 2.39097 | test_accuracy: 0.28557 |  0:00:12s\n",
      "epoch 21 | loss: 2.31744 | test_accuracy: 0.29789 |  0:00:12s\n",
      "epoch 22 | loss: 2.29217 | test_accuracy: 0.30868 |  0:00:13s\n",
      "epoch 23 | loss: 2.24884 | test_accuracy: 0.30971 |  0:00:13s\n",
      "epoch 24 | loss: 2.193   | test_accuracy: 0.32255 |  0:00:14s\n",
      "epoch 25 | loss: 2.15574 | test_accuracy: 0.34001 |  0:00:14s\n",
      "epoch 26 | loss: 2.10111 | test_accuracy: 0.34566 |  0:00:15s\n",
      "epoch 27 | loss: 2.06114 | test_accuracy: 0.34874 |  0:00:16s\n",
      "epoch 28 | loss: 2.04202 | test_accuracy: 0.35901 |  0:00:16s\n",
      "epoch 29 | loss: 2.00218 | test_accuracy: 0.3662  |  0:00:17s\n",
      "epoch 30 | loss: 1.95848 | test_accuracy: 0.37237 |  0:00:17s\n",
      "epoch 31 | loss: 1.91779 | test_accuracy: 0.37596 |  0:00:18s\n",
      "epoch 32 | loss: 1.87849 | test_accuracy: 0.37802 |  0:00:18s\n",
      "epoch 33 | loss: 1.86634 | test_accuracy: 0.37956 |  0:00:19s\n",
      "epoch 34 | loss: 1.81838 | test_accuracy: 0.39599 |  0:00:20s\n",
      "epoch 35 | loss: 1.81369 | test_accuracy: 0.39908 |  0:00:20s\n",
      "epoch 36 | loss: 1.77988 | test_accuracy: 0.40421 |  0:00:21s\n",
      "epoch 37 | loss: 1.77717 | test_accuracy: 0.40729 |  0:00:21s\n",
      "epoch 38 | loss: 1.72975 | test_accuracy: 0.41551 |  0:00:22s\n",
      "epoch 39 | loss: 1.73417 | test_accuracy: 0.42784 |  0:00:22s\n",
      "epoch 40 | loss: 1.68189 | test_accuracy: 0.42681 |  0:00:23s\n",
      "epoch 41 | loss: 1.63027 | test_accuracy: 0.43657 |  0:00:24s\n",
      "epoch 42 | loss: 1.62725 | test_accuracy: 0.44222 |  0:00:24s\n",
      "epoch 43 | loss: 1.61886 | test_accuracy: 0.45198 |  0:00:25s\n",
      "epoch 44 | loss: 1.59663 | test_accuracy: 0.4489  |  0:00:25s\n",
      "epoch 45 | loss: 1.58681 | test_accuracy: 0.45146 |  0:00:26s\n",
      "epoch 46 | loss: 1.57714 | test_accuracy: 0.46482 |  0:00:26s\n",
      "epoch 47 | loss: 1.55416 | test_accuracy: 0.4679  |  0:00:27s\n",
      "epoch 48 | loss: 1.52599 | test_accuracy: 0.47612 |  0:00:28s\n",
      "epoch 49 | loss: 1.50406 | test_accuracy: 0.47509 |  0:00:28s\n",
      "epoch 50 | loss: 1.48296 | test_accuracy: 0.48125 |  0:00:29s\n",
      "epoch 51 | loss: 1.46975 | test_accuracy: 0.48023 |  0:00:29s\n",
      "epoch 52 | loss: 1.47854 | test_accuracy: 0.48998 |  0:00:30s\n",
      "epoch 53 | loss: 1.44473 | test_accuracy: 0.48844 |  0:00:31s\n",
      "epoch 54 | loss: 1.44318 | test_accuracy: 0.48279 |  0:00:31s\n",
      "epoch 55 | loss: 1.41824 | test_accuracy: 0.49153 |  0:00:32s\n",
      "epoch 56 | loss: 1.40346 | test_accuracy: 0.49153 |  0:00:32s\n",
      "epoch 57 | loss: 1.40798 | test_accuracy: 0.49923 |  0:00:33s\n",
      "epoch 58 | loss: 1.3867  | test_accuracy: 0.50539 |  0:00:33s\n",
      "epoch 59 | loss: 1.3671  | test_accuracy: 0.50488 |  0:00:34s\n",
      "epoch 60 | loss: 1.36967 | test_accuracy: 0.50847 |  0:00:35s\n",
      "epoch 61 | loss: 1.34892 | test_accuracy: 0.51053 |  0:00:35s\n",
      "epoch 62 | loss: 1.33536 | test_accuracy: 0.51567 |  0:00:36s\n",
      "epoch 63 | loss: 1.32987 | test_accuracy: 0.52286 |  0:00:36s\n",
      "epoch 64 | loss: 1.33019 | test_accuracy: 0.52388 |  0:00:37s\n",
      "epoch 65 | loss: 1.31012 | test_accuracy: 0.52799 |  0:00:37s\n",
      "epoch 66 | loss: 1.29684 | test_accuracy: 0.53313 |  0:00:38s\n",
      "epoch 67 | loss: 1.30596 | test_accuracy: 0.53518 |  0:00:38s\n",
      "epoch 68 | loss: 1.27592 | test_accuracy: 0.54135 |  0:00:39s\n",
      "epoch 69 | loss: 1.271   | test_accuracy: 0.53775 |  0:00:40s\n",
      "epoch 70 | loss: 1.27151 | test_accuracy: 0.54391 |  0:00:40s\n",
      "epoch 71 | loss: 1.27947 | test_accuracy: 0.53929 |  0:00:41s\n",
      "epoch 72 | loss: 1.25078 | test_accuracy: 0.53775 |  0:00:41s\n",
      "epoch 73 | loss: 1.24713 | test_accuracy: 0.54237 |  0:00:42s\n",
      "epoch 74 | loss: 1.22766 | test_accuracy: 0.54443 |  0:00:43s\n",
      "epoch 75 | loss: 1.23547 | test_accuracy: 0.53878 |  0:00:43s\n",
      "epoch 76 | loss: 1.22627 | test_accuracy: 0.54751 |  0:00:44s\n",
      "epoch 77 | loss: 1.22013 | test_accuracy: 0.54494 |  0:00:44s\n",
      "epoch 78 | loss: 1.19566 | test_accuracy: 0.5547  |  0:00:45s\n",
      "epoch 79 | loss: 1.22077 | test_accuracy: 0.55059 |  0:00:45s\n",
      "epoch 80 | loss: 1.19882 | test_accuracy: 0.55265 |  0:00:46s\n",
      "epoch 81 | loss: 1.18332 | test_accuracy: 0.5511  |  0:00:46s\n",
      "epoch 82 | loss: 1.18484 | test_accuracy: 0.55213 |  0:00:47s\n",
      "epoch 83 | loss: 1.18782 | test_accuracy: 0.55829 |  0:00:48s\n",
      "epoch 84 | loss: 1.17903 | test_accuracy: 0.55778 |  0:00:48s\n",
      "epoch 85 | loss: 1.17087 | test_accuracy: 0.55675 |  0:00:49s\n",
      "epoch 86 | loss: 1.16908 | test_accuracy: 0.56754 |  0:00:49s\n",
      "epoch 87 | loss: 1.17455 | test_accuracy: 0.56446 |  0:00:50s\n",
      "epoch 88 | loss: 1.15831 | test_accuracy: 0.56446 |  0:00:50s\n",
      "epoch 89 | loss: 1.15027 | test_accuracy: 0.56549 |  0:00:51s\n",
      "epoch 90 | loss: 1.15094 | test_accuracy: 0.57011 |  0:00:52s\n",
      "epoch 91 | loss: 1.15568 | test_accuracy: 0.56549 |  0:00:52s\n",
      "epoch 92 | loss: 1.15084 | test_accuracy: 0.57473 |  0:00:53s\n",
      "epoch 93 | loss: 1.15445 | test_accuracy: 0.56703 |  0:00:53s\n",
      "epoch 94 | loss: 1.13698 | test_accuracy: 0.57114 |  0:00:54s\n",
      "epoch 95 | loss: 1.12815 | test_accuracy: 0.56805 |  0:00:54s\n",
      "epoch 96 | loss: 1.12305 | test_accuracy: 0.56703 |  0:00:55s\n",
      "epoch 97 | loss: 1.11828 | test_accuracy: 0.57114 |  0:00:56s\n",
      "epoch 98 | loss: 1.12701 | test_accuracy: 0.56959 |  0:00:56s\n",
      "epoch 99 | loss: 1.12291 | test_accuracy: 0.57268 |  0:00:57s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 92 and best_test_accuracy = 0.57473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:50:31,405] Trial 6 finished with value: 0.5747303543913713 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 5, 'gamma': 1.7568183759651528, 'lambda_sparse': 0.0005392504161373644, 'lr': 0.00013673312566455287, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.613251155624037.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.24067 | test_accuracy: 0.10889 |  0:00:00s\n",
      "epoch 1  | loss: 3.16238 | test_accuracy: 0.11659 |  0:00:01s\n",
      "epoch 2  | loss: 3.0229  | test_accuracy: 0.13046 |  0:00:02s\n",
      "epoch 3  | loss: 2.91916 | test_accuracy: 0.14381 |  0:00:02s\n",
      "epoch 4  | loss: 2.79129 | test_accuracy: 0.16076 |  0:00:03s\n",
      "epoch 5  | loss: 2.67404 | test_accuracy: 0.17103 |  0:00:04s\n",
      "epoch 6  | loss: 2.60252 | test_accuracy: 0.18901 |  0:00:04s\n",
      "epoch 7  | loss: 2.52984 | test_accuracy: 0.21572 |  0:00:05s\n",
      "epoch 8  | loss: 2.44405 | test_accuracy: 0.23523 |  0:00:06s\n",
      "epoch 9  | loss: 2.38843 | test_accuracy: 0.24705 |  0:00:07s\n",
      "epoch 10 | loss: 2.31919 | test_accuracy: 0.26656 |  0:00:07s\n",
      "epoch 11 | loss: 2.23359 | test_accuracy: 0.29635 |  0:00:08s\n",
      "epoch 12 | loss: 2.14532 | test_accuracy: 0.31895 |  0:00:09s\n",
      "epoch 13 | loss: 2.09717 | test_accuracy: 0.33847 |  0:00:10s\n",
      "epoch 14 | loss: 2.0262  | test_accuracy: 0.35799 |  0:00:10s\n",
      "epoch 15 | loss: 1.97609 | test_accuracy: 0.36775 |  0:00:11s\n",
      "epoch 16 | loss: 1.91424 | test_accuracy: 0.37288 |  0:00:12s\n",
      "epoch 17 | loss: 1.87476 | test_accuracy: 0.37545 |  0:00:12s\n",
      "epoch 18 | loss: 1.83242 | test_accuracy: 0.3888  |  0:00:13s\n",
      "epoch 19 | loss: 1.81789 | test_accuracy: 0.39445 |  0:00:14s\n",
      "epoch 20 | loss: 1.77545 | test_accuracy: 0.40473 |  0:00:14s\n",
      "epoch 21 | loss: 1.72516 | test_accuracy: 0.42013 |  0:00:15s\n",
      "epoch 22 | loss: 1.70023 | test_accuracy: 0.42989 |  0:00:16s\n",
      "epoch 23 | loss: 1.6627  | test_accuracy: 0.4376  |  0:00:16s\n",
      "epoch 24 | loss: 1.62777 | test_accuracy: 0.43657 |  0:00:17s\n",
      "epoch 25 | loss: 1.6029  | test_accuracy: 0.44376 |  0:00:18s\n",
      "epoch 26 | loss: 1.5786  | test_accuracy: 0.44787 |  0:00:19s\n",
      "epoch 27 | loss: 1.57709 | test_accuracy: 0.46687 |  0:00:20s\n",
      "epoch 28 | loss: 1.54183 | test_accuracy: 0.46995 |  0:00:20s\n",
      "epoch 29 | loss: 1.52381 | test_accuracy: 0.4643  |  0:00:21s\n",
      "epoch 30 | loss: 1.50615 | test_accuracy: 0.46893 |  0:00:22s\n",
      "epoch 31 | loss: 1.50459 | test_accuracy: 0.4679  |  0:00:22s\n",
      "epoch 32 | loss: 1.47242 | test_accuracy: 0.47612 |  0:00:23s\n",
      "epoch 33 | loss: 1.46106 | test_accuracy: 0.48588 |  0:00:24s\n",
      "epoch 34 | loss: 1.42698 | test_accuracy: 0.48279 |  0:00:24s\n",
      "epoch 35 | loss: 1.42627 | test_accuracy: 0.48485 |  0:00:25s\n",
      "epoch 36 | loss: 1.40874 | test_accuracy: 0.48742 |  0:00:26s\n",
      "epoch 37 | loss: 1.40233 | test_accuracy: 0.48793 |  0:00:26s\n",
      "epoch 38 | loss: 1.37691 | test_accuracy: 0.4905  |  0:00:27s\n",
      "epoch 39 | loss: 1.37137 | test_accuracy: 0.48793 |  0:00:28s\n",
      "epoch 40 | loss: 1.3748  | test_accuracy: 0.48844 |  0:00:29s\n",
      "epoch 41 | loss: 1.3504  | test_accuracy: 0.4982  |  0:00:30s\n",
      "epoch 42 | loss: 1.32701 | test_accuracy: 0.48998 |  0:00:31s\n",
      "epoch 43 | loss: 1.3169  | test_accuracy: 0.49358 |  0:00:31s\n",
      "epoch 44 | loss: 1.32098 | test_accuracy: 0.49409 |  0:00:32s\n",
      "epoch 45 | loss: 1.33033 | test_accuracy: 0.50539 |  0:00:33s\n",
      "epoch 46 | loss: 1.29526 | test_accuracy: 0.50899 |  0:00:34s\n",
      "epoch 47 | loss: 1.30652 | test_accuracy: 0.50847 |  0:00:35s\n",
      "epoch 48 | loss: 1.29281 | test_accuracy: 0.51567 |  0:00:35s\n",
      "epoch 49 | loss: 1.25951 | test_accuracy: 0.51515 |  0:00:36s\n",
      "epoch 50 | loss: 1.26148 | test_accuracy: 0.51823 |  0:00:37s\n",
      "epoch 51 | loss: 1.26589 | test_accuracy: 0.51977 |  0:00:38s\n",
      "epoch 52 | loss: 1.28655 | test_accuracy: 0.51875 |  0:00:38s\n",
      "epoch 53 | loss: 1.25976 | test_accuracy: 0.52594 |  0:00:39s\n",
      "epoch 54 | loss: 1.23899 | test_accuracy: 0.53313 |  0:00:40s\n",
      "epoch 55 | loss: 1.24107 | test_accuracy: 0.53313 |  0:00:41s\n",
      "epoch 56 | loss: 1.23987 | test_accuracy: 0.53467 |  0:00:42s\n",
      "epoch 57 | loss: 1.24033 | test_accuracy: 0.52851 |  0:00:42s\n",
      "epoch 58 | loss: 1.22317 | test_accuracy: 0.53724 |  0:00:43s\n",
      "epoch 59 | loss: 1.21771 | test_accuracy: 0.52851 |  0:00:44s\n",
      "epoch 60 | loss: 1.20428 | test_accuracy: 0.52902 |  0:00:45s\n",
      "epoch 61 | loss: 1.21003 | test_accuracy: 0.51823 |  0:00:45s\n",
      "epoch 62 | loss: 1.20806 | test_accuracy: 0.5244  |  0:00:46s\n",
      "epoch 63 | loss: 1.21358 | test_accuracy: 0.52953 |  0:00:47s\n",
      "epoch 64 | loss: 1.20584 | test_accuracy: 0.54032 |  0:00:47s\n",
      "epoch 65 | loss: 1.19186 | test_accuracy: 0.53467 |  0:00:48s\n",
      "epoch 66 | loss: 1.20523 | test_accuracy: 0.53775 |  0:00:49s\n",
      "epoch 67 | loss: 1.18859 | test_accuracy: 0.53775 |  0:00:50s\n",
      "epoch 68 | loss: 1.17802 | test_accuracy: 0.54032 |  0:00:50s\n",
      "epoch 69 | loss: 1.17994 | test_accuracy: 0.54083 |  0:00:51s\n",
      "epoch 70 | loss: 1.15629 | test_accuracy: 0.54289 |  0:00:52s\n",
      "epoch 71 | loss: 1.17936 | test_accuracy: 0.54751 |  0:00:53s\n",
      "epoch 72 | loss: 1.18253 | test_accuracy: 0.54083 |  0:00:53s\n",
      "epoch 73 | loss: 1.16595 | test_accuracy: 0.5357  |  0:00:54s\n",
      "epoch 74 | loss: 1.16885 | test_accuracy: 0.54391 |  0:00:55s\n",
      "epoch 75 | loss: 1.15286 | test_accuracy: 0.55265 |  0:00:56s\n",
      "epoch 76 | loss: 1.15051 | test_accuracy: 0.54751 |  0:00:56s\n",
      "epoch 77 | loss: 1.15049 | test_accuracy: 0.54905 |  0:00:57s\n",
      "epoch 78 | loss: 1.15014 | test_accuracy: 0.54648 |  0:00:58s\n",
      "epoch 79 | loss: 1.14517 | test_accuracy: 0.54237 |  0:00:59s\n",
      "epoch 80 | loss: 1.14491 | test_accuracy: 0.54648 |  0:00:59s\n",
      "epoch 81 | loss: 1.13692 | test_accuracy: 0.54597 |  0:01:00s\n",
      "epoch 82 | loss: 1.13586 | test_accuracy: 0.54494 |  0:01:01s\n",
      "epoch 83 | loss: 1.14348 | test_accuracy: 0.54443 |  0:01:02s\n",
      "epoch 84 | loss: 1.13534 | test_accuracy: 0.55213 |  0:01:02s\n",
      "epoch 85 | loss: 1.11975 | test_accuracy: 0.5547  |  0:01:03s\n",
      "epoch 86 | loss: 1.12668 | test_accuracy: 0.54545 |  0:01:04s\n",
      "epoch 87 | loss: 1.12922 | test_accuracy: 0.55881 |  0:01:05s\n",
      "epoch 88 | loss: 1.12038 | test_accuracy: 0.55521 |  0:01:06s\n",
      "epoch 89 | loss: 1.11331 | test_accuracy: 0.56703 |  0:01:07s\n",
      "epoch 90 | loss: 1.1111  | test_accuracy: 0.56343 |  0:01:08s\n",
      "epoch 91 | loss: 1.10317 | test_accuracy: 0.57062 |  0:01:08s\n",
      "epoch 92 | loss: 1.11856 | test_accuracy: 0.56549 |  0:01:09s\n",
      "epoch 93 | loss: 1.11204 | test_accuracy: 0.57319 |  0:01:10s\n",
      "epoch 94 | loss: 1.11119 | test_accuracy: 0.56651 |  0:01:10s\n",
      "epoch 95 | loss: 1.10901 | test_accuracy: 0.56651 |  0:01:11s\n",
      "epoch 96 | loss: 1.09447 | test_accuracy: 0.56343 |  0:01:12s\n",
      "epoch 97 | loss: 1.10198 | test_accuracy: 0.56394 |  0:01:13s\n",
      "epoch 98 | loss: 1.10737 | test_accuracy: 0.57011 |  0:01:13s\n",
      "epoch 99 | loss: 1.11236 | test_accuracy: 0.57011 |  0:01:14s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_test_accuracy = 0.57319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:51:46,318] Trial 7 finished with value: 0.5731895223420647 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 8, 'gamma': 1.338123644944191, 'lambda_sparse': 0.00019212196783902348, 'lr': 0.00015059393115342775, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.613251155624037.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.44917 | test_accuracy: 0.28043 |  0:00:00s\n",
      "epoch 1  | loss: 3.46867 | test_accuracy: 0.26091 |  0:00:00s\n",
      "epoch 2  | loss: 3.40771 | test_accuracy: 0.24294 |  0:00:01s\n",
      "epoch 3  | loss: 3.38044 | test_accuracy: 0.23164 |  0:00:01s\n",
      "epoch 4  | loss: 3.37563 | test_accuracy: 0.23729 |  0:00:02s\n",
      "epoch 5  | loss: 3.34921 | test_accuracy: 0.26091 |  0:00:02s\n",
      "epoch 6  | loss: 3.33524 | test_accuracy: 0.26246 |  0:00:03s\n",
      "epoch 7  | loss: 3.2936  | test_accuracy: 0.25937 |  0:00:03s\n",
      "epoch 8  | loss: 3.26123 | test_accuracy: 0.264   |  0:00:04s\n",
      "epoch 9  | loss: 3.25405 | test_accuracy: 0.26759 |  0:00:04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:51:51,928] Trial 8 finished with value: 0.28043143297380585 and parameters: {'n_d': 8, 'n_a': 8, 'n_steps': 8, 'gamma': 1.4920105863122788, 'lambda_sparse': 8.003364736320007e-05, 'lr': 0.00011568093402633078, 'mask_type': 'entmax', 'batch_size': 1024, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.613251155624037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | loss: 3.23471 | test_accuracy: 0.25475 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_test_accuracy = 0.28043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.73223 | test_accuracy: 0.47612 |  0:00:00s\n",
      "epoch 1  | loss: 1.23623 | test_accuracy: 0.53878 |  0:00:00s\n",
      "epoch 2  | loss: 1.12009 | test_accuracy: 0.55521 |  0:00:01s\n",
      "epoch 3  | loss: 1.06192 | test_accuracy: 0.57114 |  0:00:01s\n",
      "epoch 4  | loss: 1.03412 | test_accuracy: 0.59014 |  0:00:02s\n",
      "epoch 5  | loss: 1.01027 | test_accuracy: 0.58449 |  0:00:02s\n",
      "epoch 6  | loss: 0.98749 | test_accuracy: 0.58243 |  0:00:03s\n",
      "epoch 7  | loss: 0.97861 | test_accuracy: 0.57319 |  0:00:03s\n",
      "epoch 8  | loss: 0.97389 | test_accuracy: 0.58141 |  0:00:04s\n",
      "epoch 9  | loss: 0.96118 | test_accuracy: 0.58963 |  0:00:04s\n",
      "epoch 10 | loss: 0.95808 | test_accuracy: 0.58295 |  0:00:05s\n",
      "epoch 11 | loss: 0.95201 | test_accuracy: 0.59476 |  0:00:05s\n",
      "epoch 12 | loss: 0.94346 | test_accuracy: 0.60092 |  0:00:06s\n",
      "epoch 13 | loss: 0.93786 | test_accuracy: 0.61068 |  0:00:06s\n",
      "epoch 14 | loss: 0.93396 | test_accuracy: 0.5999  |  0:00:06s\n",
      "epoch 15 | loss: 0.93461 | test_accuracy: 0.60298 |  0:00:07s\n",
      "epoch 16 | loss: 0.93073 | test_accuracy: 0.61017 |  0:00:07s\n",
      "epoch 17 | loss: 0.92556 | test_accuracy: 0.60966 |  0:00:08s\n",
      "epoch 18 | loss: 0.9201  | test_accuracy: 0.61479 |  0:00:08s\n",
      "epoch 19 | loss: 0.91308 | test_accuracy: 0.6076  |  0:00:09s\n",
      "epoch 20 | loss: 0.91159 | test_accuracy: 0.60555 |  0:00:09s\n",
      "epoch 21 | loss: 0.90589 | test_accuracy: 0.61633 |  0:00:10s\n",
      "epoch 22 | loss: 0.90031 | test_accuracy: 0.61839 |  0:00:10s\n",
      "epoch 23 | loss: 0.8954  | test_accuracy: 0.61325 |  0:00:10s\n",
      "epoch 24 | loss: 0.90812 | test_accuracy: 0.61685 |  0:00:11s\n",
      "epoch 25 | loss: 0.89684 | test_accuracy: 0.61839 |  0:00:11s\n",
      "epoch 26 | loss: 0.89756 | test_accuracy: 0.61941 |  0:00:12s\n",
      "epoch 27 | loss: 0.89285 | test_accuracy: 0.62609 |  0:00:12s\n",
      "epoch 28 | loss: 0.88314 | test_accuracy: 0.62763 |  0:00:13s\n",
      "epoch 29 | loss: 0.89307 | test_accuracy: 0.62455 |  0:00:13s\n",
      "epoch 30 | loss: 0.88844 | test_accuracy: 0.6189  |  0:00:14s\n",
      "epoch 31 | loss: 0.88753 | test_accuracy: 0.62712 |  0:00:14s\n",
      "epoch 32 | loss: 0.88092 | test_accuracy: 0.63071 |  0:00:15s\n",
      "epoch 33 | loss: 0.86973 | test_accuracy: 0.6302  |  0:00:15s\n",
      "epoch 34 | loss: 0.87014 | test_accuracy: 0.64047 |  0:00:15s\n",
      "epoch 35 | loss: 0.86255 | test_accuracy: 0.63534 |  0:00:16s\n",
      "epoch 36 | loss: 0.86425 | test_accuracy: 0.64407 |  0:00:17s\n",
      "epoch 37 | loss: 0.86189 | test_accuracy: 0.63174 |  0:00:17s\n",
      "epoch 38 | loss: 0.8629  | test_accuracy: 0.63893 |  0:00:18s\n",
      "epoch 39 | loss: 0.86093 | test_accuracy: 0.6379  |  0:00:18s\n",
      "epoch 40 | loss: 0.86219 | test_accuracy: 0.63328 |  0:00:18s\n",
      "epoch 41 | loss: 0.85974 | test_accuracy: 0.63328 |  0:00:19s\n",
      "epoch 42 | loss: 0.85309 | test_accuracy: 0.63996 |  0:00:19s\n",
      "epoch 43 | loss: 0.85033 | test_accuracy: 0.62763 |  0:00:20s\n",
      "epoch 44 | loss: 0.85126 | test_accuracy: 0.64099 |  0:00:20s\n",
      "epoch 45 | loss: 0.84488 | test_accuracy: 0.64612 |  0:00:21s\n",
      "epoch 46 | loss: 0.84689 | test_accuracy: 0.63123 |  0:00:21s\n",
      "epoch 47 | loss: 0.8443  | test_accuracy: 0.64561 |  0:00:22s\n",
      "epoch 48 | loss: 0.84556 | test_accuracy: 0.64201 |  0:00:22s\n",
      "epoch 49 | loss: 0.83852 | test_accuracy: 0.64972 |  0:00:23s\n",
      "epoch 50 | loss: 0.83757 | test_accuracy: 0.64407 |  0:00:23s\n",
      "epoch 51 | loss: 0.83254 | test_accuracy: 0.65126 |  0:00:24s\n",
      "epoch 52 | loss: 0.83545 | test_accuracy: 0.65126 |  0:00:24s\n",
      "epoch 53 | loss: 0.837   | test_accuracy: 0.64304 |  0:00:25s\n",
      "epoch 54 | loss: 0.83489 | test_accuracy: 0.64972 |  0:00:25s\n",
      "epoch 55 | loss: 0.82732 | test_accuracy: 0.64664 |  0:00:26s\n",
      "epoch 56 | loss: 0.8251  | test_accuracy: 0.64201 |  0:00:26s\n",
      "epoch 57 | loss: 0.82815 | test_accuracy: 0.63945 |  0:00:27s\n",
      "epoch 58 | loss: 0.82911 | test_accuracy: 0.65023 |  0:00:27s\n",
      "epoch 59 | loss: 0.83126 | test_accuracy: 0.64355 |  0:00:27s\n",
      "epoch 60 | loss: 0.833   | test_accuracy: 0.64047 |  0:00:28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:52:20,940] Trial 9 finished with value: 0.6512583461736005 and parameters: {'n_d': 16, 'n_a': 32, 'n_steps': 3, 'gamma': 1.873162299500314, 'lambda_sparse': 9.510616385030972e-05, 'lr': 0.005649894944444701, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 9 with value: 0.6512583461736005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61 | loss: 0.83145 | test_accuracy: 0.64355 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_test_accuracy = 0.65126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.38024 | test_accuracy: 0.06215 |  0:00:00s\n",
      "epoch 1  | loss: 2.80729 | test_accuracy: 0.14432 |  0:00:00s\n",
      "epoch 2  | loss: 2.38113 | test_accuracy: 0.24037 |  0:00:01s\n",
      "epoch 3  | loss: 2.04277 | test_accuracy: 0.3508  |  0:00:01s\n",
      "epoch 4  | loss: 1.7924  | test_accuracy: 0.42424 |  0:00:02s\n",
      "epoch 5  | loss: 1.60655 | test_accuracy: 0.4905  |  0:00:02s\n",
      "epoch 6  | loss: 1.45931 | test_accuracy: 0.51926 |  0:00:03s\n",
      "epoch 7  | loss: 1.35206 | test_accuracy: 0.54186 |  0:00:03s\n",
      "epoch 8  | loss: 1.28055 | test_accuracy: 0.54135 |  0:00:04s\n",
      "epoch 9  | loss: 1.21994 | test_accuracy: 0.55984 |  0:00:04s\n",
      "epoch 10 | loss: 1.17265 | test_accuracy: 0.56189 |  0:00:05s\n",
      "epoch 11 | loss: 1.13911 | test_accuracy: 0.55008 |  0:00:05s\n",
      "epoch 12 | loss: 1.11689 | test_accuracy: 0.55213 |  0:00:06s\n",
      "epoch 13 | loss: 1.09306 | test_accuracy: 0.55265 |  0:00:06s\n",
      "epoch 14 | loss: 1.07189 | test_accuracy: 0.56805 |  0:00:07s\n",
      "epoch 15 | loss: 1.06829 | test_accuracy: 0.57576 |  0:00:07s\n",
      "epoch 16 | loss: 1.04459 | test_accuracy: 0.58192 |  0:00:08s\n",
      "epoch 17 | loss: 1.0345  | test_accuracy: 0.57627 |  0:00:08s\n",
      "epoch 18 | loss: 1.03793 | test_accuracy: 0.57165 |  0:00:09s\n",
      "epoch 19 | loss: 1.02378 | test_accuracy: 0.57524 |  0:00:09s\n",
      "epoch 20 | loss: 1.01631 | test_accuracy: 0.58449 |  0:00:10s\n",
      "epoch 21 | loss: 1.02008 | test_accuracy: 0.585   |  0:00:10s\n",
      "epoch 22 | loss: 1.00588 | test_accuracy: 0.58654 |  0:00:11s\n",
      "epoch 23 | loss: 1.00311 | test_accuracy: 0.59682 |  0:00:11s\n",
      "epoch 24 | loss: 0.99326 | test_accuracy: 0.60298 |  0:00:12s\n",
      "epoch 25 | loss: 0.98979 | test_accuracy: 0.60298 |  0:00:12s\n",
      "epoch 26 | loss: 0.98256 | test_accuracy: 0.5999  |  0:00:13s\n",
      "epoch 27 | loss: 0.98295 | test_accuracy: 0.60401 |  0:00:13s\n",
      "epoch 28 | loss: 0.97685 | test_accuracy: 0.59682 |  0:00:14s\n",
      "epoch 29 | loss: 0.97431 | test_accuracy: 0.60555 |  0:00:14s\n",
      "epoch 30 | loss: 0.97337 | test_accuracy: 0.6076  |  0:00:15s\n",
      "epoch 31 | loss: 0.96157 | test_accuracy: 0.6076  |  0:00:15s\n",
      "epoch 32 | loss: 0.96212 | test_accuracy: 0.61171 |  0:00:16s\n",
      "epoch 33 | loss: 0.96002 | test_accuracy: 0.61376 |  0:00:16s\n",
      "epoch 34 | loss: 0.95916 | test_accuracy: 0.6189  |  0:00:17s\n",
      "epoch 35 | loss: 0.94991 | test_accuracy: 0.62558 |  0:00:18s\n",
      "epoch 36 | loss: 0.95168 | test_accuracy: 0.62506 |  0:00:18s\n",
      "epoch 37 | loss: 0.94775 | test_accuracy: 0.62455 |  0:00:19s\n",
      "epoch 38 | loss: 0.94097 | test_accuracy: 0.62815 |  0:00:19s\n",
      "epoch 39 | loss: 0.93636 | test_accuracy: 0.62096 |  0:00:20s\n",
      "epoch 40 | loss: 0.94198 | test_accuracy: 0.62147 |  0:00:20s\n",
      "epoch 41 | loss: 0.93619 | test_accuracy: 0.6225  |  0:00:21s\n",
      "epoch 42 | loss: 0.93318 | test_accuracy: 0.62763 |  0:00:21s\n",
      "epoch 43 | loss: 0.93351 | test_accuracy: 0.6189  |  0:00:22s\n",
      "epoch 44 | loss: 0.93058 | test_accuracy: 0.62404 |  0:00:22s\n",
      "epoch 45 | loss: 0.92952 | test_accuracy: 0.63123 |  0:00:23s\n",
      "epoch 46 | loss: 0.92579 | test_accuracy: 0.62917 |  0:00:23s\n",
      "epoch 47 | loss: 0.92078 | test_accuracy: 0.63071 |  0:00:24s\n",
      "epoch 48 | loss: 0.91687 | test_accuracy: 0.63123 |  0:00:24s\n",
      "epoch 49 | loss: 0.91547 | test_accuracy: 0.63585 |  0:00:25s\n",
      "epoch 50 | loss: 0.9123  | test_accuracy: 0.63071 |  0:00:25s\n",
      "epoch 51 | loss: 0.91183 | test_accuracy: 0.63585 |  0:00:26s\n",
      "epoch 52 | loss: 0.90812 | test_accuracy: 0.64099 |  0:00:26s\n",
      "epoch 53 | loss: 0.90743 | test_accuracy: 0.63739 |  0:00:27s\n",
      "epoch 54 | loss: 0.90484 | test_accuracy: 0.63945 |  0:00:27s\n",
      "epoch 55 | loss: 0.90488 | test_accuracy: 0.6379  |  0:00:28s\n",
      "epoch 56 | loss: 0.89803 | test_accuracy: 0.63945 |  0:00:28s\n",
      "epoch 57 | loss: 0.8973  | test_accuracy: 0.63739 |  0:00:29s\n",
      "epoch 58 | loss: 0.89189 | test_accuracy: 0.63688 |  0:00:29s\n",
      "epoch 59 | loss: 0.8963  | test_accuracy: 0.63842 |  0:00:30s\n",
      "epoch 60 | loss: 0.8896  | test_accuracy: 0.6451  |  0:00:30s\n",
      "epoch 61 | loss: 0.89138 | test_accuracy: 0.64047 |  0:00:31s\n",
      "epoch 62 | loss: 0.89462 | test_accuracy: 0.63842 |  0:00:31s\n",
      "epoch 63 | loss: 0.89148 | test_accuracy: 0.64355 |  0:00:32s\n",
      "epoch 64 | loss: 0.88405 | test_accuracy: 0.64099 |  0:00:32s\n",
      "epoch 65 | loss: 0.8815  | test_accuracy: 0.64253 |  0:00:33s\n",
      "epoch 66 | loss: 0.87968 | test_accuracy: 0.64304 |  0:00:33s\n",
      "epoch 67 | loss: 0.87888 | test_accuracy: 0.63996 |  0:00:34s\n",
      "epoch 68 | loss: 0.88203 | test_accuracy: 0.6415  |  0:00:34s\n",
      "epoch 69 | loss: 0.87022 | test_accuracy: 0.64253 |  0:00:35s\n",
      "epoch 70 | loss: 0.87808 | test_accuracy: 0.64304 |  0:00:35s\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 60 and best_test_accuracy = 0.6451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:52:56,762] Trial 10 finished with value: 0.6450950179763739 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 3, 'gamma': 1.9733550992290787, 'lambda_sparse': 1.9233279923981242e-05, 'lr': 0.0008033338441937909, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 9 with value: 0.6512583461736005.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.45096 | test_accuracy: 0.04931 |  0:00:00s\n",
      "epoch 1  | loss: 2.99022 | test_accuracy: 0.09348 |  0:00:01s\n",
      "epoch 2  | loss: 2.65034 | test_accuracy: 0.17206 |  0:00:01s\n",
      "epoch 3  | loss: 2.36319 | test_accuracy: 0.24191 |  0:00:02s\n",
      "epoch 4  | loss: 2.11711 | test_accuracy: 0.32152 |  0:00:02s\n",
      "epoch 5  | loss: 1.90342 | test_accuracy: 0.39394 |  0:00:03s\n",
      "epoch 6  | loss: 1.72272 | test_accuracy: 0.44633 |  0:00:04s\n",
      "epoch 7  | loss: 1.58216 | test_accuracy: 0.48536 |  0:00:04s\n",
      "epoch 8  | loss: 1.4878  | test_accuracy: 0.48947 |  0:00:05s\n",
      "epoch 9  | loss: 1.40046 | test_accuracy: 0.50231 |  0:00:05s\n",
      "epoch 10 | loss: 1.33824 | test_accuracy: 0.52491 |  0:00:06s\n",
      "epoch 11 | loss: 1.28983 | test_accuracy: 0.53826 |  0:00:06s\n",
      "epoch 12 | loss: 1.25061 | test_accuracy: 0.53826 |  0:00:07s\n",
      "epoch 13 | loss: 1.21411 | test_accuracy: 0.5398  |  0:00:07s\n",
      "epoch 14 | loss: 1.17712 | test_accuracy: 0.54186 |  0:00:08s\n",
      "epoch 15 | loss: 1.15596 | test_accuracy: 0.54905 |  0:00:08s\n",
      "epoch 16 | loss: 1.12811 | test_accuracy: 0.55573 |  0:00:09s\n",
      "epoch 17 | loss: 1.10763 | test_accuracy: 0.56189 |  0:00:09s\n",
      "epoch 18 | loss: 1.0939  | test_accuracy: 0.57781 |  0:00:10s\n",
      "epoch 19 | loss: 1.07028 | test_accuracy: 0.57576 |  0:00:10s\n",
      "epoch 20 | loss: 1.06477 | test_accuracy: 0.57884 |  0:00:11s\n",
      "epoch 21 | loss: 1.05713 | test_accuracy: 0.58089 |  0:00:11s\n",
      "epoch 22 | loss: 1.03938 | test_accuracy: 0.56959 |  0:00:12s\n",
      "epoch 23 | loss: 1.0306  | test_accuracy: 0.57987 |  0:00:12s\n",
      "epoch 24 | loss: 1.02878 | test_accuracy: 0.57524 |  0:00:13s\n",
      "epoch 25 | loss: 1.02066 | test_accuracy: 0.58192 |  0:00:13s\n",
      "epoch 26 | loss: 1.0176  | test_accuracy: 0.57833 |  0:00:14s\n",
      "epoch 27 | loss: 1.01435 | test_accuracy: 0.58192 |  0:00:14s\n",
      "epoch 28 | loss: 1.0069  | test_accuracy: 0.58808 |  0:00:14s\n",
      "epoch 29 | loss: 1.00378 | test_accuracy: 0.58141 |  0:00:15s\n",
      "epoch 30 | loss: 0.99912 | test_accuracy: 0.58757 |  0:00:15s\n",
      "epoch 31 | loss: 0.99133 | test_accuracy: 0.5886  |  0:00:16s\n",
      "epoch 32 | loss: 0.99262 | test_accuracy: 0.58808 |  0:00:17s\n",
      "epoch 33 | loss: 0.98143 | test_accuracy: 0.5963  |  0:00:17s\n",
      "epoch 34 | loss: 0.978   | test_accuracy: 0.60606 |  0:00:18s\n",
      "epoch 35 | loss: 0.96768 | test_accuracy: 0.59887 |  0:00:18s\n",
      "epoch 36 | loss: 0.97247 | test_accuracy: 0.60555 |  0:00:19s\n",
      "epoch 37 | loss: 0.96709 | test_accuracy: 0.60657 |  0:00:19s\n",
      "epoch 38 | loss: 0.96782 | test_accuracy: 0.60041 |  0:00:20s\n",
      "epoch 39 | loss: 0.9596  | test_accuracy: 0.60298 |  0:00:20s\n",
      "epoch 40 | loss: 0.95865 | test_accuracy: 0.60144 |  0:00:21s\n",
      "epoch 41 | loss: 0.95682 | test_accuracy: 0.60401 |  0:00:21s\n",
      "epoch 42 | loss: 0.95257 | test_accuracy: 0.60452 |  0:00:21s\n",
      "epoch 43 | loss: 0.95191 | test_accuracy: 0.60657 |  0:00:22s\n",
      "epoch 44 | loss: 0.94503 | test_accuracy: 0.60555 |  0:00:22s\n",
      "epoch 45 | loss: 0.94685 | test_accuracy: 0.60657 |  0:00:23s\n",
      "epoch 46 | loss: 0.94798 | test_accuracy: 0.60555 |  0:00:23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:53:21,412] Trial 11 finished with value: 0.6065742167437083 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 3, 'gamma': 1.9620741072597794, 'lambda_sparse': 1.928696847758741e-05, 'lr': 0.0005992572053811721, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 9 with value: 0.6512583461736005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47 | loss: 0.94248 | test_accuracy: 0.60452 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_test_accuracy = 0.60657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.41557 | test_accuracy: 0.06266 |  0:00:00s\n",
      "epoch 1  | loss: 2.89099 | test_accuracy: 0.12789 |  0:00:01s\n",
      "epoch 2  | loss: 2.47762 | test_accuracy: 0.21726 |  0:00:01s\n",
      "epoch 3  | loss: 2.11897 | test_accuracy: 0.3282  |  0:00:02s\n",
      "epoch 4  | loss: 1.84088 | test_accuracy: 0.42065 |  0:00:02s\n",
      "epoch 5  | loss: 1.62368 | test_accuracy: 0.48485 |  0:00:03s\n",
      "epoch 6  | loss: 1.46173 | test_accuracy: 0.5244  |  0:00:03s\n",
      "epoch 7  | loss: 1.36194 | test_accuracy: 0.54186 |  0:00:04s\n",
      "epoch 8  | loss: 1.28683 | test_accuracy: 0.53775 |  0:00:04s\n",
      "epoch 9  | loss: 1.22478 | test_accuracy: 0.55419 |  0:00:05s\n",
      "epoch 10 | loss: 1.17669 | test_accuracy: 0.566   |  0:00:05s\n",
      "epoch 11 | loss: 1.14937 | test_accuracy: 0.57062 |  0:00:06s\n",
      "epoch 12 | loss: 1.12065 | test_accuracy: 0.57319 |  0:00:06s\n",
      "epoch 13 | loss: 1.11265 | test_accuracy: 0.57268 |  0:00:07s\n",
      "epoch 14 | loss: 1.09186 | test_accuracy: 0.57114 |  0:00:07s\n",
      "epoch 15 | loss: 1.07672 | test_accuracy: 0.57833 |  0:00:08s\n",
      "epoch 16 | loss: 1.05463 | test_accuracy: 0.58295 |  0:00:08s\n",
      "epoch 17 | loss: 1.05277 | test_accuracy: 0.585   |  0:00:09s\n",
      "epoch 18 | loss: 1.03485 | test_accuracy: 0.59065 |  0:00:09s\n",
      "epoch 19 | loss: 1.02821 | test_accuracy: 0.59219 |  0:00:10s\n",
      "epoch 20 | loss: 1.01452 | test_accuracy: 0.60092 |  0:00:10s\n",
      "epoch 21 | loss: 1.01412 | test_accuracy: 0.5963  |  0:00:11s\n",
      "epoch 22 | loss: 1.01211 | test_accuracy: 0.59219 |  0:00:11s\n",
      "epoch 23 | loss: 0.99456 | test_accuracy: 0.5999  |  0:00:12s\n",
      "epoch 24 | loss: 0.99182 | test_accuracy: 0.59784 |  0:00:12s\n",
      "epoch 25 | loss: 0.98973 | test_accuracy: 0.60606 |  0:00:13s\n",
      "epoch 26 | loss: 0.98529 | test_accuracy: 0.61479 |  0:00:13s\n",
      "epoch 27 | loss: 0.98979 | test_accuracy: 0.6189  |  0:00:14s\n",
      "epoch 28 | loss: 0.97839 | test_accuracy: 0.61633 |  0:00:14s\n",
      "epoch 29 | loss: 0.97902 | test_accuracy: 0.61941 |  0:00:15s\n",
      "epoch 30 | loss: 0.97584 | test_accuracy: 0.6112  |  0:00:15s\n",
      "epoch 31 | loss: 0.9674  | test_accuracy: 0.61531 |  0:00:16s\n",
      "epoch 32 | loss: 0.96446 | test_accuracy: 0.62096 |  0:00:16s\n",
      "epoch 33 | loss: 0.96213 | test_accuracy: 0.62198 |  0:00:17s\n",
      "epoch 34 | loss: 0.96278 | test_accuracy: 0.6225  |  0:00:17s\n",
      "epoch 35 | loss: 0.95648 | test_accuracy: 0.62044 |  0:00:18s\n",
      "epoch 36 | loss: 0.95249 | test_accuracy: 0.62661 |  0:00:18s\n",
      "epoch 37 | loss: 0.95821 | test_accuracy: 0.61222 |  0:00:19s\n",
      "epoch 38 | loss: 0.95082 | test_accuracy: 0.62404 |  0:00:19s\n",
      "epoch 39 | loss: 0.94632 | test_accuracy: 0.62815 |  0:00:20s\n",
      "epoch 40 | loss: 0.93499 | test_accuracy: 0.62763 |  0:00:20s\n",
      "epoch 41 | loss: 0.93172 | test_accuracy: 0.62815 |  0:00:21s\n",
      "epoch 42 | loss: 0.94205 | test_accuracy: 0.62455 |  0:00:22s\n",
      "epoch 43 | loss: 0.93165 | test_accuracy: 0.61479 |  0:00:22s\n",
      "epoch 44 | loss: 0.93459 | test_accuracy: 0.62147 |  0:00:23s\n",
      "epoch 45 | loss: 0.92944 | test_accuracy: 0.62558 |  0:00:23s\n",
      "epoch 46 | loss: 0.92348 | test_accuracy: 0.62044 |  0:00:24s\n",
      "epoch 47 | loss: 0.92763 | test_accuracy: 0.62404 |  0:00:24s\n",
      "epoch 48 | loss: 0.91525 | test_accuracy: 0.6302  |  0:00:25s\n",
      "epoch 49 | loss: 0.9192  | test_accuracy: 0.62301 |  0:00:25s\n",
      "epoch 50 | loss: 0.9162  | test_accuracy: 0.62969 |  0:00:26s\n",
      "epoch 51 | loss: 0.91394 | test_accuracy: 0.62301 |  0:00:26s\n",
      "epoch 52 | loss: 0.91164 | test_accuracy: 0.62044 |  0:00:27s\n",
      "epoch 53 | loss: 0.91613 | test_accuracy: 0.62763 |  0:00:27s\n",
      "epoch 54 | loss: 0.90699 | test_accuracy: 0.62609 |  0:00:28s\n",
      "epoch 55 | loss: 0.91055 | test_accuracy: 0.62866 |  0:00:28s\n",
      "epoch 56 | loss: 0.90609 | test_accuracy: 0.63585 |  0:00:29s\n",
      "epoch 57 | loss: 0.9015  | test_accuracy: 0.62969 |  0:00:29s\n",
      "epoch 58 | loss: 0.89763 | test_accuracy: 0.62866 |  0:00:30s\n",
      "epoch 59 | loss: 0.90447 | test_accuracy: 0.6225  |  0:00:30s\n",
      "epoch 60 | loss: 0.90142 | test_accuracy: 0.62661 |  0:00:31s\n",
      "epoch 61 | loss: 0.89839 | test_accuracy: 0.6225  |  0:00:31s\n",
      "epoch 62 | loss: 0.89743 | test_accuracy: 0.62198 |  0:00:31s\n",
      "epoch 63 | loss: 0.89889 | test_accuracy: 0.61479 |  0:00:32s\n",
      "epoch 64 | loss: 0.89478 | test_accuracy: 0.62609 |  0:00:33s\n",
      "epoch 65 | loss: 0.8872  | test_accuracy: 0.62506 |  0:00:33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:53:55,665] Trial 12 finished with value: 0.6358500256805342 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 3, 'gamma': 1.6356916703878845, 'lambda_sparse': 1.008047396335102e-05, 'lr': 0.0007471987136054405, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 9 with value: 0.6512583461736005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66 | loss: 0.89158 | test_accuracy: 0.62404 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_test_accuracy = 0.63585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.5389  | test_accuracy: 0.36569 |  0:00:00s\n",
      "epoch 1  | loss: 1.77875 | test_accuracy: 0.4905  |  0:00:01s\n",
      "epoch 2  | loss: 1.40751 | test_accuracy: 0.52748 |  0:00:01s\n",
      "epoch 3  | loss: 1.23738 | test_accuracy: 0.55881 |  0:00:02s\n",
      "epoch 4  | loss: 1.13612 | test_accuracy: 0.5737  |  0:00:03s\n",
      "epoch 5  | loss: 1.08921 | test_accuracy: 0.56959 |  0:00:03s\n",
      "epoch 6  | loss: 1.05497 | test_accuracy: 0.58706 |  0:00:04s\n",
      "epoch 7  | loss: 1.02365 | test_accuracy: 0.59476 |  0:00:05s\n",
      "epoch 8  | loss: 1.01434 | test_accuracy: 0.58141 |  0:00:05s\n",
      "epoch 9  | loss: 1.00358 | test_accuracy: 0.59887 |  0:00:06s\n",
      "epoch 10 | loss: 0.98428 | test_accuracy: 0.59938 |  0:00:06s\n",
      "epoch 11 | loss: 0.9786  | test_accuracy: 0.59784 |  0:00:07s\n",
      "epoch 12 | loss: 0.95991 | test_accuracy: 0.6076  |  0:00:08s\n",
      "epoch 13 | loss: 0.94875 | test_accuracy: 0.60247 |  0:00:08s\n",
      "epoch 14 | loss: 0.9436  | test_accuracy: 0.6112  |  0:00:09s\n",
      "epoch 15 | loss: 0.9406  | test_accuracy: 0.61325 |  0:00:10s\n",
      "epoch 16 | loss: 0.93236 | test_accuracy: 0.62609 |  0:00:10s\n",
      "epoch 17 | loss: 0.91609 | test_accuracy: 0.62096 |  0:00:11s\n",
      "epoch 18 | loss: 0.91479 | test_accuracy: 0.61993 |  0:00:11s\n",
      "epoch 19 | loss: 0.90991 | test_accuracy: 0.62096 |  0:00:12s\n",
      "epoch 20 | loss: 0.90095 | test_accuracy: 0.61685 |  0:00:13s\n",
      "epoch 21 | loss: 0.89415 | test_accuracy: 0.61993 |  0:00:13s\n",
      "epoch 22 | loss: 0.89608 | test_accuracy: 0.62198 |  0:00:14s\n",
      "epoch 23 | loss: 0.88089 | test_accuracy: 0.61685 |  0:00:14s\n",
      "epoch 24 | loss: 0.88524 | test_accuracy: 0.61736 |  0:00:15s\n",
      "epoch 25 | loss: 0.88579 | test_accuracy: 0.62712 |  0:00:16s\n",
      "epoch 26 | loss: 0.87826 | test_accuracy: 0.62198 |  0:00:16s\n",
      "epoch 27 | loss: 0.87306 | test_accuracy: 0.62763 |  0:00:17s\n",
      "epoch 28 | loss: 0.87137 | test_accuracy: 0.63174 |  0:00:17s\n",
      "epoch 29 | loss: 0.87624 | test_accuracy: 0.62763 |  0:00:18s\n",
      "epoch 30 | loss: 0.87051 | test_accuracy: 0.6225  |  0:00:19s\n",
      "epoch 31 | loss: 0.87977 | test_accuracy: 0.62712 |  0:00:19s\n",
      "epoch 32 | loss: 0.85713 | test_accuracy: 0.6338  |  0:00:20s\n",
      "epoch 33 | loss: 0.85365 | test_accuracy: 0.6225  |  0:00:20s\n",
      "epoch 34 | loss: 0.85164 | test_accuracy: 0.62506 |  0:00:21s\n",
      "epoch 35 | loss: 0.84932 | test_accuracy: 0.62815 |  0:00:22s\n",
      "epoch 36 | loss: 0.84477 | test_accuracy: 0.62661 |  0:00:22s\n",
      "epoch 37 | loss: 0.84476 | test_accuracy: 0.62506 |  0:00:23s\n",
      "epoch 38 | loss: 0.84441 | test_accuracy: 0.6302  |  0:00:23s\n",
      "epoch 39 | loss: 0.84537 | test_accuracy: 0.63071 |  0:00:24s\n",
      "epoch 40 | loss: 0.84026 | test_accuracy: 0.63431 |  0:00:25s\n",
      "epoch 41 | loss: 0.84003 | test_accuracy: 0.63636 |  0:00:25s\n",
      "epoch 42 | loss: 0.83539 | test_accuracy: 0.62558 |  0:00:26s\n",
      "epoch 43 | loss: 0.8378  | test_accuracy: 0.62815 |  0:00:27s\n",
      "epoch 44 | loss: 0.83063 | test_accuracy: 0.63071 |  0:00:27s\n",
      "epoch 45 | loss: 0.82855 | test_accuracy: 0.63739 |  0:00:28s\n",
      "epoch 46 | loss: 0.82419 | test_accuracy: 0.63893 |  0:00:28s\n",
      "epoch 47 | loss: 0.82086 | test_accuracy: 0.63123 |  0:00:29s\n",
      "epoch 48 | loss: 0.82298 | test_accuracy: 0.62609 |  0:00:30s\n",
      "epoch 49 | loss: 0.82259 | test_accuracy: 0.63174 |  0:00:30s\n",
      "epoch 50 | loss: 0.81715 | test_accuracy: 0.64304 |  0:00:31s\n",
      "epoch 51 | loss: 0.81033 | test_accuracy: 0.63945 |  0:00:32s\n",
      "epoch 52 | loss: 0.81563 | test_accuracy: 0.64458 |  0:00:32s\n",
      "epoch 53 | loss: 0.81283 | test_accuracy: 0.64407 |  0:00:33s\n",
      "epoch 54 | loss: 0.81968 | test_accuracy: 0.64869 |  0:00:34s\n",
      "epoch 55 | loss: 0.80985 | test_accuracy: 0.63945 |  0:00:34s\n",
      "epoch 56 | loss: 0.80159 | test_accuracy: 0.64664 |  0:00:35s\n",
      "epoch 57 | loss: 0.79909 | test_accuracy: 0.6415  |  0:00:36s\n",
      "epoch 58 | loss: 0.79984 | test_accuracy: 0.63739 |  0:00:36s\n",
      "epoch 59 | loss: 0.79436 | test_accuracy: 0.64304 |  0:00:37s\n",
      "epoch 60 | loss: 0.79848 | test_accuracy: 0.63482 |  0:00:37s\n",
      "epoch 61 | loss: 0.79091 | test_accuracy: 0.63893 |  0:00:38s\n",
      "epoch 62 | loss: 0.7933  | test_accuracy: 0.64715 |  0:00:39s\n",
      "epoch 63 | loss: 0.79614 | test_accuracy: 0.64458 |  0:00:39s\n",
      "epoch 64 | loss: 0.79124 | test_accuracy: 0.6528  |  0:00:40s\n",
      "epoch 65 | loss: 0.79355 | test_accuracy: 0.64664 |  0:00:40s\n",
      "epoch 66 | loss: 0.78127 | test_accuracy: 0.64458 |  0:00:41s\n",
      "epoch 67 | loss: 0.78669 | test_accuracy: 0.64715 |  0:00:42s\n",
      "epoch 68 | loss: 0.79603 | test_accuracy: 0.63585 |  0:00:42s\n",
      "epoch 69 | loss: 0.78951 | test_accuracy: 0.6415  |  0:00:43s\n",
      "epoch 70 | loss: 0.79329 | test_accuracy: 0.6528  |  0:00:44s\n",
      "epoch 71 | loss: 0.78988 | test_accuracy: 0.65639 |  0:00:44s\n",
      "epoch 72 | loss: 0.78168 | test_accuracy: 0.65999 |  0:00:45s\n",
      "epoch 73 | loss: 0.7854  | test_accuracy: 0.65023 |  0:00:46s\n",
      "epoch 74 | loss: 0.77678 | test_accuracy: 0.65691 |  0:00:46s\n",
      "epoch 75 | loss: 0.77768 | test_accuracy: 0.65794 |  0:00:47s\n",
      "epoch 76 | loss: 0.77753 | test_accuracy: 0.65331 |  0:00:47s\n",
      "epoch 77 | loss: 0.77378 | test_accuracy: 0.65023 |  0:00:48s\n",
      "epoch 78 | loss: 0.76792 | test_accuracy: 0.65126 |  0:00:49s\n",
      "epoch 79 | loss: 0.77011 | test_accuracy: 0.65794 |  0:00:50s\n",
      "epoch 80 | loss: 0.76911 | test_accuracy: 0.66307 |  0:00:50s\n",
      "epoch 81 | loss: 0.77587 | test_accuracy: 0.65999 |  0:00:51s\n",
      "epoch 82 | loss: 0.76602 | test_accuracy: 0.65588 |  0:00:52s\n",
      "epoch 83 | loss: 0.76873 | test_accuracy: 0.66667 |  0:00:52s\n",
      "epoch 84 | loss: 0.75732 | test_accuracy: 0.66359 |  0:00:53s\n",
      "epoch 85 | loss: 0.75866 | test_accuracy: 0.65537 |  0:00:54s\n",
      "epoch 86 | loss: 0.75953 | test_accuracy: 0.65331 |  0:00:54s\n",
      "epoch 87 | loss: 0.75747 | test_accuracy: 0.66461 |  0:00:55s\n",
      "epoch 88 | loss: 0.75979 | test_accuracy: 0.65742 |  0:00:56s\n",
      "epoch 89 | loss: 0.7542  | test_accuracy: 0.66461 |  0:00:56s\n",
      "epoch 90 | loss: 0.75553 | test_accuracy: 0.66667 |  0:00:57s\n",
      "epoch 91 | loss: 0.75456 | test_accuracy: 0.65383 |  0:00:58s\n",
      "epoch 92 | loss: 0.74878 | test_accuracy: 0.66153 |  0:00:58s\n",
      "epoch 93 | loss: 0.75374 | test_accuracy: 0.66204 |  0:00:59s\n",
      "\n",
      "Early stopping occurred at epoch 93 with best_epoch = 83 and best_test_accuracy = 0.66667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:54:55,299] Trial 13 finished with value: 0.6666666666666666 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.000577900836613, 'lambda_sparse': 5.5022590042154394e-05, 'lr': 0.0017850922152588724, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 13 with value: 0.6666666666666666.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.41271 | test_accuracy: 0.45763 |  0:00:00s\n",
      "epoch 1  | loss: 1.53628 | test_accuracy: 0.51926 |  0:00:01s\n",
      "epoch 2  | loss: 1.2854  | test_accuracy: 0.51104 |  0:00:02s\n",
      "epoch 3  | loss: 1.16787 | test_accuracy: 0.52286 |  0:00:03s\n",
      "epoch 4  | loss: 1.12447 | test_accuracy: 0.55162 |  0:00:04s\n",
      "epoch 5  | loss: 1.08098 | test_accuracy: 0.57576 |  0:00:04s\n",
      "epoch 6  | loss: 1.04532 | test_accuracy: 0.57833 |  0:00:05s\n",
      "epoch 7  | loss: 1.02117 | test_accuracy: 0.57884 |  0:00:06s\n",
      "epoch 8  | loss: 1.0015  | test_accuracy: 0.58089 |  0:00:07s\n",
      "epoch 9  | loss: 0.9684  | test_accuracy: 0.5886  |  0:00:08s\n",
      "epoch 10 | loss: 0.97098 | test_accuracy: 0.60092 |  0:00:09s\n",
      "epoch 11 | loss: 0.9671  | test_accuracy: 0.61376 |  0:00:10s\n",
      "epoch 12 | loss: 0.95773 | test_accuracy: 0.60144 |  0:00:10s\n",
      "epoch 13 | loss: 0.95349 | test_accuracy: 0.60657 |  0:00:11s\n",
      "epoch 14 | loss: 0.93991 | test_accuracy: 0.61171 |  0:00:12s\n",
      "epoch 15 | loss: 0.93208 | test_accuracy: 0.59733 |  0:00:13s\n",
      "epoch 16 | loss: 0.92497 | test_accuracy: 0.60966 |  0:00:13s\n",
      "epoch 17 | loss: 0.91053 | test_accuracy: 0.61222 |  0:00:14s\n",
      "epoch 18 | loss: 0.90364 | test_accuracy: 0.60966 |  0:00:15s\n",
      "epoch 19 | loss: 0.89569 | test_accuracy: 0.61685 |  0:00:16s\n",
      "epoch 20 | loss: 0.88567 | test_accuracy: 0.62712 |  0:00:17s\n",
      "epoch 21 | loss: 0.88474 | test_accuracy: 0.63277 |  0:00:17s\n",
      "epoch 22 | loss: 0.87994 | test_accuracy: 0.62609 |  0:00:18s\n",
      "epoch 23 | loss: 0.87056 | test_accuracy: 0.62917 |  0:00:19s\n",
      "epoch 24 | loss: 0.86094 | test_accuracy: 0.62917 |  0:00:20s\n",
      "epoch 25 | loss: 0.85638 | test_accuracy: 0.6338  |  0:00:20s\n",
      "epoch 26 | loss: 0.86008 | test_accuracy: 0.62969 |  0:00:21s\n",
      "epoch 27 | loss: 0.85792 | test_accuracy: 0.63328 |  0:00:22s\n",
      "epoch 28 | loss: 0.86068 | test_accuracy: 0.63328 |  0:00:23s\n",
      "epoch 29 | loss: 0.85338 | test_accuracy: 0.62917 |  0:00:23s\n",
      "epoch 30 | loss: 0.85291 | test_accuracy: 0.62763 |  0:00:24s\n",
      "epoch 31 | loss: 0.84526 | test_accuracy: 0.63482 |  0:00:25s\n",
      "epoch 32 | loss: 0.84049 | test_accuracy: 0.6338  |  0:00:26s\n",
      "epoch 33 | loss: 0.83636 | test_accuracy: 0.6338  |  0:00:27s\n",
      "epoch 34 | loss: 0.83254 | test_accuracy: 0.62455 |  0:00:28s\n",
      "epoch 35 | loss: 0.83467 | test_accuracy: 0.62096 |  0:00:29s\n",
      "epoch 36 | loss: 0.82658 | test_accuracy: 0.6189  |  0:00:29s\n",
      "epoch 37 | loss: 0.82489 | test_accuracy: 0.62917 |  0:00:30s\n",
      "epoch 38 | loss: 0.82517 | test_accuracy: 0.62404 |  0:00:31s\n",
      "epoch 39 | loss: 0.82153 | test_accuracy: 0.63585 |  0:00:32s\n",
      "epoch 40 | loss: 0.81467 | test_accuracy: 0.63585 |  0:00:32s\n",
      "epoch 41 | loss: 0.81413 | test_accuracy: 0.62815 |  0:00:33s\n",
      "epoch 42 | loss: 0.81295 | test_accuracy: 0.63071 |  0:00:34s\n",
      "epoch 43 | loss: 0.80644 | test_accuracy: 0.6415  |  0:00:35s\n",
      "epoch 44 | loss: 0.81022 | test_accuracy: 0.6415  |  0:00:36s\n",
      "epoch 45 | loss: 0.8041  | test_accuracy: 0.64664 |  0:00:36s\n",
      "epoch 46 | loss: 0.81031 | test_accuracy: 0.64818 |  0:00:37s\n",
      "epoch 47 | loss: 0.80351 | test_accuracy: 0.63945 |  0:00:38s\n",
      "epoch 48 | loss: 0.79801 | test_accuracy: 0.6415  |  0:00:39s\n",
      "epoch 49 | loss: 0.79859 | test_accuracy: 0.64201 |  0:00:40s\n",
      "epoch 50 | loss: 0.78846 | test_accuracy: 0.64664 |  0:00:41s\n",
      "epoch 51 | loss: 0.78581 | test_accuracy: 0.64099 |  0:00:42s\n",
      "epoch 52 | loss: 0.78581 | test_accuracy: 0.64715 |  0:00:42s\n",
      "epoch 53 | loss: 0.78437 | test_accuracy: 0.64612 |  0:00:43s\n",
      "epoch 54 | loss: 0.78613 | test_accuracy: 0.65229 |  0:00:44s\n",
      "epoch 55 | loss: 0.79065 | test_accuracy: 0.65177 |  0:00:45s\n",
      "epoch 56 | loss: 0.78797 | test_accuracy: 0.65126 |  0:00:45s\n",
      "epoch 57 | loss: 0.77899 | test_accuracy: 0.64664 |  0:00:46s\n",
      "epoch 58 | loss: 0.77073 | test_accuracy: 0.65126 |  0:00:47s\n",
      "epoch 59 | loss: 0.77974 | test_accuracy: 0.6451  |  0:00:48s\n",
      "epoch 60 | loss: 0.77757 | test_accuracy: 0.64561 |  0:00:48s\n",
      "epoch 61 | loss: 0.77588 | test_accuracy: 0.65074 |  0:00:49s\n",
      "epoch 62 | loss: 0.77863 | test_accuracy: 0.64047 |  0:00:50s\n",
      "epoch 63 | loss: 0.77201 | test_accuracy: 0.65074 |  0:00:51s\n",
      "epoch 64 | loss: 0.76443 | test_accuracy: 0.6415  |  0:00:51s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_test_accuracy = 0.65229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:55:47,385] Trial 14 finished with value: 0.6522855675398048 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 5, 'gamma': 1.0133346559903844, 'lambda_sparse': 0.0006121875163466326, 'lr': 0.002422868968579807, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 13 with value: 0.6666666666666666.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.61212 | test_accuracy: 0.36415 |  0:00:00s\n",
      "epoch 1  | loss: 1.81682 | test_accuracy: 0.48998 |  0:00:01s\n",
      "epoch 2  | loss: 1.42057 | test_accuracy: 0.5244  |  0:00:02s\n",
      "epoch 3  | loss: 1.25266 | test_accuracy: 0.54391 |  0:00:02s\n",
      "epoch 4  | loss: 1.20814 | test_accuracy: 0.5511  |  0:00:03s\n",
      "epoch 5  | loss: 1.14706 | test_accuracy: 0.53775 |  0:00:04s\n",
      "epoch 6  | loss: 1.11498 | test_accuracy: 0.566   |  0:00:05s\n",
      "epoch 7  | loss: 1.09449 | test_accuracy: 0.57627 |  0:00:05s\n",
      "epoch 8  | loss: 1.07186 | test_accuracy: 0.57165 |  0:00:06s\n",
      "epoch 9  | loss: 1.0536  | test_accuracy: 0.58141 |  0:00:07s\n",
      "epoch 10 | loss: 1.03467 | test_accuracy: 0.59014 |  0:00:08s\n",
      "epoch 11 | loss: 1.02368 | test_accuracy: 0.59476 |  0:00:08s\n",
      "epoch 12 | loss: 0.99969 | test_accuracy: 0.60092 |  0:00:09s\n",
      "epoch 13 | loss: 0.98396 | test_accuracy: 0.61376 |  0:00:10s\n",
      "epoch 14 | loss: 0.96355 | test_accuracy: 0.60298 |  0:00:11s\n",
      "epoch 15 | loss: 0.9604  | test_accuracy: 0.61222 |  0:00:11s\n",
      "epoch 16 | loss: 0.94983 | test_accuracy: 0.60966 |  0:00:12s\n",
      "epoch 17 | loss: 0.93402 | test_accuracy: 0.62661 |  0:00:13s\n",
      "epoch 18 | loss: 0.951   | test_accuracy: 0.62044 |  0:00:14s\n",
      "epoch 19 | loss: 0.94116 | test_accuracy: 0.61171 |  0:00:14s\n",
      "epoch 20 | loss: 0.93247 | test_accuracy: 0.62661 |  0:00:15s\n",
      "epoch 21 | loss: 0.91508 | test_accuracy: 0.61222 |  0:00:16s\n",
      "epoch 22 | loss: 0.90475 | test_accuracy: 0.61633 |  0:00:17s\n",
      "epoch 23 | loss: 0.90804 | test_accuracy: 0.61787 |  0:00:17s\n",
      "epoch 24 | loss: 0.90363 | test_accuracy: 0.6112  |  0:00:18s\n",
      "epoch 25 | loss: 0.90382 | test_accuracy: 0.62558 |  0:00:19s\n",
      "epoch 26 | loss: 0.89861 | test_accuracy: 0.60863 |  0:00:20s\n",
      "epoch 27 | loss: 0.88756 | test_accuracy: 0.61325 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_test_accuracy = 0.62661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:56:08,732] Trial 15 finished with value: 0.6266050333846944 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 5, 'gamma': 1.0196968050631112, 'lambda_sparse': 0.0007641098708318258, 'lr': 0.001545626465748313, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 13 with value: 0.6666666666666666.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.53642 | test_accuracy: 0.36672 |  0:00:00s\n",
      "epoch 1  | loss: 1.76109 | test_accuracy: 0.49718 |  0:00:01s\n",
      "epoch 2  | loss: 1.38747 | test_accuracy: 0.54545 |  0:00:01s\n",
      "epoch 3  | loss: 1.23205 | test_accuracy: 0.54391 |  0:00:02s\n",
      "epoch 4  | loss: 1.15708 | test_accuracy: 0.57062 |  0:00:03s\n",
      "epoch 5  | loss: 1.12277 | test_accuracy: 0.57833 |  0:00:03s\n",
      "epoch 6  | loss: 1.08253 | test_accuracy: 0.58552 |  0:00:04s\n",
      "epoch 7  | loss: 1.05548 | test_accuracy: 0.59219 |  0:00:04s\n",
      "epoch 8  | loss: 1.03519 | test_accuracy: 0.585   |  0:00:05s\n",
      "epoch 9  | loss: 1.01246 | test_accuracy: 0.58295 |  0:00:06s\n",
      "epoch 10 | loss: 0.99302 | test_accuracy: 0.59219 |  0:00:06s\n",
      "epoch 11 | loss: 0.98395 | test_accuracy: 0.59322 |  0:00:07s\n",
      "epoch 12 | loss: 0.96372 | test_accuracy: 0.60452 |  0:00:08s\n",
      "epoch 13 | loss: 0.95695 | test_accuracy: 0.60298 |  0:00:08s\n",
      "epoch 14 | loss: 0.9546  | test_accuracy: 0.60401 |  0:00:09s\n",
      "epoch 15 | loss: 0.93375 | test_accuracy: 0.5999  |  0:00:09s\n",
      "epoch 16 | loss: 0.92721 | test_accuracy: 0.60452 |  0:00:10s\n",
      "epoch 17 | loss: 0.92491 | test_accuracy: 0.61325 |  0:00:10s\n",
      "epoch 18 | loss: 0.91459 | test_accuracy: 0.62096 |  0:00:11s\n",
      "epoch 19 | loss: 0.9033  | test_accuracy: 0.62044 |  0:00:12s\n",
      "epoch 20 | loss: 0.9002  | test_accuracy: 0.61736 |  0:00:12s\n",
      "epoch 21 | loss: 0.89632 | test_accuracy: 0.62969 |  0:00:13s\n",
      "epoch 22 | loss: 0.88257 | test_accuracy: 0.63945 |  0:00:14s\n",
      "epoch 23 | loss: 0.88539 | test_accuracy: 0.62917 |  0:00:14s\n",
      "epoch 24 | loss: 0.88524 | test_accuracy: 0.62763 |  0:00:15s\n",
      "epoch 25 | loss: 0.87623 | test_accuracy: 0.62147 |  0:00:15s\n",
      "epoch 26 | loss: 0.87273 | test_accuracy: 0.63534 |  0:00:16s\n",
      "epoch 27 | loss: 0.86597 | test_accuracy: 0.63893 |  0:00:17s\n",
      "epoch 28 | loss: 0.86455 | test_accuracy: 0.64818 |  0:00:17s\n",
      "epoch 29 | loss: 0.86842 | test_accuracy: 0.63688 |  0:00:18s\n",
      "epoch 30 | loss: 0.85949 | test_accuracy: 0.6302  |  0:00:19s\n",
      "epoch 31 | loss: 0.85897 | test_accuracy: 0.63534 |  0:00:19s\n",
      "epoch 32 | loss: 0.85207 | test_accuracy: 0.62866 |  0:00:20s\n",
      "epoch 33 | loss: 0.84846 | test_accuracy: 0.63482 |  0:00:21s\n",
      "epoch 34 | loss: 0.84774 | test_accuracy: 0.63636 |  0:00:21s\n",
      "epoch 35 | loss: 0.85401 | test_accuracy: 0.6379  |  0:00:22s\n",
      "epoch 36 | loss: 0.84503 | test_accuracy: 0.63431 |  0:00:23s\n",
      "epoch 37 | loss: 0.83857 | test_accuracy: 0.64355 |  0:00:23s\n",
      "epoch 38 | loss: 0.84039 | test_accuracy: 0.64458 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_test_accuracy = 0.64818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:56:33,299] Trial 16 finished with value: 0.6481766820749871 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.000425057304706, 'lambda_sparse': 0.0009195328261470907, 'lr': 0.0019168013635256715, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 13 with value: 0.6666666666666666.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.87145 | test_accuracy: 0.16281 |  0:00:00s\n",
      "epoch 1  | loss: 4.52846 | test_accuracy: 0.18336 |  0:00:01s\n",
      "epoch 2  | loss: 4.31675 | test_accuracy: 0.19312 |  0:00:02s\n",
      "epoch 3  | loss: 4.05555 | test_accuracy: 0.20699 |  0:00:03s\n",
      "epoch 4  | loss: 3.80727 | test_accuracy: 0.21623 |  0:00:03s\n",
      "epoch 5  | loss: 3.58265 | test_accuracy: 0.24499 |  0:00:04s\n",
      "epoch 6  | loss: 3.4073  | test_accuracy: 0.24653 |  0:00:05s\n",
      "epoch 7  | loss: 3.18917 | test_accuracy: 0.26091 |  0:00:06s\n",
      "epoch 8  | loss: 2.95419 | test_accuracy: 0.28865 |  0:00:07s\n",
      "epoch 9  | loss: 2.77551 | test_accuracy: 0.31587 |  0:00:07s\n",
      "epoch 10 | loss: 2.55039 | test_accuracy: 0.34155 |  0:00:08s\n",
      "epoch 11 | loss: 2.40426 | test_accuracy: 0.36723 |  0:00:09s\n",
      "epoch 12 | loss: 2.2646  | test_accuracy: 0.38315 |  0:00:10s\n",
      "epoch 13 | loss: 2.12247 | test_accuracy: 0.40164 |  0:00:10s\n",
      "epoch 14 | loss: 2.01978 | test_accuracy: 0.40421 |  0:00:11s\n",
      "epoch 15 | loss: 1.95399 | test_accuracy: 0.42886 |  0:00:12s\n",
      "epoch 16 | loss: 1.84172 | test_accuracy: 0.44479 |  0:00:13s\n",
      "epoch 17 | loss: 1.77873 | test_accuracy: 0.45198 |  0:00:13s\n",
      "epoch 18 | loss: 1.69292 | test_accuracy: 0.46174 |  0:00:14s\n",
      "epoch 19 | loss: 1.65718 | test_accuracy: 0.47252 |  0:00:15s\n",
      "epoch 20 | loss: 1.58675 | test_accuracy: 0.48279 |  0:00:16s\n",
      "epoch 21 | loss: 1.56823 | test_accuracy: 0.48588 |  0:00:17s\n",
      "epoch 22 | loss: 1.52579 | test_accuracy: 0.49153 |  0:00:17s\n",
      "epoch 23 | loss: 1.48959 | test_accuracy: 0.48947 |  0:00:18s\n",
      "epoch 24 | loss: 1.45386 | test_accuracy: 0.49512 |  0:00:19s\n",
      "epoch 25 | loss: 1.41833 | test_accuracy: 0.50847 |  0:00:20s\n",
      "epoch 26 | loss: 1.39882 | test_accuracy: 0.51104 |  0:00:21s\n",
      "epoch 27 | loss: 1.35616 | test_accuracy: 0.51515 |  0:00:21s\n",
      "epoch 28 | loss: 1.35341 | test_accuracy: 0.52131 |  0:00:22s\n",
      "epoch 29 | loss: 1.32449 | test_accuracy: 0.52491 |  0:00:23s\n",
      "epoch 30 | loss: 1.33209 | test_accuracy: 0.52799 |  0:00:24s\n",
      "epoch 31 | loss: 1.29461 | test_accuracy: 0.52799 |  0:00:25s\n",
      "epoch 32 | loss: 1.29642 | test_accuracy: 0.53159 |  0:00:25s\n",
      "epoch 33 | loss: 1.27945 | test_accuracy: 0.53518 |  0:00:26s\n",
      "epoch 34 | loss: 1.2601  | test_accuracy: 0.53056 |  0:00:27s\n",
      "epoch 35 | loss: 1.23599 | test_accuracy: 0.53929 |  0:00:28s\n",
      "epoch 36 | loss: 1.23791 | test_accuracy: 0.54032 |  0:00:28s\n",
      "epoch 37 | loss: 1.23141 | test_accuracy: 0.53878 |  0:00:29s\n",
      "epoch 38 | loss: 1.22555 | test_accuracy: 0.5434  |  0:00:30s\n",
      "epoch 39 | loss: 1.19899 | test_accuracy: 0.54854 |  0:00:31s\n",
      "epoch 40 | loss: 1.20006 | test_accuracy: 0.55213 |  0:00:31s\n",
      "epoch 41 | loss: 1.19747 | test_accuracy: 0.55367 |  0:00:32s\n",
      "epoch 42 | loss: 1.18827 | test_accuracy: 0.54443 |  0:00:33s\n",
      "epoch 43 | loss: 1.16874 | test_accuracy: 0.54905 |  0:00:34s\n",
      "epoch 44 | loss: 1.16216 | test_accuracy: 0.54597 |  0:00:34s\n",
      "epoch 45 | loss: 1.16497 | test_accuracy: 0.5511  |  0:00:35s\n",
      "epoch 46 | loss: 1.15592 | test_accuracy: 0.54802 |  0:00:36s\n",
      "epoch 47 | loss: 1.15671 | test_accuracy: 0.55213 |  0:00:37s\n",
      "epoch 48 | loss: 1.12895 | test_accuracy: 0.55265 |  0:00:37s\n",
      "epoch 49 | loss: 1.13911 | test_accuracy: 0.54751 |  0:00:38s\n",
      "epoch 50 | loss: 1.14011 | test_accuracy: 0.5547  |  0:00:39s\n",
      "epoch 51 | loss: 1.11624 | test_accuracy: 0.55881 |  0:00:40s\n",
      "epoch 52 | loss: 1.13463 | test_accuracy: 0.55881 |  0:00:40s\n",
      "epoch 53 | loss: 1.11011 | test_accuracy: 0.55316 |  0:00:41s\n",
      "epoch 54 | loss: 1.12084 | test_accuracy: 0.56703 |  0:00:42s\n",
      "epoch 55 | loss: 1.11226 | test_accuracy: 0.57062 |  0:00:43s\n",
      "epoch 56 | loss: 1.1083  | test_accuracy: 0.56292 |  0:00:43s\n",
      "epoch 57 | loss: 1.11684 | test_accuracy: 0.56292 |  0:00:44s\n",
      "epoch 58 | loss: 1.11432 | test_accuracy: 0.5624  |  0:00:45s\n",
      "epoch 59 | loss: 1.10445 | test_accuracy: 0.566   |  0:00:46s\n",
      "epoch 60 | loss: 1.0924  | test_accuracy: 0.56446 |  0:00:46s\n",
      "epoch 61 | loss: 1.08583 | test_accuracy: 0.57165 |  0:00:47s\n",
      "epoch 62 | loss: 1.08943 | test_accuracy: 0.57473 |  0:00:48s\n",
      "epoch 63 | loss: 1.08308 | test_accuracy: 0.5737  |  0:00:49s\n",
      "epoch 64 | loss: 1.0835  | test_accuracy: 0.56138 |  0:00:49s\n",
      "epoch 65 | loss: 1.09444 | test_accuracy: 0.56189 |  0:00:50s\n",
      "epoch 66 | loss: 1.06974 | test_accuracy: 0.56189 |  0:00:51s\n",
      "epoch 67 | loss: 1.07353 | test_accuracy: 0.5624  |  0:00:52s\n",
      "epoch 68 | loss: 1.08112 | test_accuracy: 0.56394 |  0:00:52s\n",
      "epoch 69 | loss: 1.06272 | test_accuracy: 0.57114 |  0:00:53s\n",
      "epoch 70 | loss: 1.06516 | test_accuracy: 0.57268 |  0:00:54s\n",
      "epoch 71 | loss: 1.05936 | test_accuracy: 0.56959 |  0:00:55s\n",
      "epoch 72 | loss: 1.0661  | test_accuracy: 0.57062 |  0:00:55s\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 62 and best_test_accuracy = 0.57473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:57:29,574] Trial 17 finished with value: 0.5747303543913713 and parameters: {'n_d': 32, 'n_a': 8, 'n_steps': 6, 'gamma': 1.1089359807078438, 'lambda_sparse': 0.00026575048016036013, 'lr': 0.00037815477654966253, 'mask_type': 'sparsemax', 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 13 with value: 0.6666666666666666.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.86968 | test_accuracy: 0.56754 |  0:00:00s\n",
      "epoch 1  | loss: 1.16378 | test_accuracy: 0.58808 |  0:00:01s\n",
      "epoch 2  | loss: 1.05134 | test_accuracy: 0.60144 |  0:00:02s\n",
      "epoch 3  | loss: 0.98194 | test_accuracy: 0.6112  |  0:00:02s\n",
      "epoch 4  | loss: 0.96133 | test_accuracy: 0.61171 |  0:00:03s\n",
      "epoch 5  | loss: 0.94409 | test_accuracy: 0.61839 |  0:00:04s\n",
      "epoch 6  | loss: 0.92554 | test_accuracy: 0.60555 |  0:00:04s\n",
      "epoch 7  | loss: 0.91248 | test_accuracy: 0.60863 |  0:00:05s\n",
      "epoch 8  | loss: 0.8905  | test_accuracy: 0.62301 |  0:00:06s\n",
      "epoch 9  | loss: 0.88582 | test_accuracy: 0.63071 |  0:00:06s\n",
      "epoch 10 | loss: 0.87308 | test_accuracy: 0.61993 |  0:00:07s\n",
      "epoch 11 | loss: 0.86082 | test_accuracy: 0.62917 |  0:00:08s\n",
      "epoch 12 | loss: 0.85468 | test_accuracy: 0.6379  |  0:00:08s\n",
      "epoch 13 | loss: 0.85059 | test_accuracy: 0.63277 |  0:00:09s\n",
      "epoch 14 | loss: 0.83974 | test_accuracy: 0.63585 |  0:00:09s\n",
      "epoch 15 | loss: 0.83892 | test_accuracy: 0.62352 |  0:00:10s\n",
      "epoch 16 | loss: 0.82936 | test_accuracy: 0.6415  |  0:00:11s\n",
      "epoch 17 | loss: 0.82463 | test_accuracy: 0.62866 |  0:00:11s\n",
      "epoch 18 | loss: 0.8234  | test_accuracy: 0.63482 |  0:00:12s\n",
      "epoch 19 | loss: 0.81964 | test_accuracy: 0.65177 |  0:00:13s\n",
      "epoch 20 | loss: 0.81014 | test_accuracy: 0.65229 |  0:00:13s\n",
      "epoch 21 | loss: 0.79939 | test_accuracy: 0.64766 |  0:00:14s\n",
      "epoch 22 | loss: 0.79316 | test_accuracy: 0.65896 |  0:00:15s\n",
      "epoch 23 | loss: 0.7905  | test_accuracy: 0.64612 |  0:00:15s\n",
      "epoch 24 | loss: 0.79378 | test_accuracy: 0.63945 |  0:00:16s\n",
      "epoch 25 | loss: 0.78733 | test_accuracy: 0.63996 |  0:00:16s\n",
      "epoch 26 | loss: 0.77707 | test_accuracy: 0.64818 |  0:00:17s\n",
      "epoch 27 | loss: 0.77338 | test_accuracy: 0.65948 |  0:00:18s\n",
      "epoch 28 | loss: 0.76954 | test_accuracy: 0.65639 |  0:00:18s\n",
      "epoch 29 | loss: 0.76434 | test_accuracy: 0.65537 |  0:00:19s\n",
      "epoch 30 | loss: 0.76223 | test_accuracy: 0.65742 |  0:00:20s\n",
      "epoch 31 | loss: 0.75983 | test_accuracy: 0.6641  |  0:00:20s\n",
      "epoch 32 | loss: 0.75448 | test_accuracy: 0.65845 |  0:00:21s\n",
      "epoch 33 | loss: 0.7455  | test_accuracy: 0.66872 |  0:00:22s\n",
      "epoch 34 | loss: 0.75345 | test_accuracy: 0.6754  |  0:00:22s\n",
      "epoch 35 | loss: 0.73903 | test_accuracy: 0.67899 |  0:00:23s\n",
      "epoch 36 | loss: 0.74304 | test_accuracy: 0.66718 |  0:00:24s\n",
      "epoch 37 | loss: 0.73002 | test_accuracy: 0.66923 |  0:00:24s\n",
      "epoch 38 | loss: 0.73308 | test_accuracy: 0.66615 |  0:00:25s\n",
      "epoch 39 | loss: 0.72369 | test_accuracy: 0.66564 |  0:00:25s\n",
      "epoch 40 | loss: 0.71923 | test_accuracy: 0.66564 |  0:00:26s\n",
      "epoch 41 | loss: 0.72244 | test_accuracy: 0.66513 |  0:00:27s\n",
      "epoch 42 | loss: 0.72226 | test_accuracy: 0.6867  |  0:00:27s\n",
      "epoch 43 | loss: 0.71433 | test_accuracy: 0.6831  |  0:00:28s\n",
      "epoch 44 | loss: 0.71234 | test_accuracy: 0.67386 |  0:00:29s\n",
      "epoch 45 | loss: 0.72164 | test_accuracy: 0.6754  |  0:00:29s\n",
      "epoch 46 | loss: 0.72175 | test_accuracy: 0.67643 |  0:00:30s\n",
      "epoch 47 | loss: 0.70921 | test_accuracy: 0.68105 |  0:00:31s\n",
      "epoch 48 | loss: 0.69587 | test_accuracy: 0.6831  |  0:00:31s\n",
      "epoch 49 | loss: 0.70014 | test_accuracy: 0.68413 |  0:00:32s\n",
      "epoch 50 | loss: 0.68901 | test_accuracy: 0.68567 |  0:00:33s\n",
      "epoch 51 | loss: 0.68928 | test_accuracy: 0.67899 |  0:00:33s\n",
      "epoch 52 | loss: 0.67945 | test_accuracy: 0.68567 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_test_accuracy = 0.6867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:58:04,163] Trial 18 finished with value: 0.6866974833076528 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.1501946000609145, 'lambda_sparse': 0.0015522355263382782, 'lr': 0.0034457975361170466, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 18 with value: 0.6866974833076528.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.81752 | test_accuracy: 0.54802 |  0:00:00s\n",
      "epoch 1  | loss: 1.15888 | test_accuracy: 0.56857 |  0:00:01s\n",
      "epoch 2  | loss: 1.0497  | test_accuracy: 0.60709 |  0:00:01s\n",
      "epoch 3  | loss: 0.99973 | test_accuracy: 0.60555 |  0:00:02s\n",
      "epoch 4  | loss: 0.95412 | test_accuracy: 0.62096 |  0:00:03s\n",
      "epoch 5  | loss: 0.93443 | test_accuracy: 0.6225  |  0:00:03s\n",
      "epoch 6  | loss: 0.91846 | test_accuracy: 0.62969 |  0:00:04s\n",
      "epoch 7  | loss: 0.90317 | test_accuracy: 0.62352 |  0:00:05s\n",
      "epoch 8  | loss: 0.88948 | test_accuracy: 0.62969 |  0:00:05s\n",
      "epoch 9  | loss: 0.88629 | test_accuracy: 0.62866 |  0:00:06s\n",
      "epoch 10 | loss: 0.88492 | test_accuracy: 0.63431 |  0:00:07s\n",
      "epoch 11 | loss: 0.8685  | test_accuracy: 0.63739 |  0:00:07s\n",
      "epoch 12 | loss: 0.85934 | test_accuracy: 0.64458 |  0:00:08s\n",
      "epoch 13 | loss: 0.86039 | test_accuracy: 0.64458 |  0:00:09s\n",
      "epoch 14 | loss: 0.86028 | test_accuracy: 0.64355 |  0:00:09s\n",
      "epoch 15 | loss: 0.85088 | test_accuracy: 0.6379  |  0:00:10s\n",
      "epoch 16 | loss: 0.84393 | test_accuracy: 0.6415  |  0:00:11s\n",
      "epoch 17 | loss: 0.84568 | test_accuracy: 0.63996 |  0:00:11s\n",
      "epoch 18 | loss: 0.8467  | test_accuracy: 0.6415  |  0:00:12s\n",
      "epoch 19 | loss: 0.83268 | test_accuracy: 0.6528  |  0:00:13s\n",
      "epoch 20 | loss: 0.8291  | test_accuracy: 0.6492  |  0:00:13s\n",
      "epoch 21 | loss: 0.81174 | test_accuracy: 0.64355 |  0:00:14s\n",
      "epoch 22 | loss: 0.80855 | test_accuracy: 0.65691 |  0:00:15s\n",
      "epoch 23 | loss: 0.81127 | test_accuracy: 0.6528  |  0:00:15s\n",
      "epoch 24 | loss: 0.82386 | test_accuracy: 0.65383 |  0:00:16s\n",
      "epoch 25 | loss: 0.79986 | test_accuracy: 0.66307 |  0:00:17s\n",
      "epoch 26 | loss: 0.79942 | test_accuracy: 0.66204 |  0:00:17s\n",
      "epoch 27 | loss: 0.79089 | test_accuracy: 0.66513 |  0:00:18s\n",
      "epoch 28 | loss: 0.7851  | test_accuracy: 0.6605  |  0:00:19s\n",
      "epoch 29 | loss: 0.78559 | test_accuracy: 0.66667 |  0:00:19s\n",
      "epoch 30 | loss: 0.78502 | test_accuracy: 0.65845 |  0:00:20s\n",
      "epoch 31 | loss: 0.77708 | test_accuracy: 0.66564 |  0:00:20s\n",
      "epoch 32 | loss: 0.76694 | test_accuracy: 0.66769 |  0:00:21s\n",
      "epoch 33 | loss: 0.77369 | test_accuracy: 0.66872 |  0:00:22s\n",
      "epoch 34 | loss: 0.76275 | test_accuracy: 0.66204 |  0:00:22s\n",
      "epoch 35 | loss: 0.75622 | test_accuracy: 0.67232 |  0:00:23s\n",
      "epoch 36 | loss: 0.74925 | test_accuracy: 0.67694 |  0:00:24s\n",
      "epoch 37 | loss: 0.73794 | test_accuracy: 0.6754  |  0:00:24s\n",
      "epoch 38 | loss: 0.74031 | test_accuracy: 0.67386 |  0:00:25s\n",
      "epoch 39 | loss: 0.7505  | test_accuracy: 0.66513 |  0:00:26s\n",
      "epoch 40 | loss: 0.74133 | test_accuracy: 0.6718  |  0:00:26s\n",
      "epoch 41 | loss: 0.75055 | test_accuracy: 0.66821 |  0:00:27s\n",
      "epoch 42 | loss: 0.73757 | test_accuracy: 0.68002 |  0:00:28s\n",
      "epoch 43 | loss: 0.74232 | test_accuracy: 0.68002 |  0:00:28s\n",
      "epoch 44 | loss: 0.73416 | test_accuracy: 0.68053 |  0:00:29s\n",
      "epoch 45 | loss: 0.72196 | test_accuracy: 0.66923 |  0:00:30s\n",
      "epoch 46 | loss: 0.72236 | test_accuracy: 0.67232 |  0:00:30s\n",
      "epoch 47 | loss: 0.72715 | test_accuracy: 0.69492 |  0:00:31s\n",
      "epoch 48 | loss: 0.70134 | test_accuracy: 0.69029 |  0:00:32s\n",
      "epoch 49 | loss: 0.69946 | test_accuracy: 0.68516 |  0:00:32s\n",
      "epoch 50 | loss: 0.70677 | test_accuracy: 0.68516 |  0:00:33s\n",
      "epoch 51 | loss: 0.7045  | test_accuracy: 0.68464 |  0:00:34s\n",
      "epoch 52 | loss: 0.69365 | test_accuracy: 0.67437 |  0:00:34s\n",
      "epoch 53 | loss: 0.68209 | test_accuracy: 0.69646 |  0:00:35s\n",
      "epoch 54 | loss: 0.67548 | test_accuracy: 0.68207 |  0:00:36s\n",
      "epoch 55 | loss: 0.68621 | test_accuracy: 0.68978 |  0:00:36s\n",
      "epoch 56 | loss: 0.6875  | test_accuracy: 0.68516 |  0:00:37s\n",
      "epoch 57 | loss: 0.68294 | test_accuracy: 0.69851 |  0:00:38s\n",
      "epoch 58 | loss: 0.67829 | test_accuracy: 0.69492 |  0:00:38s\n",
      "epoch 59 | loss: 0.67581 | test_accuracy: 0.69286 |  0:00:39s\n",
      "epoch 60 | loss: 0.67017 | test_accuracy: 0.69286 |  0:00:39s\n",
      "epoch 61 | loss: 0.66397 | test_accuracy: 0.69851 |  0:00:40s\n",
      "epoch 62 | loss: 0.66217 | test_accuracy: 0.69902 |  0:00:41s\n",
      "epoch 63 | loss: 0.66947 | test_accuracy: 0.68464 |  0:00:41s\n",
      "epoch 64 | loss: 0.6655  | test_accuracy: 0.7093  |  0:00:42s\n",
      "epoch 65 | loss: 0.6566  | test_accuracy: 0.69697 |  0:00:43s\n",
      "epoch 66 | loss: 0.64442 | test_accuracy: 0.69183 |  0:00:43s\n",
      "epoch 67 | loss: 0.65211 | test_accuracy: 0.71032 |  0:00:44s\n",
      "epoch 68 | loss: 0.64803 | test_accuracy: 0.69029 |  0:00:45s\n",
      "epoch 69 | loss: 0.64267 | test_accuracy: 0.7093  |  0:00:45s\n",
      "epoch 70 | loss: 0.63898 | test_accuracy: 0.70827 |  0:00:46s\n",
      "epoch 71 | loss: 0.63033 | test_accuracy: 0.70981 |  0:00:47s\n",
      "epoch 72 | loss: 0.6334  | test_accuracy: 0.7093  |  0:00:47s\n",
      "epoch 73 | loss: 0.63288 | test_accuracy: 0.71238 |  0:00:48s\n",
      "epoch 74 | loss: 0.62466 | test_accuracy: 0.7057  |  0:00:49s\n",
      "epoch 75 | loss: 0.62185 | test_accuracy: 0.71289 |  0:00:49s\n",
      "epoch 76 | loss: 0.61467 | test_accuracy: 0.71905 |  0:00:50s\n",
      "epoch 77 | loss: 0.61221 | test_accuracy: 0.70981 |  0:00:50s\n",
      "epoch 78 | loss: 0.6253  | test_accuracy: 0.70313 |  0:00:51s\n",
      "epoch 79 | loss: 0.62131 | test_accuracy: 0.70776 |  0:00:52s\n",
      "epoch 80 | loss: 0.61708 | test_accuracy: 0.71238 |  0:00:52s\n",
      "epoch 81 | loss: 0.60313 | test_accuracy: 0.71084 |  0:00:53s\n",
      "epoch 82 | loss: 0.61034 | test_accuracy: 0.72265 |  0:00:54s\n",
      "epoch 83 | loss: 0.59746 | test_accuracy: 0.72522 |  0:00:54s\n",
      "epoch 84 | loss: 0.5884  | test_accuracy: 0.72316 |  0:00:55s\n",
      "epoch 85 | loss: 0.58902 | test_accuracy: 0.717   |  0:00:56s\n",
      "epoch 86 | loss: 0.59541 | test_accuracy: 0.72625 |  0:00:56s\n",
      "epoch 87 | loss: 0.57939 | test_accuracy: 0.7247  |  0:00:57s\n",
      "epoch 88 | loss: 0.57792 | test_accuracy: 0.71854 |  0:00:58s\n",
      "epoch 89 | loss: 0.5848  | test_accuracy: 0.70159 |  0:00:58s\n",
      "epoch 90 | loss: 0.58405 | test_accuracy: 0.72162 |  0:00:59s\n",
      "epoch 91 | loss: 0.58532 | test_accuracy: 0.71238 |  0:01:00s\n",
      "epoch 92 | loss: 0.58056 | test_accuracy: 0.71649 |  0:01:00s\n",
      "epoch 93 | loss: 0.57121 | test_accuracy: 0.73344 |  0:01:01s\n",
      "epoch 94 | loss: 0.56355 | test_accuracy: 0.73703 |  0:01:02s\n",
      "epoch 95 | loss: 0.57023 | test_accuracy: 0.72779 |  0:01:02s\n",
      "epoch 96 | loss: 0.5774  | test_accuracy: 0.7283  |  0:01:03s\n",
      "epoch 97 | loss: 0.56653 | test_accuracy: 0.72162 |  0:01:04s\n",
      "epoch 98 | loss: 0.5595  | test_accuracy: 0.72984 |  0:01:04s\n",
      "epoch 99 | loss: 0.55229 | test_accuracy: 0.73857 |  0:01:05s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_test_accuracy = 0.73857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:59:09,698] Trial 19 finished with value: 0.7385721623009759 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.213287225900646, 'lambda_sparse': 0.008788520337902688, 'lr': 0.0036503942104555327, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 19 with value: 0.7385721623009759.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25131 | test_accuracy: 0.51977 |  0:00:01s\n",
      "epoch 1  | loss: 1.5322  | test_accuracy: 0.53416 |  0:00:02s\n",
      "epoch 2  | loss: 1.35259 | test_accuracy: 0.57473 |  0:00:03s\n",
      "epoch 3  | loss: 1.26968 | test_accuracy: 0.58963 |  0:00:05s\n",
      "epoch 4  | loss: 1.1791  | test_accuracy: 0.56857 |  0:00:06s\n",
      "epoch 5  | loss: 1.1312  | test_accuracy: 0.57576 |  0:00:07s\n",
      "epoch 6  | loss: 1.10374 | test_accuracy: 0.5773  |  0:00:09s\n",
      "epoch 7  | loss: 1.06674 | test_accuracy: 0.58141 |  0:00:10s\n",
      "epoch 8  | loss: 1.0498  | test_accuracy: 0.59373 |  0:00:11s\n",
      "epoch 9  | loss: 1.06663 | test_accuracy: 0.57935 |  0:00:13s\n",
      "epoch 10 | loss: 1.03405 | test_accuracy: 0.57987 |  0:00:14s\n",
      "epoch 11 | loss: 1.02004 | test_accuracy: 0.59271 |  0:00:15s\n",
      "epoch 12 | loss: 1.01407 | test_accuracy: 0.60606 |  0:00:16s\n",
      "epoch 13 | loss: 0.99237 | test_accuracy: 0.59425 |  0:00:18s\n",
      "epoch 14 | loss: 0.98948 | test_accuracy: 0.59784 |  0:00:19s\n",
      "epoch 15 | loss: 0.97714 | test_accuracy: 0.61582 |  0:00:20s\n",
      "epoch 16 | loss: 0.97767 | test_accuracy: 0.60452 |  0:00:22s\n",
      "epoch 17 | loss: 0.96264 | test_accuracy: 0.61582 |  0:00:23s\n",
      "epoch 18 | loss: 0.95422 | test_accuracy: 0.60863 |  0:00:24s\n",
      "epoch 19 | loss: 0.95335 | test_accuracy: 0.61222 |  0:00:25s\n",
      "epoch 20 | loss: 0.94022 | test_accuracy: 0.61017 |  0:00:27s\n",
      "epoch 21 | loss: 0.93494 | test_accuracy: 0.60657 |  0:00:28s\n",
      "epoch 22 | loss: 0.9376  | test_accuracy: 0.61531 |  0:00:29s\n",
      "epoch 23 | loss: 0.92687 | test_accuracy: 0.61633 |  0:00:31s\n",
      "epoch 24 | loss: 0.92053 | test_accuracy: 0.60709 |  0:00:32s\n",
      "epoch 25 | loss: 0.91734 | test_accuracy: 0.62198 |  0:00:33s\n",
      "epoch 26 | loss: 0.92782 | test_accuracy: 0.61222 |  0:00:35s\n",
      "epoch 27 | loss: 0.93114 | test_accuracy: 0.61839 |  0:00:36s\n",
      "epoch 28 | loss: 0.91705 | test_accuracy: 0.61428 |  0:00:37s\n",
      "epoch 29 | loss: 0.91731 | test_accuracy: 0.61222 |  0:00:39s\n",
      "epoch 30 | loss: 0.91972 | test_accuracy: 0.61325 |  0:00:40s\n",
      "epoch 31 | loss: 0.91014 | test_accuracy: 0.61068 |  0:00:41s\n",
      "epoch 32 | loss: 0.91482 | test_accuracy: 0.60401 |  0:00:42s\n",
      "epoch 33 | loss: 0.92689 | test_accuracy: 0.61531 |  0:00:44s\n",
      "epoch 34 | loss: 0.91769 | test_accuracy: 0.61941 |  0:00:45s\n",
      "epoch 35 | loss: 0.91464 | test_accuracy: 0.61428 |  0:00:46s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_test_accuracy = 0.62198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 15:59:56,893] Trial 20 finished with value: 0.6219825372367745 and parameters: {'n_d': 32, 'n_a': 8, 'n_steps': 10, 'gamma': 1.1759795168918716, 'lambda_sparse': 0.008211563454521783, 'lr': 0.004158177136688408, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 19 with value: 0.7385721623009759.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.84151 | test_accuracy: 0.54135 |  0:00:00s\n",
      "epoch 1  | loss: 1.15103 | test_accuracy: 0.57165 |  0:00:01s\n",
      "epoch 2  | loss: 1.04147 | test_accuracy: 0.57216 |  0:00:01s\n",
      "epoch 3  | loss: 0.98744 | test_accuracy: 0.59887 |  0:00:02s\n",
      "epoch 4  | loss: 0.94866 | test_accuracy: 0.59887 |  0:00:03s\n",
      "epoch 5  | loss: 0.9356  | test_accuracy: 0.61582 |  0:00:03s\n",
      "epoch 6  | loss: 0.92376 | test_accuracy: 0.61325 |  0:00:04s\n",
      "epoch 7  | loss: 0.90862 | test_accuracy: 0.62044 |  0:00:05s\n",
      "epoch 8  | loss: 0.89429 | test_accuracy: 0.61376 |  0:00:06s\n",
      "epoch 9  | loss: 0.87937 | test_accuracy: 0.62506 |  0:00:06s\n",
      "epoch 10 | loss: 0.8767  | test_accuracy: 0.64099 |  0:00:07s\n",
      "epoch 11 | loss: 0.87573 | test_accuracy: 0.63071 |  0:00:07s\n",
      "epoch 12 | loss: 0.86077 | test_accuracy: 0.64047 |  0:00:08s\n",
      "epoch 13 | loss: 0.85544 | test_accuracy: 0.62866 |  0:00:09s\n",
      "epoch 14 | loss: 0.84974 | test_accuracy: 0.63482 |  0:00:10s\n",
      "epoch 15 | loss: 0.83824 | test_accuracy: 0.63431 |  0:00:10s\n",
      "epoch 16 | loss: 0.82839 | test_accuracy: 0.64561 |  0:00:11s\n",
      "epoch 17 | loss: 0.82404 | test_accuracy: 0.6415  |  0:00:12s\n",
      "epoch 18 | loss: 0.82843 | test_accuracy: 0.64715 |  0:00:12s\n",
      "epoch 19 | loss: 0.82079 | test_accuracy: 0.64818 |  0:00:13s\n",
      "epoch 20 | loss: 0.81459 | test_accuracy: 0.64818 |  0:00:14s\n",
      "epoch 21 | loss: 0.81165 | test_accuracy: 0.65177 |  0:00:14s\n",
      "epoch 22 | loss: 0.80622 | test_accuracy: 0.65023 |  0:00:15s\n",
      "epoch 23 | loss: 0.81065 | test_accuracy: 0.64047 |  0:00:15s\n",
      "epoch 24 | loss: 0.8042  | test_accuracy: 0.65434 |  0:00:16s\n",
      "epoch 25 | loss: 0.79443 | test_accuracy: 0.65742 |  0:00:17s\n",
      "epoch 26 | loss: 0.79776 | test_accuracy: 0.66153 |  0:00:17s\n",
      "epoch 27 | loss: 0.7872  | test_accuracy: 0.65896 |  0:00:18s\n",
      "epoch 28 | loss: 0.78421 | test_accuracy: 0.66615 |  0:00:19s\n",
      "epoch 29 | loss: 0.77244 | test_accuracy: 0.65588 |  0:00:19s\n",
      "epoch 30 | loss: 0.77242 | test_accuracy: 0.67232 |  0:00:20s\n",
      "epoch 31 | loss: 0.76152 | test_accuracy: 0.66615 |  0:00:21s\n",
      "epoch 32 | loss: 0.75811 | test_accuracy: 0.66821 |  0:00:22s\n",
      "epoch 33 | loss: 0.75536 | test_accuracy: 0.68259 |  0:00:22s\n",
      "epoch 34 | loss: 0.74669 | test_accuracy: 0.66307 |  0:00:23s\n",
      "epoch 35 | loss: 0.75266 | test_accuracy: 0.66256 |  0:00:24s\n",
      "epoch 36 | loss: 0.75014 | test_accuracy: 0.67026 |  0:00:25s\n",
      "epoch 37 | loss: 0.75402 | test_accuracy: 0.66102 |  0:00:25s\n",
      "epoch 38 | loss: 0.74881 | test_accuracy: 0.67488 |  0:00:26s\n",
      "epoch 39 | loss: 0.74548 | test_accuracy: 0.66821 |  0:00:27s\n",
      "epoch 40 | loss: 0.74771 | test_accuracy: 0.65999 |  0:00:27s\n",
      "epoch 41 | loss: 0.73617 | test_accuracy: 0.6641  |  0:00:28s\n",
      "epoch 42 | loss: 0.73282 | test_accuracy: 0.66461 |  0:00:28s\n",
      "epoch 43 | loss: 0.73328 | test_accuracy: 0.66821 |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_test_accuracy = 0.68259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:00:26,730] Trial 21 finished with value: 0.6825885978428351 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.128727156894212, 'lambda_sparse': 0.00956110524986577, 'lr': 0.0034408457733325418, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 19 with value: 0.7385721623009759.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.5267  | test_accuracy: 0.52491 |  0:00:00s\n",
      "epoch 1  | loss: 1.05432 | test_accuracy: 0.56035 |  0:00:01s\n",
      "epoch 2  | loss: 0.9938  | test_accuracy: 0.59425 |  0:00:02s\n",
      "epoch 3  | loss: 0.94639 | test_accuracy: 0.60401 |  0:00:02s\n",
      "epoch 4  | loss: 0.91928 | test_accuracy: 0.6225  |  0:00:03s\n",
      "epoch 5  | loss: 0.90586 | test_accuracy: 0.62558 |  0:00:04s\n",
      "epoch 6  | loss: 0.89381 | test_accuracy: 0.62404 |  0:00:04s\n",
      "epoch 7  | loss: 0.88934 | test_accuracy: 0.62352 |  0:00:05s\n",
      "epoch 8  | loss: 0.87504 | test_accuracy: 0.62455 |  0:00:06s\n",
      "epoch 9  | loss: 0.85803 | test_accuracy: 0.6189  |  0:00:06s\n",
      "epoch 10 | loss: 0.86355 | test_accuracy: 0.63123 |  0:00:07s\n",
      "epoch 11 | loss: 0.8448  | test_accuracy: 0.62404 |  0:00:08s\n",
      "epoch 12 | loss: 0.83913 | test_accuracy: 0.64099 |  0:00:08s\n",
      "epoch 13 | loss: 0.83474 | test_accuracy: 0.64201 |  0:00:09s\n",
      "epoch 14 | loss: 0.82404 | test_accuracy: 0.63123 |  0:00:10s\n",
      "epoch 15 | loss: 0.83328 | test_accuracy: 0.63174 |  0:00:10s\n",
      "epoch 16 | loss: 0.82757 | test_accuracy: 0.63739 |  0:00:11s\n",
      "epoch 17 | loss: 0.83187 | test_accuracy: 0.63688 |  0:00:11s\n",
      "epoch 18 | loss: 0.83791 | test_accuracy: 0.63534 |  0:00:12s\n",
      "epoch 19 | loss: 0.82662 | test_accuracy: 0.61222 |  0:00:13s\n",
      "epoch 20 | loss: 0.84889 | test_accuracy: 0.63277 |  0:00:13s\n",
      "epoch 21 | loss: 0.82576 | test_accuracy: 0.64099 |  0:00:14s\n",
      "epoch 22 | loss: 0.81456 | test_accuracy: 0.6451  |  0:00:15s\n",
      "epoch 23 | loss: 0.80739 | test_accuracy: 0.64304 |  0:00:15s\n",
      "epoch 24 | loss: 0.80005 | test_accuracy: 0.64355 |  0:00:16s\n",
      "epoch 25 | loss: 0.79081 | test_accuracy: 0.64715 |  0:00:17s\n",
      "epoch 26 | loss: 0.79029 | test_accuracy: 0.6492  |  0:00:17s\n",
      "epoch 27 | loss: 0.78912 | test_accuracy: 0.64869 |  0:00:18s\n",
      "epoch 28 | loss: 0.77416 | test_accuracy: 0.65948 |  0:00:19s\n",
      "epoch 29 | loss: 0.78139 | test_accuracy: 0.64407 |  0:00:19s\n",
      "epoch 30 | loss: 0.78515 | test_accuracy: 0.6451  |  0:00:20s\n",
      "epoch 31 | loss: 0.77528 | test_accuracy: 0.64664 |  0:00:21s\n",
      "epoch 32 | loss: 0.76905 | test_accuracy: 0.65691 |  0:00:21s\n",
      "epoch 33 | loss: 0.75022 | test_accuracy: 0.66204 |  0:00:22s\n",
      "epoch 34 | loss: 0.74788 | test_accuracy: 0.65999 |  0:00:23s\n",
      "epoch 35 | loss: 0.75085 | test_accuracy: 0.65229 |  0:00:23s\n",
      "epoch 36 | loss: 0.74722 | test_accuracy: 0.66564 |  0:00:24s\n",
      "epoch 37 | loss: 0.738   | test_accuracy: 0.67437 |  0:00:25s\n",
      "epoch 38 | loss: 0.74308 | test_accuracy: 0.65845 |  0:00:25s\n",
      "epoch 39 | loss: 0.73756 | test_accuracy: 0.66975 |  0:00:26s\n",
      "epoch 40 | loss: 0.73513 | test_accuracy: 0.66615 |  0:00:27s\n",
      "epoch 41 | loss: 0.72885 | test_accuracy: 0.67026 |  0:00:27s\n",
      "epoch 42 | loss: 0.71214 | test_accuracy: 0.66975 |  0:00:28s\n",
      "epoch 43 | loss: 0.7127  | test_accuracy: 0.66564 |  0:00:29s\n",
      "epoch 44 | loss: 0.70618 | test_accuracy: 0.66975 |  0:00:29s\n",
      "epoch 45 | loss: 0.69332 | test_accuracy: 0.68567 |  0:00:30s\n",
      "epoch 46 | loss: 0.68774 | test_accuracy: 0.66872 |  0:00:31s\n",
      "epoch 47 | loss: 0.69625 | test_accuracy: 0.68721 |  0:00:31s\n",
      "epoch 48 | loss: 0.68066 | test_accuracy: 0.69337 |  0:00:32s\n",
      "epoch 49 | loss: 0.69063 | test_accuracy: 0.68567 |  0:00:33s\n",
      "epoch 50 | loss: 0.68869 | test_accuracy: 0.68567 |  0:00:33s\n",
      "epoch 51 | loss: 0.68354 | test_accuracy: 0.6831  |  0:00:34s\n",
      "epoch 52 | loss: 0.67608 | test_accuracy: 0.68105 |  0:00:35s\n",
      "epoch 53 | loss: 0.66633 | test_accuracy: 0.67899 |  0:00:35s\n",
      "epoch 54 | loss: 0.66345 | test_accuracy: 0.67437 |  0:00:36s\n",
      "epoch 55 | loss: 0.66095 | test_accuracy: 0.67694 |  0:00:37s\n",
      "epoch 56 | loss: 0.65424 | test_accuracy: 0.68413 |  0:00:37s\n",
      "epoch 57 | loss: 0.65912 | test_accuracy: 0.67488 |  0:00:38s\n",
      "epoch 58 | loss: 0.65677 | test_accuracy: 0.67797 |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_test_accuracy = 0.69337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:01:06,058] Trial 22 finished with value: 0.6933744221879815 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.4146967797657481, 'lambda_sparse': 0.0018709337704911843, 'lr': 0.008596852682094574, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 19 with value: 0.7385721623009759.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.54768 | test_accuracy: 0.55932 |  0:00:00s\n",
      "epoch 1  | loss: 1.05302 | test_accuracy: 0.57422 |  0:00:01s\n",
      "epoch 2  | loss: 0.98155 | test_accuracy: 0.58808 |  0:00:02s\n",
      "epoch 3  | loss: 0.94856 | test_accuracy: 0.60041 |  0:00:02s\n",
      "epoch 4  | loss: 0.91376 | test_accuracy: 0.62558 |  0:00:03s\n",
      "epoch 5  | loss: 0.90496 | test_accuracy: 0.62096 |  0:00:04s\n",
      "epoch 6  | loss: 0.90331 | test_accuracy: 0.62301 |  0:00:04s\n",
      "epoch 7  | loss: 0.89071 | test_accuracy: 0.61479 |  0:00:05s\n",
      "epoch 8  | loss: 0.88063 | test_accuracy: 0.63945 |  0:00:06s\n",
      "epoch 9  | loss: 0.87399 | test_accuracy: 0.6379  |  0:00:06s\n",
      "epoch 10 | loss: 0.86675 | test_accuracy: 0.63636 |  0:00:07s\n",
      "epoch 11 | loss: 0.86371 | test_accuracy: 0.63277 |  0:00:08s\n",
      "epoch 12 | loss: 0.84978 | test_accuracy: 0.63688 |  0:00:08s\n",
      "epoch 13 | loss: 0.85292 | test_accuracy: 0.63893 |  0:00:09s\n",
      "epoch 14 | loss: 0.84358 | test_accuracy: 0.63893 |  0:00:10s\n",
      "epoch 15 | loss: 0.85213 | test_accuracy: 0.63225 |  0:00:11s\n",
      "epoch 16 | loss: 0.83671 | test_accuracy: 0.64407 |  0:00:11s\n",
      "epoch 17 | loss: 0.82484 | test_accuracy: 0.64304 |  0:00:12s\n",
      "epoch 18 | loss: 0.82771 | test_accuracy: 0.6492  |  0:00:13s\n",
      "epoch 19 | loss: 0.82075 | test_accuracy: 0.64253 |  0:00:13s\n",
      "epoch 20 | loss: 0.81258 | test_accuracy: 0.64304 |  0:00:14s\n",
      "epoch 21 | loss: 0.80389 | test_accuracy: 0.64715 |  0:00:15s\n",
      "epoch 22 | loss: 0.80127 | test_accuracy: 0.65948 |  0:00:15s\n",
      "epoch 23 | loss: 0.79152 | test_accuracy: 0.66102 |  0:00:16s\n",
      "epoch 24 | loss: 0.78783 | test_accuracy: 0.66359 |  0:00:17s\n",
      "epoch 25 | loss: 0.79178 | test_accuracy: 0.66256 |  0:00:18s\n",
      "epoch 26 | loss: 0.78849 | test_accuracy: 0.65845 |  0:00:18s\n",
      "epoch 27 | loss: 0.79295 | test_accuracy: 0.66615 |  0:00:19s\n",
      "epoch 28 | loss: 0.78227 | test_accuracy: 0.6605  |  0:00:20s\n",
      "epoch 29 | loss: 0.76983 | test_accuracy: 0.6605  |  0:00:20s\n",
      "epoch 30 | loss: 0.76781 | test_accuracy: 0.66359 |  0:00:21s\n",
      "epoch 31 | loss: 0.77212 | test_accuracy: 0.64561 |  0:00:22s\n",
      "epoch 32 | loss: 0.76937 | test_accuracy: 0.65999 |  0:00:23s\n",
      "epoch 33 | loss: 0.76573 | test_accuracy: 0.66359 |  0:00:23s\n",
      "epoch 34 | loss: 0.77067 | test_accuracy: 0.67129 |  0:00:24s\n",
      "epoch 35 | loss: 0.75795 | test_accuracy: 0.6718  |  0:00:25s\n",
      "epoch 36 | loss: 0.75345 | test_accuracy: 0.65845 |  0:00:25s\n",
      "epoch 37 | loss: 0.7429  | test_accuracy: 0.66513 |  0:00:26s\n",
      "epoch 38 | loss: 0.73591 | test_accuracy: 0.66615 |  0:00:26s\n",
      "epoch 39 | loss: 0.74455 | test_accuracy: 0.65896 |  0:00:27s\n",
      "epoch 40 | loss: 0.74579 | test_accuracy: 0.67078 |  0:00:28s\n",
      "epoch 41 | loss: 0.73089 | test_accuracy: 0.67232 |  0:00:29s\n",
      "epoch 42 | loss: 0.72165 | test_accuracy: 0.67643 |  0:00:29s\n",
      "epoch 43 | loss: 0.73185 | test_accuracy: 0.67848 |  0:00:30s\n",
      "epoch 44 | loss: 0.71219 | test_accuracy: 0.68618 |  0:00:30s\n",
      "epoch 45 | loss: 0.70878 | test_accuracy: 0.68105 |  0:00:31s\n",
      "epoch 46 | loss: 0.71016 | test_accuracy: 0.65896 |  0:00:32s\n",
      "epoch 47 | loss: 0.71738 | test_accuracy: 0.6641  |  0:00:32s\n",
      "epoch 48 | loss: 0.70657 | test_accuracy: 0.67694 |  0:00:33s\n",
      "epoch 49 | loss: 0.7048  | test_accuracy: 0.68105 |  0:00:34s\n",
      "epoch 50 | loss: 0.70757 | test_accuracy: 0.67797 |  0:00:35s\n",
      "epoch 51 | loss: 0.69925 | test_accuracy: 0.67899 |  0:00:35s\n",
      "epoch 52 | loss: 0.69408 | test_accuracy: 0.69183 |  0:00:36s\n",
      "epoch 53 | loss: 0.68726 | test_accuracy: 0.67745 |  0:00:37s\n",
      "epoch 54 | loss: 0.70028 | test_accuracy: 0.68002 |  0:00:37s\n",
      "epoch 55 | loss: 0.68614 | test_accuracy: 0.69132 |  0:00:38s\n",
      "epoch 56 | loss: 0.67672 | test_accuracy: 0.69029 |  0:00:39s\n",
      "epoch 57 | loss: 0.67156 | test_accuracy: 0.68721 |  0:00:39s\n",
      "epoch 58 | loss: 0.67874 | test_accuracy: 0.69646 |  0:00:40s\n",
      "epoch 59 | loss: 0.66189 | test_accuracy: 0.70005 |  0:00:41s\n",
      "epoch 60 | loss: 0.65444 | test_accuracy: 0.68567 |  0:00:41s\n",
      "epoch 61 | loss: 0.65364 | test_accuracy: 0.69646 |  0:00:42s\n",
      "epoch 62 | loss: 0.66346 | test_accuracy: 0.69081 |  0:00:42s\n",
      "epoch 63 | loss: 0.64251 | test_accuracy: 0.70621 |  0:00:43s\n",
      "epoch 64 | loss: 0.65266 | test_accuracy: 0.69851 |  0:00:44s\n",
      "epoch 65 | loss: 0.63718 | test_accuracy: 0.698   |  0:00:44s\n",
      "epoch 66 | loss: 0.63534 | test_accuracy: 0.69337 |  0:00:45s\n",
      "epoch 67 | loss: 0.62983 | test_accuracy: 0.69851 |  0:00:46s\n",
      "epoch 68 | loss: 0.62095 | test_accuracy: 0.69286 |  0:00:46s\n",
      "epoch 69 | loss: 0.6271  | test_accuracy: 0.70005 |  0:00:47s\n",
      "epoch 70 | loss: 0.60984 | test_accuracy: 0.70621 |  0:00:48s\n",
      "epoch 71 | loss: 0.60705 | test_accuracy: 0.70621 |  0:00:48s\n",
      "epoch 72 | loss: 0.60136 | test_accuracy: 0.70981 |  0:00:49s\n",
      "epoch 73 | loss: 0.61212 | test_accuracy: 0.70211 |  0:00:50s\n",
      "epoch 74 | loss: 0.59993 | test_accuracy: 0.717   |  0:00:50s\n",
      "epoch 75 | loss: 0.60964 | test_accuracy: 0.70211 |  0:00:51s\n",
      "epoch 76 | loss: 0.60249 | test_accuracy: 0.72162 |  0:00:52s\n",
      "epoch 77 | loss: 0.5847  | test_accuracy: 0.72008 |  0:00:52s\n",
      "epoch 78 | loss: 0.58337 | test_accuracy: 0.71341 |  0:00:53s\n",
      "epoch 79 | loss: 0.5746  | test_accuracy: 0.72984 |  0:00:53s\n",
      "epoch 80 | loss: 0.57811 | test_accuracy: 0.71803 |  0:00:54s\n",
      "epoch 81 | loss: 0.58219 | test_accuracy: 0.70211 |  0:00:55s\n",
      "epoch 82 | loss: 0.59573 | test_accuracy: 0.72316 |  0:00:55s\n",
      "epoch 83 | loss: 0.58504 | test_accuracy: 0.71854 |  0:00:56s\n",
      "epoch 84 | loss: 0.57523 | test_accuracy: 0.72625 |  0:00:57s\n",
      "epoch 85 | loss: 0.56672 | test_accuracy: 0.72727 |  0:00:57s\n",
      "epoch 86 | loss: 0.54583 | test_accuracy: 0.73292 |  0:00:58s\n",
      "epoch 87 | loss: 0.54944 | test_accuracy: 0.73344 |  0:00:59s\n",
      "epoch 88 | loss: 0.55173 | test_accuracy: 0.73087 |  0:00:59s\n",
      "epoch 89 | loss: 0.54788 | test_accuracy: 0.736   |  0:01:00s\n",
      "epoch 90 | loss: 0.53362 | test_accuracy: 0.72779 |  0:01:01s\n",
      "epoch 91 | loss: 0.54006 | test_accuracy: 0.73549 |  0:01:01s\n",
      "epoch 92 | loss: 0.54364 | test_accuracy: 0.73344 |  0:01:02s\n",
      "epoch 93 | loss: 0.52334 | test_accuracy: 0.72214 |  0:01:03s\n",
      "epoch 94 | loss: 0.54843 | test_accuracy: 0.73498 |  0:01:03s\n",
      "epoch 95 | loss: 0.5285  | test_accuracy: 0.73857 |  0:01:04s\n",
      "epoch 96 | loss: 0.52137 | test_accuracy: 0.74884 |  0:01:04s\n",
      "epoch 97 | loss: 0.51287 | test_accuracy: 0.74474 |  0:01:05s\n",
      "epoch 98 | loss: 0.51086 | test_accuracy: 0.74782 |  0:01:06s\n",
      "epoch 99 | loss: 0.50931 | test_accuracy: 0.75398 |  0:01:06s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_test_accuracy = 0.75398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:02:13,234] Trial 23 finished with value: 0.7539804827940421 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.3542801903123354, 'lambda_sparse': 0.0015067427179960662, 'lr': 0.007483834315662805, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 23 with value: 0.7539804827940421.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.81578 | test_accuracy: 0.51977 |  0:00:00s\n",
      "epoch 1  | loss: 1.12245 | test_accuracy: 0.56959 |  0:00:01s\n",
      "epoch 2  | loss: 1.02623 | test_accuracy: 0.56703 |  0:00:02s\n",
      "epoch 3  | loss: 0.99584 | test_accuracy: 0.59425 |  0:00:03s\n",
      "epoch 4  | loss: 0.96322 | test_accuracy: 0.59938 |  0:00:04s\n",
      "epoch 5  | loss: 0.94695 | test_accuracy: 0.59887 |  0:00:05s\n",
      "epoch 6  | loss: 0.94103 | test_accuracy: 0.61222 |  0:00:06s\n",
      "epoch 7  | loss: 0.92854 | test_accuracy: 0.61325 |  0:00:07s\n",
      "epoch 8  | loss: 0.92421 | test_accuracy: 0.62096 |  0:00:08s\n",
      "epoch 9  | loss: 0.90469 | test_accuracy: 0.61993 |  0:00:09s\n",
      "epoch 10 | loss: 0.9018  | test_accuracy: 0.61736 |  0:00:10s\n",
      "epoch 11 | loss: 0.89683 | test_accuracy: 0.6112  |  0:00:11s\n",
      "epoch 12 | loss: 0.88976 | test_accuracy: 0.61479 |  0:00:12s\n",
      "epoch 13 | loss: 0.88491 | test_accuracy: 0.61171 |  0:00:12s\n",
      "epoch 14 | loss: 0.89244 | test_accuracy: 0.60709 |  0:00:13s\n",
      "epoch 15 | loss: 0.8913  | test_accuracy: 0.60657 |  0:00:14s\n",
      "epoch 16 | loss: 0.89034 | test_accuracy: 0.61582 |  0:00:15s\n",
      "epoch 17 | loss: 0.8896  | test_accuracy: 0.62147 |  0:00:16s\n",
      "epoch 18 | loss: 0.88232 | test_accuracy: 0.6225  |  0:00:17s\n",
      "epoch 19 | loss: 0.87967 | test_accuracy: 0.6112  |  0:00:18s\n",
      "epoch 20 | loss: 0.87518 | test_accuracy: 0.62763 |  0:00:19s\n",
      "epoch 21 | loss: 0.86998 | test_accuracy: 0.61993 |  0:00:20s\n",
      "epoch 22 | loss: 0.87055 | test_accuracy: 0.62147 |  0:00:21s\n",
      "epoch 23 | loss: 0.87429 | test_accuracy: 0.61479 |  0:00:22s\n",
      "epoch 24 | loss: 0.86794 | test_accuracy: 0.60812 |  0:00:22s\n",
      "epoch 25 | loss: 0.86149 | test_accuracy: 0.6225  |  0:00:23s\n",
      "epoch 26 | loss: 0.85906 | test_accuracy: 0.62352 |  0:00:24s\n",
      "epoch 27 | loss: 0.86056 | test_accuracy: 0.63328 |  0:00:25s\n",
      "epoch 28 | loss: 0.85806 | test_accuracy: 0.61531 |  0:00:26s\n",
      "epoch 29 | loss: 0.86509 | test_accuracy: 0.62096 |  0:00:27s\n",
      "epoch 30 | loss: 0.85927 | test_accuracy: 0.62558 |  0:00:28s\n",
      "epoch 31 | loss: 0.8544  | test_accuracy: 0.62352 |  0:00:29s\n",
      "epoch 32 | loss: 0.85231 | test_accuracy: 0.62506 |  0:00:30s\n",
      "epoch 33 | loss: 0.84288 | test_accuracy: 0.62506 |  0:00:31s\n",
      "epoch 34 | loss: 0.8513  | test_accuracy: 0.63123 |  0:00:32s\n",
      "epoch 35 | loss: 0.8522  | test_accuracy: 0.62558 |  0:00:33s\n",
      "epoch 36 | loss: 0.85121 | test_accuracy: 0.62609 |  0:00:34s\n",
      "epoch 37 | loss: 0.86884 | test_accuracy: 0.62096 |  0:00:36s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_test_accuracy = 0.63328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:02:49,748] Trial 24 finished with value: 0.6332819722650231 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 6, 'gamma': 1.4296106389025924, 'lambda_sparse': 0.0016747163891916487, 'lr': 0.009366163726644774, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 23 with value: 0.7539804827940421.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.47768 | test_accuracy: 0.45403 |  0:00:00s\n",
      "epoch 1  | loss: 1.31188 | test_accuracy: 0.57319 |  0:00:01s\n",
      "epoch 2  | loss: 1.09756 | test_accuracy: 0.59733 |  0:00:01s\n",
      "epoch 3  | loss: 1.03235 | test_accuracy: 0.5963  |  0:00:02s\n",
      "epoch 4  | loss: 1.0008  | test_accuracy: 0.59322 |  0:00:03s\n",
      "epoch 5  | loss: 0.97457 | test_accuracy: 0.60247 |  0:00:03s\n",
      "epoch 6  | loss: 0.95691 | test_accuracy: 0.6112  |  0:00:04s\n",
      "epoch 7  | loss: 0.94315 | test_accuracy: 0.61531 |  0:00:04s\n",
      "epoch 8  | loss: 0.92172 | test_accuracy: 0.62301 |  0:00:05s\n",
      "epoch 9  | loss: 0.91522 | test_accuracy: 0.6189  |  0:00:06s\n",
      "epoch 10 | loss: 0.91122 | test_accuracy: 0.62352 |  0:00:06s\n",
      "epoch 11 | loss: 0.89478 | test_accuracy: 0.62558 |  0:00:07s\n",
      "epoch 12 | loss: 0.89631 | test_accuracy: 0.62301 |  0:00:07s\n",
      "epoch 13 | loss: 0.89097 | test_accuracy: 0.62609 |  0:00:08s\n",
      "epoch 14 | loss: 0.88862 | test_accuracy: 0.62044 |  0:00:09s\n",
      "epoch 15 | loss: 0.88514 | test_accuracy: 0.62661 |  0:00:10s\n",
      "epoch 16 | loss: 0.87936 | test_accuracy: 0.62198 |  0:00:10s\n",
      "epoch 17 | loss: 0.8697  | test_accuracy: 0.63174 |  0:00:11s\n",
      "epoch 18 | loss: 0.85654 | test_accuracy: 0.62404 |  0:00:11s\n",
      "epoch 19 | loss: 0.86527 | test_accuracy: 0.6302  |  0:00:12s\n",
      "epoch 20 | loss: 0.86833 | test_accuracy: 0.62352 |  0:00:12s\n",
      "epoch 21 | loss: 0.85078 | test_accuracy: 0.62506 |  0:00:13s\n",
      "epoch 22 | loss: 0.85396 | test_accuracy: 0.63636 |  0:00:14s\n",
      "epoch 23 | loss: 0.84177 | test_accuracy: 0.63842 |  0:00:14s\n",
      "epoch 24 | loss: 0.83635 | test_accuracy: 0.63277 |  0:00:15s\n",
      "epoch 25 | loss: 0.82418 | test_accuracy: 0.6379  |  0:00:15s\n",
      "epoch 26 | loss: 0.81633 | test_accuracy: 0.63277 |  0:00:16s\n",
      "epoch 27 | loss: 0.82488 | test_accuracy: 0.63893 |  0:00:16s\n",
      "epoch 28 | loss: 0.83007 | test_accuracy: 0.65383 |  0:00:17s\n",
      "epoch 29 | loss: 0.8245  | test_accuracy: 0.6338  |  0:00:18s\n",
      "epoch 30 | loss: 0.83265 | test_accuracy: 0.63174 |  0:00:18s\n",
      "epoch 31 | loss: 0.82016 | test_accuracy: 0.63225 |  0:00:19s\n",
      "epoch 32 | loss: 0.81389 | test_accuracy: 0.6379  |  0:00:19s\n",
      "epoch 33 | loss: 0.81276 | test_accuracy: 0.63996 |  0:00:20s\n",
      "epoch 34 | loss: 0.80722 | test_accuracy: 0.6415  |  0:00:21s\n",
      "epoch 35 | loss: 0.79907 | test_accuracy: 0.64561 |  0:00:21s\n",
      "epoch 36 | loss: 0.79662 | test_accuracy: 0.65229 |  0:00:22s\n",
      "epoch 37 | loss: 0.79896 | test_accuracy: 0.66102 |  0:00:22s\n",
      "epoch 38 | loss: 0.79755 | test_accuracy: 0.64355 |  0:00:23s\n",
      "epoch 39 | loss: 0.79518 | test_accuracy: 0.65126 |  0:00:23s\n",
      "epoch 40 | loss: 0.79709 | test_accuracy: 0.65074 |  0:00:24s\n",
      "epoch 41 | loss: 0.79224 | test_accuracy: 0.6492  |  0:00:24s\n",
      "epoch 42 | loss: 0.78522 | test_accuracy: 0.65999 |  0:00:25s\n",
      "epoch 43 | loss: 0.7862  | test_accuracy: 0.66153 |  0:00:25s\n",
      "epoch 44 | loss: 0.77898 | test_accuracy: 0.66461 |  0:00:26s\n",
      "epoch 45 | loss: 0.77841 | test_accuracy: 0.65845 |  0:00:27s\n",
      "epoch 46 | loss: 0.76421 | test_accuracy: 0.66513 |  0:00:27s\n",
      "epoch 47 | loss: 0.77644 | test_accuracy: 0.67026 |  0:00:28s\n",
      "epoch 48 | loss: 0.77363 | test_accuracy: 0.66821 |  0:00:29s\n",
      "epoch 49 | loss: 0.77434 | test_accuracy: 0.65691 |  0:00:29s\n",
      "epoch 50 | loss: 0.75855 | test_accuracy: 0.66718 |  0:00:30s\n",
      "epoch 51 | loss: 0.75552 | test_accuracy: 0.66102 |  0:00:31s\n",
      "epoch 52 | loss: 0.74952 | test_accuracy: 0.66923 |  0:00:31s\n",
      "epoch 53 | loss: 0.75843 | test_accuracy: 0.66307 |  0:00:32s\n",
      "epoch 54 | loss: 0.7564  | test_accuracy: 0.65639 |  0:00:32s\n",
      "epoch 55 | loss: 0.76218 | test_accuracy: 0.66564 |  0:00:33s\n",
      "epoch 56 | loss: 0.75962 | test_accuracy: 0.66461 |  0:00:33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:03:24,578] Trial 25 finished with value: 0.6702619414483821 and parameters: {'n_d': 8, 'n_a': 32, 'n_steps': 4, 'gamma': 1.3235725133874385, 'lambda_sparse': 0.005514046454134327, 'lr': 0.006192025877081822, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 23 with value: 0.7539804827940421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57 | loss: 0.75057 | test_accuracy: 0.66975 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_test_accuracy = 0.67026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.94725 | test_accuracy: 0.53672 |  0:00:00s\n",
      "epoch 1  | loss: 1.13378 | test_accuracy: 0.55419 |  0:00:01s\n",
      "epoch 2  | loss: 1.03017 | test_accuracy: 0.57216 |  0:00:02s\n",
      "epoch 3  | loss: 0.98789 | test_accuracy: 0.585   |  0:00:03s\n",
      "epoch 4  | loss: 0.95425 | test_accuracy: 0.61325 |  0:00:04s\n",
      "epoch 5  | loss: 0.94486 | test_accuracy: 0.58808 |  0:00:05s\n",
      "epoch 6  | loss: 0.93384 | test_accuracy: 0.61171 |  0:00:06s\n",
      "epoch 7  | loss: 0.91418 | test_accuracy: 0.60401 |  0:00:06s\n",
      "epoch 8  | loss: 0.89498 | test_accuracy: 0.61428 |  0:00:07s\n",
      "epoch 9  | loss: 0.91239 | test_accuracy: 0.59887 |  0:00:08s\n",
      "epoch 10 | loss: 0.88987 | test_accuracy: 0.60914 |  0:00:09s\n",
      "epoch 11 | loss: 0.87981 | test_accuracy: 0.62506 |  0:00:10s\n",
      "epoch 12 | loss: 0.87434 | test_accuracy: 0.61068 |  0:00:10s\n",
      "epoch 13 | loss: 0.87776 | test_accuracy: 0.62609 |  0:00:11s\n",
      "epoch 14 | loss: 0.87519 | test_accuracy: 0.61171 |  0:00:12s\n",
      "epoch 15 | loss: 0.87283 | test_accuracy: 0.60298 |  0:00:13s\n",
      "epoch 16 | loss: 0.86532 | test_accuracy: 0.61222 |  0:00:14s\n",
      "epoch 17 | loss: 0.86468 | test_accuracy: 0.62712 |  0:00:14s\n",
      "epoch 18 | loss: 0.86069 | test_accuracy: 0.62969 |  0:00:15s\n",
      "epoch 19 | loss: 0.84647 | test_accuracy: 0.62404 |  0:00:16s\n",
      "epoch 20 | loss: 0.84145 | test_accuracy: 0.62198 |  0:00:17s\n",
      "epoch 21 | loss: 0.83594 | test_accuracy: 0.63842 |  0:00:17s\n",
      "epoch 22 | loss: 0.82839 | test_accuracy: 0.62558 |  0:00:18s\n",
      "epoch 23 | loss: 0.83955 | test_accuracy: 0.62661 |  0:00:19s\n",
      "epoch 24 | loss: 0.84259 | test_accuracy: 0.6379  |  0:00:20s\n",
      "epoch 25 | loss: 0.82873 | test_accuracy: 0.63277 |  0:00:20s\n",
      "epoch 26 | loss: 0.82581 | test_accuracy: 0.62506 |  0:00:21s\n",
      "epoch 27 | loss: 0.83281 | test_accuracy: 0.62917 |  0:00:22s\n",
      "epoch 28 | loss: 0.84735 | test_accuracy: 0.62661 |  0:00:23s\n",
      "epoch 29 | loss: 0.84953 | test_accuracy: 0.61633 |  0:00:24s\n",
      "epoch 30 | loss: 0.83584 | test_accuracy: 0.61068 |  0:00:25s\n",
      "epoch 31 | loss: 0.82446 | test_accuracy: 0.62455 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_test_accuracy = 0.63842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:03:50,998] Trial 26 finished with value: 0.6384180790960452 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 6, 'gamma': 1.433668941082768, 'lambda_sparse': 0.0017336709735101385, 'lr': 0.006960045372167099, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 256}. Best is trial 23 with value: 0.7539804827940421.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.639   | test_accuracy: 0.50539 |  0:00:01s\n",
      "epoch 1  | loss: 1.1069  | test_accuracy: 0.57473 |  0:00:02s\n",
      "epoch 2  | loss: 1.02306 | test_accuracy: 0.59527 |  0:00:02s\n",
      "epoch 3  | loss: 0.98393 | test_accuracy: 0.60195 |  0:00:03s\n",
      "epoch 4  | loss: 0.94995 | test_accuracy: 0.60812 |  0:00:04s\n",
      "epoch 5  | loss: 0.91992 | test_accuracy: 0.6189  |  0:00:06s\n",
      "epoch 6  | loss: 0.90763 | test_accuracy: 0.63636 |  0:00:07s\n",
      "epoch 7  | loss: 0.89154 | test_accuracy: 0.6189  |  0:00:07s\n",
      "epoch 8  | loss: 0.89258 | test_accuracy: 0.62506 |  0:00:08s\n",
      "epoch 9  | loss: 0.87997 | test_accuracy: 0.62404 |  0:00:09s\n",
      "epoch 10 | loss: 0.87141 | test_accuracy: 0.62301 |  0:00:10s\n",
      "epoch 11 | loss: 0.85566 | test_accuracy: 0.63636 |  0:00:11s\n",
      "epoch 12 | loss: 0.86121 | test_accuracy: 0.62404 |  0:00:12s\n",
      "epoch 13 | loss: 0.86247 | test_accuracy: 0.62096 |  0:00:12s\n",
      "epoch 14 | loss: 0.84762 | test_accuracy: 0.62506 |  0:00:13s\n",
      "epoch 15 | loss: 0.85203 | test_accuracy: 0.62558 |  0:00:14s\n",
      "epoch 16 | loss: 0.84622 | test_accuracy: 0.62506 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_test_accuracy = 0.63636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:04:06,604] Trial 27 finished with value: 0.6363636363636364 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 5, 'gamma': 1.2579436289088035, 'lambda_sparse': 0.0012229821919809833, 'lr': 0.005258165066571801, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 23 with value: 0.7539804827940421.\n",
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.88644 | test_accuracy: 0.50693 |  0:00:00s\n",
      "epoch 1  | loss: 1.0681  | test_accuracy: 0.58449 |  0:00:01s\n",
      "epoch 2  | loss: 0.97838 | test_accuracy: 0.58757 |  0:00:01s\n",
      "epoch 3  | loss: 0.95143 | test_accuracy: 0.60709 |  0:00:02s\n",
      "epoch 4  | loss: 0.9314  | test_accuracy: 0.61582 |  0:00:03s\n",
      "epoch 5  | loss: 0.91316 | test_accuracy: 0.62558 |  0:00:03s\n",
      "epoch 6  | loss: 0.89695 | test_accuracy: 0.61274 |  0:00:04s\n",
      "epoch 7  | loss: 0.88854 | test_accuracy: 0.62506 |  0:00:04s\n",
      "epoch 8  | loss: 0.8744  | test_accuracy: 0.64612 |  0:00:05s\n",
      "epoch 9  | loss: 0.86    | test_accuracy: 0.62866 |  0:00:05s\n",
      "epoch 10 | loss: 0.8544  | test_accuracy: 0.6415  |  0:00:06s\n",
      "epoch 11 | loss: 0.84645 | test_accuracy: 0.6379  |  0:00:07s\n",
      "epoch 12 | loss: 0.84851 | test_accuracy: 0.62455 |  0:00:07s\n",
      "epoch 13 | loss: 0.83861 | test_accuracy: 0.61993 |  0:00:08s\n",
      "epoch 14 | loss: 0.83381 | test_accuracy: 0.64972 |  0:00:08s\n",
      "epoch 15 | loss: 0.82679 | test_accuracy: 0.63123 |  0:00:09s\n",
      "epoch 16 | loss: 0.81669 | test_accuracy: 0.63945 |  0:00:10s\n",
      "epoch 17 | loss: 0.81184 | test_accuracy: 0.63893 |  0:00:10s\n",
      "epoch 18 | loss: 0.81793 | test_accuracy: 0.63482 |  0:00:11s\n",
      "epoch 19 | loss: 0.81875 | test_accuracy: 0.64099 |  0:00:11s\n",
      "epoch 20 | loss: 0.82085 | test_accuracy: 0.65177 |  0:00:12s\n",
      "epoch 21 | loss: 0.80066 | test_accuracy: 0.65229 |  0:00:12s\n",
      "epoch 22 | loss: 0.79866 | test_accuracy: 0.64458 |  0:00:13s\n",
      "epoch 23 | loss: 0.78816 | test_accuracy: 0.65588 |  0:00:14s\n",
      "epoch 24 | loss: 0.78385 | test_accuracy: 0.65023 |  0:00:14s\n",
      "epoch 25 | loss: 0.77833 | test_accuracy: 0.65074 |  0:00:15s\n",
      "epoch 26 | loss: 0.77383 | test_accuracy: 0.65794 |  0:00:15s\n",
      "epoch 27 | loss: 0.78074 | test_accuracy: 0.66153 |  0:00:16s\n",
      "epoch 28 | loss: 0.7755  | test_accuracy: 0.64869 |  0:00:16s\n",
      "epoch 29 | loss: 0.77049 | test_accuracy: 0.65999 |  0:00:17s\n",
      "epoch 30 | loss: 0.77127 | test_accuracy: 0.64766 |  0:00:18s\n",
      "epoch 31 | loss: 0.75713 | test_accuracy: 0.65537 |  0:00:18s\n",
      "epoch 32 | loss: 0.75688 | test_accuracy: 0.66256 |  0:00:19s\n",
      "epoch 33 | loss: 0.7496  | test_accuracy: 0.65948 |  0:00:19s\n",
      "epoch 34 | loss: 0.75173 | test_accuracy: 0.66615 |  0:00:20s\n",
      "epoch 35 | loss: 0.74673 | test_accuracy: 0.67334 |  0:00:21s\n",
      "epoch 36 | loss: 0.73327 | test_accuracy: 0.66769 |  0:00:21s\n",
      "epoch 37 | loss: 0.74669 | test_accuracy: 0.66256 |  0:00:22s\n",
      "epoch 38 | loss: 0.7524  | test_accuracy: 0.66821 |  0:00:22s\n",
      "epoch 39 | loss: 0.73478 | test_accuracy: 0.67026 |  0:00:23s\n",
      "epoch 40 | loss: 0.73498 | test_accuracy: 0.66923 |  0:00:24s\n",
      "epoch 41 | loss: 0.72851 | test_accuracy: 0.67283 |  0:00:25s\n",
      "epoch 42 | loss: 0.71942 | test_accuracy: 0.66615 |  0:00:25s\n",
      "epoch 43 | loss: 0.72291 | test_accuracy: 0.65948 |  0:00:26s\n",
      "epoch 44 | loss: 0.72256 | test_accuracy: 0.65999 |  0:00:26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:04:34,268] Trial 28 finished with value: 0.6733436055469953 and parameters: {'n_d': 32, 'n_a': 8, 'n_steps': 4, 'gamma': 1.4286732245726588, 'lambda_sparse': 0.00036912680625090415, 'lr': 0.008029856906237332, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 23 with value: 0.7539804827940421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 | loss: 0.71608 | test_accuracy: 0.66153 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_test_accuracy = 0.67334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.53388 | test_accuracy: 0.12275 |  0:00:00s\n",
      "epoch 1  | loss: 2.06015 | test_accuracy: 0.33693 |  0:00:00s\n",
      "epoch 2  | loss: 1.7506  | test_accuracy: 0.48947 |  0:00:01s\n",
      "epoch 3  | loss: 1.53837 | test_accuracy: 0.54083 |  0:00:01s\n",
      "epoch 4  | loss: 1.39242 | test_accuracy: 0.55829 |  0:00:02s\n",
      "epoch 5  | loss: 1.2856  | test_accuracy: 0.57114 |  0:00:02s\n",
      "epoch 6  | loss: 1.19631 | test_accuracy: 0.57935 |  0:00:02s\n",
      "epoch 7  | loss: 1.13811 | test_accuracy: 0.5886  |  0:00:03s\n",
      "epoch 8  | loss: 1.0872  | test_accuracy: 0.59682 |  0:00:03s\n",
      "epoch 9  | loss: 1.04815 | test_accuracy: 0.60657 |  0:00:04s\n",
      "epoch 10 | loss: 1.02662 | test_accuracy: 0.61068 |  0:00:04s\n",
      "epoch 11 | loss: 1.00125 | test_accuracy: 0.6189  |  0:00:05s\n",
      "epoch 12 | loss: 0.98478 | test_accuracy: 0.61787 |  0:00:05s\n",
      "epoch 13 | loss: 0.97104 | test_accuracy: 0.62352 |  0:00:06s\n",
      "epoch 14 | loss: 0.96149 | test_accuracy: 0.61993 |  0:00:06s\n",
      "epoch 15 | loss: 0.95398 | test_accuracy: 0.61839 |  0:00:07s\n",
      "epoch 16 | loss: 0.93952 | test_accuracy: 0.62044 |  0:00:07s\n",
      "epoch 17 | loss: 0.93404 | test_accuracy: 0.61479 |  0:00:08s\n",
      "epoch 18 | loss: 0.92909 | test_accuracy: 0.61685 |  0:00:08s\n",
      "epoch 19 | loss: 0.91319 | test_accuracy: 0.61685 |  0:00:08s\n",
      "epoch 20 | loss: 0.91406 | test_accuracy: 0.61839 |  0:00:09s\n",
      "epoch 21 | loss: 0.90302 | test_accuracy: 0.62096 |  0:00:09s\n",
      "epoch 22 | loss: 0.9032  | test_accuracy: 0.62096 |  0:00:10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-05-20 16:04:45,149] Trial 29 finished with value: 0.6235233692860811 and parameters: {'n_d': 8, 'n_a': 32, 'n_steps': 3, 'gamma': 1.6071829909582283, 'lambda_sparse': 0.0027253411149805147, 'lr': 0.0012095818772022032, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 23 with value: 0.7539804827940421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 | loss: 0.90132 | test_accuracy: 0.61736 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_test_accuracy = 0.62352\n",
      "Best trial:\n",
      "FrozenTrial(number=23, state=TrialState.COMPLETE, values=[0.7539804827940421], datetime_start=datetime.datetime(2025, 5, 20, 16, 1, 6, 58713), datetime_complete=datetime.datetime(2025, 5, 20, 16, 2, 13, 234558), params={'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.3542801903123354, 'lambda_sparse': 0.0015067427179960662, 'lr': 0.007483834315662805, 'mask_type': 'entmax', 'batch_size': 512, 'virtual_batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_d': CategoricalDistribution(choices=(8, 16, 32)), 'n_a': CategoricalDistribution(choices=(8, 16, 32)), 'n_steps': IntDistribution(high=10, log=False, low=3, step=1), 'gamma': FloatDistribution(high=2.0, log=False, low=1.0, step=None), 'lambda_sparse': FloatDistribution(high=0.01, log=True, low=1e-05, step=None), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'mask_type': CategoricalDistribution(choices=('entmax', 'sparsemax')), 'batch_size': CategoricalDistribution(choices=(512, 1024)), 'virtual_batch_size': CategoricalDistribution(choices=(128, 256))}, trial_id=23, value=None)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:49:17.745667Z",
     "start_time": "2025-05-20T13:47:19.062741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "best_model = TabNetClassifier(\n",
    "    n_d=best_params[\"n_d\"],\n",
    "    n_a=best_params[\"n_a\"],\n",
    "    n_steps=best_params[\"n_steps\"],\n",
    "    gamma=best_params[\"gamma\"],\n",
    "    lambda_sparse=best_params[\"lambda_sparse\"],\n",
    "    optimizer_params={\"lr\": best_params[\"lr\"]},\n",
    "    mask_type=best_params[\"mask_type\"],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X_train=X_train_final, y_train=y_train_final,\n",
    "    eval_set=[(X_test_scaled, y_test)],\n",
    "    eval_name=[\"test\"],\n",
    "    eval_metric=[\"accuracy\"],\n",
    "    max_epochs=200,\n",
    "    patience=30,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    virtual_batch_size=best_params[\"virtual_batch_size\"],\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_preds = best_model.predict(X_test_scaled)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ],
   "id": "339bcd7d34859855",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.54768 | test_accuracy: 0.48462 |  0:00:00s\n",
      "epoch 1  | loss: 1.05302 | test_accuracy: 0.51154 |  0:00:01s\n",
      "epoch 2  | loss: 0.98155 | test_accuracy: 0.52692 |  0:00:02s\n",
      "epoch 3  | loss: 0.94856 | test_accuracy: 0.53077 |  0:00:02s\n",
      "epoch 4  | loss: 0.91376 | test_accuracy: 0.54077 |  0:00:03s\n",
      "epoch 5  | loss: 0.90496 | test_accuracy: 0.55385 |  0:00:04s\n",
      "epoch 6  | loss: 0.90331 | test_accuracy: 0.55385 |  0:00:04s\n",
      "epoch 7  | loss: 0.89071 | test_accuracy: 0.54692 |  0:00:05s\n",
      "epoch 8  | loss: 0.88063 | test_accuracy: 0.55692 |  0:00:06s\n",
      "epoch 9  | loss: 0.87399 | test_accuracy: 0.55    |  0:00:06s\n",
      "epoch 10 | loss: 0.86675 | test_accuracy: 0.54923 |  0:00:07s\n",
      "epoch 11 | loss: 0.86371 | test_accuracy: 0.55692 |  0:00:07s\n",
      "epoch 12 | loss: 0.84978 | test_accuracy: 0.54538 |  0:00:08s\n",
      "epoch 13 | loss: 0.85292 | test_accuracy: 0.55538 |  0:00:09s\n",
      "epoch 14 | loss: 0.84358 | test_accuracy: 0.55231 |  0:00:09s\n",
      "epoch 15 | loss: 0.85213 | test_accuracy: 0.54769 |  0:00:10s\n",
      "epoch 16 | loss: 0.83671 | test_accuracy: 0.56077 |  0:00:11s\n",
      "epoch 17 | loss: 0.82484 | test_accuracy: 0.55    |  0:00:11s\n",
      "epoch 18 | loss: 0.82771 | test_accuracy: 0.55385 |  0:00:12s\n",
      "epoch 19 | loss: 0.82075 | test_accuracy: 0.55308 |  0:00:13s\n",
      "epoch 20 | loss: 0.81258 | test_accuracy: 0.55615 |  0:00:13s\n",
      "epoch 21 | loss: 0.80389 | test_accuracy: 0.54923 |  0:00:14s\n",
      "epoch 22 | loss: 0.80127 | test_accuracy: 0.56231 |  0:00:15s\n",
      "epoch 23 | loss: 0.79152 | test_accuracy: 0.55    |  0:00:15s\n",
      "epoch 24 | loss: 0.78783 | test_accuracy: 0.56154 |  0:00:16s\n",
      "epoch 25 | loss: 0.79178 | test_accuracy: 0.56308 |  0:00:17s\n",
      "epoch 26 | loss: 0.78849 | test_accuracy: 0.55923 |  0:00:17s\n",
      "epoch 27 | loss: 0.79295 | test_accuracy: 0.56462 |  0:00:18s\n",
      "epoch 28 | loss: 0.78227 | test_accuracy: 0.57308 |  0:00:19s\n",
      "epoch 29 | loss: 0.76983 | test_accuracy: 0.56846 |  0:00:19s\n",
      "epoch 30 | loss: 0.76781 | test_accuracy: 0.55846 |  0:00:20s\n",
      "epoch 31 | loss: 0.77212 | test_accuracy: 0.57385 |  0:00:20s\n",
      "epoch 32 | loss: 0.76937 | test_accuracy: 0.57154 |  0:00:21s\n",
      "epoch 33 | loss: 0.76573 | test_accuracy: 0.56462 |  0:00:22s\n",
      "epoch 34 | loss: 0.77067 | test_accuracy: 0.56154 |  0:00:22s\n",
      "epoch 35 | loss: 0.75795 | test_accuracy: 0.56462 |  0:00:23s\n",
      "epoch 36 | loss: 0.75345 | test_accuracy: 0.56    |  0:00:24s\n",
      "epoch 37 | loss: 0.7429  | test_accuracy: 0.56385 |  0:00:24s\n",
      "epoch 38 | loss: 0.73591 | test_accuracy: 0.56923 |  0:00:25s\n",
      "epoch 39 | loss: 0.74455 | test_accuracy: 0.57462 |  0:00:26s\n",
      "epoch 40 | loss: 0.74579 | test_accuracy: 0.56846 |  0:00:26s\n",
      "epoch 41 | loss: 0.73089 | test_accuracy: 0.57077 |  0:00:27s\n",
      "epoch 42 | loss: 0.72165 | test_accuracy: 0.57923 |  0:00:28s\n",
      "epoch 43 | loss: 0.73185 | test_accuracy: 0.58308 |  0:00:28s\n",
      "epoch 44 | loss: 0.71219 | test_accuracy: 0.58385 |  0:00:29s\n",
      "epoch 45 | loss: 0.70878 | test_accuracy: 0.57846 |  0:00:30s\n",
      "epoch 46 | loss: 0.71016 | test_accuracy: 0.57154 |  0:00:30s\n",
      "epoch 47 | loss: 0.71738 | test_accuracy: 0.57769 |  0:00:31s\n",
      "epoch 48 | loss: 0.70657 | test_accuracy: 0.57308 |  0:00:31s\n",
      "epoch 49 | loss: 0.7048  | test_accuracy: 0.56462 |  0:00:32s\n",
      "epoch 50 | loss: 0.70757 | test_accuracy: 0.57923 |  0:00:33s\n",
      "epoch 51 | loss: 0.69925 | test_accuracy: 0.57462 |  0:00:33s\n",
      "epoch 52 | loss: 0.69408 | test_accuracy: 0.58462 |  0:00:34s\n",
      "epoch 53 | loss: 0.68726 | test_accuracy: 0.58308 |  0:00:35s\n",
      "epoch 54 | loss: 0.70028 | test_accuracy: 0.58769 |  0:00:35s\n",
      "epoch 55 | loss: 0.68614 | test_accuracy: 0.59077 |  0:00:36s\n",
      "epoch 56 | loss: 0.67672 | test_accuracy: 0.57385 |  0:00:37s\n",
      "epoch 57 | loss: 0.67156 | test_accuracy: 0.59769 |  0:00:37s\n",
      "epoch 58 | loss: 0.67874 | test_accuracy: 0.58154 |  0:00:38s\n",
      "epoch 59 | loss: 0.66189 | test_accuracy: 0.59846 |  0:00:39s\n",
      "epoch 60 | loss: 0.65444 | test_accuracy: 0.56385 |  0:00:39s\n",
      "epoch 61 | loss: 0.65364 | test_accuracy: 0.57462 |  0:00:40s\n",
      "epoch 62 | loss: 0.66346 | test_accuracy: 0.58231 |  0:00:41s\n",
      "epoch 63 | loss: 0.64251 | test_accuracy: 0.58538 |  0:00:42s\n",
      "epoch 64 | loss: 0.65266 | test_accuracy: 0.58769 |  0:00:42s\n",
      "epoch 65 | loss: 0.63718 | test_accuracy: 0.58462 |  0:00:43s\n",
      "epoch 66 | loss: 0.63534 | test_accuracy: 0.58769 |  0:00:44s\n",
      "epoch 67 | loss: 0.62983 | test_accuracy: 0.58385 |  0:00:44s\n",
      "epoch 68 | loss: 0.62095 | test_accuracy: 0.57923 |  0:00:45s\n",
      "epoch 69 | loss: 0.6271  | test_accuracy: 0.60077 |  0:00:45s\n",
      "epoch 70 | loss: 0.60984 | test_accuracy: 0.59    |  0:00:46s\n",
      "epoch 71 | loss: 0.60705 | test_accuracy: 0.59615 |  0:00:47s\n",
      "epoch 72 | loss: 0.60136 | test_accuracy: 0.60846 |  0:00:47s\n",
      "epoch 73 | loss: 0.61212 | test_accuracy: 0.59385 |  0:00:48s\n",
      "epoch 74 | loss: 0.59993 | test_accuracy: 0.59308 |  0:00:49s\n",
      "epoch 75 | loss: 0.60964 | test_accuracy: 0.6     |  0:00:49s\n",
      "epoch 76 | loss: 0.60249 | test_accuracy: 0.59385 |  0:00:50s\n",
      "epoch 77 | loss: 0.5847  | test_accuracy: 0.58462 |  0:00:51s\n",
      "epoch 78 | loss: 0.58337 | test_accuracy: 0.58692 |  0:00:51s\n",
      "epoch 79 | loss: 0.5746  | test_accuracy: 0.58769 |  0:00:52s\n",
      "epoch 80 | loss: 0.57811 | test_accuracy: 0.57923 |  0:00:53s\n",
      "epoch 81 | loss: 0.58219 | test_accuracy: 0.59    |  0:00:53s\n",
      "epoch 82 | loss: 0.59573 | test_accuracy: 0.59    |  0:00:54s\n",
      "epoch 83 | loss: 0.58504 | test_accuracy: 0.58462 |  0:00:55s\n",
      "epoch 84 | loss: 0.57523 | test_accuracy: 0.59154 |  0:00:55s\n",
      "epoch 85 | loss: 0.56672 | test_accuracy: 0.59385 |  0:00:56s\n",
      "epoch 86 | loss: 0.54583 | test_accuracy: 0.60923 |  0:00:57s\n",
      "epoch 87 | loss: 0.54944 | test_accuracy: 0.60231 |  0:00:57s\n",
      "epoch 88 | loss: 0.55173 | test_accuracy: 0.59462 |  0:00:58s\n",
      "epoch 89 | loss: 0.54788 | test_accuracy: 0.59231 |  0:00:59s\n",
      "epoch 90 | loss: 0.53362 | test_accuracy: 0.58769 |  0:00:59s\n",
      "epoch 91 | loss: 0.54006 | test_accuracy: 0.58846 |  0:01:00s\n",
      "epoch 92 | loss: 0.54364 | test_accuracy: 0.58923 |  0:01:01s\n",
      "epoch 93 | loss: 0.52334 | test_accuracy: 0.59462 |  0:01:01s\n",
      "epoch 94 | loss: 0.54843 | test_accuracy: 0.6     |  0:01:02s\n",
      "epoch 95 | loss: 0.5285  | test_accuracy: 0.60462 |  0:01:03s\n",
      "epoch 96 | loss: 0.52137 | test_accuracy: 0.59923 |  0:01:03s\n",
      "epoch 97 | loss: 0.51287 | test_accuracy: 0.61538 |  0:01:04s\n",
      "epoch 98 | loss: 0.51086 | test_accuracy: 0.60231 |  0:01:05s\n",
      "epoch 99 | loss: 0.50931 | test_accuracy: 0.60308 |  0:01:05s\n",
      "epoch 100| loss: 0.50659 | test_accuracy: 0.61154 |  0:01:06s\n",
      "epoch 101| loss: 0.50128 | test_accuracy: 0.61077 |  0:01:07s\n",
      "epoch 102| loss: 0.50849 | test_accuracy: 0.59462 |  0:01:07s\n",
      "epoch 103| loss: 0.49186 | test_accuracy: 0.61    |  0:01:08s\n",
      "epoch 104| loss: 0.49098 | test_accuracy: 0.59385 |  0:01:08s\n",
      "epoch 105| loss: 0.48141 | test_accuracy: 0.61    |  0:01:09s\n",
      "epoch 106| loss: 0.47134 | test_accuracy: 0.60385 |  0:01:10s\n",
      "epoch 107| loss: 0.4637  | test_accuracy: 0.60308 |  0:01:11s\n",
      "epoch 108| loss: 0.47464 | test_accuracy: 0.6     |  0:01:11s\n",
      "epoch 109| loss: 0.46922 | test_accuracy: 0.60769 |  0:01:12s\n",
      "epoch 110| loss: 0.48007 | test_accuracy: 0.59923 |  0:01:13s\n",
      "epoch 111| loss: 0.46605 | test_accuracy: 0.61154 |  0:01:13s\n",
      "epoch 112| loss: 0.45776 | test_accuracy: 0.60231 |  0:01:14s\n",
      "epoch 113| loss: 0.45643 | test_accuracy: 0.60769 |  0:01:15s\n",
      "epoch 114| loss: 0.45066 | test_accuracy: 0.59    |  0:01:15s\n",
      "epoch 115| loss: 0.45877 | test_accuracy: 0.60923 |  0:01:16s\n",
      "epoch 116| loss: 0.44687 | test_accuracy: 0.61154 |  0:01:16s\n",
      "epoch 117| loss: 0.44454 | test_accuracy: 0.59615 |  0:01:17s\n",
      "epoch 118| loss: 0.45745 | test_accuracy: 0.60769 |  0:01:18s\n",
      "epoch 119| loss: 0.44245 | test_accuracy: 0.6     |  0:01:18s\n",
      "epoch 120| loss: 0.43118 | test_accuracy: 0.60308 |  0:01:19s\n",
      "epoch 121| loss: 0.43049 | test_accuracy: 0.61846 |  0:01:20s\n",
      "epoch 122| loss: 0.42371 | test_accuracy: 0.60385 |  0:01:20s\n",
      "epoch 123| loss: 0.42968 | test_accuracy: 0.61308 |  0:01:21s\n",
      "epoch 124| loss: 0.43612 | test_accuracy: 0.60615 |  0:01:22s\n",
      "epoch 125| loss: 0.422   | test_accuracy: 0.62462 |  0:01:22s\n",
      "epoch 126| loss: 0.41444 | test_accuracy: 0.60846 |  0:01:23s\n",
      "epoch 127| loss: 0.42425 | test_accuracy: 0.61462 |  0:01:23s\n",
      "epoch 128| loss: 0.43334 | test_accuracy: 0.60923 |  0:01:24s\n",
      "epoch 129| loss: 0.42385 | test_accuracy: 0.62692 |  0:01:25s\n",
      "epoch 130| loss: 0.41355 | test_accuracy: 0.61462 |  0:01:25s\n",
      "epoch 131| loss: 0.4244  | test_accuracy: 0.61692 |  0:01:26s\n",
      "epoch 132| loss: 0.42083 | test_accuracy: 0.60692 |  0:01:27s\n",
      "epoch 133| loss: 0.4184  | test_accuracy: 0.62769 |  0:01:27s\n",
      "epoch 134| loss: 0.39041 | test_accuracy: 0.61154 |  0:01:28s\n",
      "epoch 135| loss: 0.39825 | test_accuracy: 0.62923 |  0:01:29s\n",
      "epoch 136| loss: 0.39603 | test_accuracy: 0.62615 |  0:01:29s\n",
      "epoch 137| loss: 0.37801 | test_accuracy: 0.63077 |  0:01:30s\n",
      "epoch 138| loss: 0.37582 | test_accuracy: 0.61846 |  0:01:31s\n",
      "epoch 139| loss: 0.3844  | test_accuracy: 0.62231 |  0:01:31s\n",
      "epoch 140| loss: 0.37063 | test_accuracy: 0.61846 |  0:01:32s\n",
      "epoch 141| loss: 0.36119 | test_accuracy: 0.62615 |  0:01:32s\n",
      "epoch 142| loss: 0.36933 | test_accuracy: 0.62692 |  0:01:33s\n",
      "epoch 143| loss: 0.36062 | test_accuracy: 0.63    |  0:01:34s\n",
      "epoch 144| loss: 0.37667 | test_accuracy: 0.63077 |  0:01:34s\n",
      "epoch 145| loss: 0.36734 | test_accuracy: 0.62538 |  0:01:35s\n",
      "epoch 146| loss: 0.38051 | test_accuracy: 0.63385 |  0:01:36s\n",
      "epoch 147| loss: 0.36279 | test_accuracy: 0.61615 |  0:01:36s\n",
      "epoch 148| loss: 0.34083 | test_accuracy: 0.63154 |  0:01:37s\n",
      "epoch 149| loss: 0.34268 | test_accuracy: 0.62538 |  0:01:37s\n",
      "epoch 150| loss: 0.34174 | test_accuracy: 0.62462 |  0:01:38s\n",
      "epoch 151| loss: 0.34562 | test_accuracy: 0.64538 |  0:01:39s\n",
      "epoch 152| loss: 0.33159 | test_accuracy: 0.64462 |  0:01:39s\n",
      "epoch 153| loss: 0.35175 | test_accuracy: 0.62385 |  0:01:40s\n",
      "epoch 154| loss: 0.36105 | test_accuracy: 0.62462 |  0:01:41s\n",
      "epoch 155| loss: 0.35753 | test_accuracy: 0.63077 |  0:01:41s\n",
      "epoch 156| loss: 0.34604 | test_accuracy: 0.62769 |  0:01:42s\n",
      "epoch 157| loss: 0.34142 | test_accuracy: 0.62538 |  0:01:42s\n",
      "epoch 158| loss: 0.34902 | test_accuracy: 0.62846 |  0:01:43s\n",
      "epoch 159| loss: 0.34048 | test_accuracy: 0.63462 |  0:01:44s\n",
      "epoch 160| loss: 0.3307  | test_accuracy: 0.62538 |  0:01:44s\n",
      "epoch 161| loss: 0.32203 | test_accuracy: 0.63231 |  0:01:45s\n",
      "epoch 162| loss: 0.31845 | test_accuracy: 0.63231 |  0:01:46s\n",
      "epoch 163| loss: 0.31715 | test_accuracy: 0.62231 |  0:01:46s\n",
      "epoch 164| loss: 0.31826 | test_accuracy: 0.63615 |  0:01:47s\n",
      "epoch 165| loss: 0.309   | test_accuracy: 0.62231 |  0:01:47s\n",
      "epoch 166| loss: 0.30195 | test_accuracy: 0.62923 |  0:01:48s\n",
      "epoch 167| loss: 0.31225 | test_accuracy: 0.63692 |  0:01:49s\n",
      "epoch 168| loss: 0.30182 | test_accuracy: 0.63615 |  0:01:49s\n",
      "epoch 169| loss: 0.30459 | test_accuracy: 0.64231 |  0:01:50s\n",
      "epoch 170| loss: 0.29092 | test_accuracy: 0.62846 |  0:01:51s\n",
      "epoch 171| loss: 0.29672 | test_accuracy: 0.64154 |  0:01:51s\n",
      "epoch 172| loss: 0.29352 | test_accuracy: 0.64538 |  0:01:52s\n",
      "epoch 173| loss: 0.2873  | test_accuracy: 0.63462 |  0:01:53s\n",
      "epoch 174| loss: 0.28952 | test_accuracy: 0.63538 |  0:01:53s\n",
      "epoch 175| loss: 0.28388 | test_accuracy: 0.64154 |  0:01:54s\n",
      "epoch 176| loss: 0.27951 | test_accuracy: 0.62692 |  0:01:54s\n",
      "epoch 177| loss: 0.26728 | test_accuracy: 0.63615 |  0:01:55s\n",
      "epoch 178| loss: 0.2779  | test_accuracy: 0.63077 |  0:01:56s\n",
      "epoch 179| loss: 0.28628 | test_accuracy: 0.62769 |  0:01:57s\n",
      "epoch 180| loss: 0.28233 | test_accuracy: 0.63154 |  0:01:57s\n",
      "epoch 181| loss: 0.27299 | test_accuracy: 0.64231 |  0:01:58s\n",
      "\n",
      "Early stopping occurred at epoch 181 with best_epoch = 151 and best_test_accuracy = 0.64538\n",
      "Test accuracy: 0.6454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkuayten/Library/Python/3.9/lib/python/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:51:29.357026Z",
     "start_time": "2025-05-20T13:51:29.268747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_df = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "\n",
    "results_df.to_csv(\"tabnet_wine_optuna.csv\", index=False)\n",
    "\n",
    "print(\"Study results saved to tabnet_wine_optuna.csv\")\n"
   ],
   "id": "2c29e08a14659d3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study results saved to tabnet_wine_optuna.csv\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36a43a242ff62c35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
